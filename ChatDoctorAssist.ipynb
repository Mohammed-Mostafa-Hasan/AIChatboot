{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4ab4cc",
   "metadata": {},
   "source": [
    "## Build a conversation agent by langchain and OpenAI \n",
    "- overview about langchain \n",
    "\n",
    "* it contain backbone where all abstraction and runtime logic are stored\n",
    "* layer of third party integration and components \n",
    "* a set of prebuilt architectures and templates to use\n",
    "* a serving layer to consume chain as api\n",
    "* an observability layer to monitor your application in development test and and production state \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19484362",
   "metadata": {},
   "source": [
    "### Overview about all libraries used \n",
    "\n",
    "- os : interacting with our operating system to get data from it.\n",
    "- dotenv: .env file is a file where i can store my secret info in .gitignore file\n",
    "\n",
    "<a href = \"https://docs.langchain.com/?_gl=1*1qfiw4g*_gcl_au*MTkyNDcwMTM3Ny4xNzYyMzE4Mzgz*_ga*NzM3NDc0ODQyLjE3NjIzMTgzODQ.*_ga_47WX3HKKY2*czE3NjIzMTgzODMkbzEkZzAkdDE3NjIzMTgzODMkajYwJGwwJGgw\">Langchain</a>\n",
    "\n",
    "\n",
    "\n",
    "- <font color =\"yellow\">Prompt Templates </font>: help to translate user input and parameters into instructions for a language model. This can be used to guide a model's response, helping it understand the context and generate relevant and coherent language-based output for more information click on <a href = \"https://github.com/langchain-ai/langchain/blob/v0.3/docs/docs/concepts/prompt_templates.mdx\">link</a> this can imported from langchain or langchain-classic.\n",
    "\n",
    "- <font color =\"yellow\">LLmChain </font>: It‚Äôs used to connect a language model (like GPT) with a prompt template ‚Äî making it easy to run structured interactions with an LLM this can imported from langchain or langchain-classic.\n",
    "\n",
    "Benefit of usage\n",
    "\n",
    "‚úÖ Reusability ‚Äî easily reuse prompt templates.\n",
    "\n",
    "‚úÖ Integration ‚Äî can chain multiple LLMChains together.\n",
    "\n",
    "‚úÖ Clarity ‚Äî separates prompt design from model logic.\n",
    "\n",
    "‚úÖ Control ‚Äî better structure for debugging and scaling workflows.\n",
    "\n",
    "- <font color =\"yellow\">ConversationChain </font>: maintained conversation history with memory. It combined a language model with a memory component to track the conversation context can imported from langchain.chains .\n",
    "\n",
    "- <font color =\"yellow\">ChatOpenAI </font> This guide will help you getting started with ChatOpenAI chat models for more <a href = \"https://v03.api.js.langchain.com/classes/_langchain_openai.ChatOpenAI.html?_gl=1*z6uc5g*_gcl_au*MTkyNDcwMTM3Ny4xNzYyMzE4Mzgz*_ga*NzM3NDc0ODQyLjE3NjIzMTgzODQ.*_ga_47WX3HKKY2*czE3NjIzMjU3OTQkbzMkZzEkdDE3NjIzMjU4MTAkajQ0JGwwJGgw\">info</a> this can import from langchain.chat_models .\n",
    "\n",
    "- <font color =\"yellow\">ConversationBufferMemory </font> this enable you to store your chat message and extract them in a variable to use it when it needed can imported from langchain.memory . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee190dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-core in /Users/mac/Library/Python/3.9/lib/python/site-packages (0.3.79)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain-core) (2.12.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain-core) (0.4.37)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.4)\n",
      "Requirement already satisfied: anyio in /Users/mac/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.11.0)\n",
      "Requirement already satisfied: idna in /Users/mac/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mac/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: certifi in /Users/mac/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.10.5)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "''' all libraries installed \n",
    "pip install langchain-core\n",
    "pip install faiss-cpu google-search-results\n",
    "pip install tiktoken\n",
    "pip install pypdf\n",
    "pip install openai\n",
    "pip install huggingface_hub\n",
    "pip install streamlit\n",
    " pip install --upgrade langchain langchain-community langchain-openai  # Install core, community, and OpenAI integrations\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3787a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "OpenAi_api_key = os.environ['openai_api_key']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9107ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=OpenAi_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "224c82ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure thing‚Äîhere‚Äôs a quick one for you:\n",
      "\n",
      "**Why don't skeletons fight each other?**\n",
      "\n",
      "Because they don't have the guts. üòÑ\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    " \n",
    "  model=\"openai/gpt-oss-20b\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"tell me a jok?\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0cef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain, ConversationChain  \n",
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "314ed17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/6gb01wfj6tsbpbbv07qz7nt40000gn/T/ipykernel_2542/1322791419.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here‚Äôs a **two‚Äëday ‚Äúmust‚Äësee‚Äù itinerary** that balances Rome‚Äôs iconic landmarks, a touch of local flavor, and a realistic pace.  \n",
      "Feel free to tweak it based on your interests (food, art, shopping, etc.) or let me know if you‚Äôd like a more relaxed or adventurous version!\n",
      "\n",
      "---\n",
      "\n",
      "## Day‚ÄØ1 ‚Äì Ancient Rome & Classic Highlights\n",
      "\n",
      "| Time | Activity | Notes |\n",
      "|------|----------|-------|\n",
      "| **08:30 ‚Äì 10:00** | **Colosseum** (skip‚Äëthe‚Äëline ticket) | Arrive early to beat crowds. 30‚Äëmin audio guide is great. |\n",
      "| **10:15 ‚Äì 11:30** | **Roman Forum & Palatine Hill** | Walk through the ruins; the Palatine offers a panoramic view of the Forum. |\n",
      "| **11:45 ‚Äì 12:30** | **Lunch in Monti** | Try a classic *suppl√¨* or *pizza al taglio* at a local trattoria. |\n",
      "| **12:45 ‚Äì 13:30** | **Capitoline Hill & Museums** | A short walk; the museums have a superb collection of ancient art. |\n",
      "| **13:45 ‚Äì 14:15** | **Pantheon** | Free entry; the dome is a marvel. |\n",
      "| **14:30 ‚Äì 15:00** | **Piazza Navona** | Grab a gelato, enjoy the fountains, and maybe a quick coffee. |\n",
      "| **15:15 ‚Äì 15:45** | **Trevi Fountain** | Toss a coin‚Äîbest in the late afternoon when the light is golden. |\n",
      "| **16:00 ‚Äì 16:30** | **Spanish Steps** | Climb the steps; the view of the city is worth it. |\n",
      "| **17:00 ‚Äì 18:30** | **Shopping/Leisure in Via del Corso** | Browse boutiques or just stroll. |\n",
      "| **19:00** | **Dinner in Trastevere** | Book a table at *Da Enzo* or *Osteria der Belli* for authentic Roman cuisine. |\n",
      "\n",
      "**Transport Tips**  \n",
      "- **Metro**: Line A (Colosseum) ‚Üí Line B (Pantheon) ‚Üí Line A (Piazza Navona).  \n",
      "- **Walking**: Most sites are within a 20‚Äëmin walk of each other.  \n",
      "- **Tickets**: Buy a combined ‚ÄúColosseum, Roman Forum & Palatine‚Äù ticket online to skip the line.\n",
      "\n",
      "---\n",
      "\n",
      "## Day‚ÄØ2 ‚Äì Vatican & Trastevere\n",
      "\n",
      "| Time | Activity | Notes |\n",
      "|------|----------|-------|\n",
      "| **08:30 ‚Äì 10:30** | **Vatican Museums & Sistine Chapel** | Book a ‚Äúskip‚Äëthe‚Äëline‚Äù guided tour. 2‚Äëhour visit is typical. |\n",
      "| **10:45 ‚Äì 11:30** | **St.‚ÄØPeter‚Äôs Basilica** | Free entry; climb to the dome for a breathtaking view. |\n",
      "| **11:45 ‚Äì 12:30** | **Castel Sant‚ÄôAngelo** | Walk along the Tiber; the museum offers great art and history. |\n",
      "| **12:45 ‚Äì 13:45** | **Lunch near the Vatican** | Try *Pizzarium* for a quick, delicious bite. |\n",
      "| **14:00 ‚Äì 15:30** | **Trastevere Exploration** | Wander the cobblestone streets, visit Santa Maria in Trastevere. |\n",
      "| **15:45 ‚Äì 16:30** | **Villa Farnesina** (optional) | A Renaissance gem; free entry, but check opening times. |\n",
      "| **17:00 ‚Äì 18:30** | **Relax at Villa Borghese Gardens** | Rent a bike or just stroll; the park is a nice break. |\n",
      "| **19:00** | **Dinner in Trastevere** | *Osteria Santa Maria* or *Da Teo* for a cozy, local experience. |\n",
      "\n",
      "**Transport Tips**  \n",
      "- **Metro**: Line A (Ottaviano) ‚Üí Line B (Ottaviano) ‚Üí Line A (Trastevere).  \n",
      "- **Walking**: The Vatican area is compact; Trastevere is best explored on foot.  \n",
      "- **Tickets**: Pre‚Äëbook the Vatican Museums and consider a combined Vatican & Castel Sant‚ÄôAngelo ticket.\n",
      "\n",
      "---\n",
      "\n",
      "## Quick Checklist\n",
      "\n",
      "| ‚úîÔ∏è | Item |\n",
      "|----|------|\n",
      "| **Tickets** | Colosseum + Forum + Palatine (online), Vatican Museums (online), optional guided tours. |\n",
      "| **Transport** | Metro card (10‚Äëride) or daily pass; consider a bike rental for Villa Borghese. |\n",
      "| **Meals** | Reserve dinner tables in advance for Trastevere restaurants. |\n",
      "| **Packing** | Comfortable shoes, light jacket (evenings can be cool), reusable water bottle. |\n",
      "| **Apps** | Google Maps, Rome2rio, *Vatican Museums* app for audio guides. |\n",
      "\n",
      "---\n",
      "\n",
      "### Want to tailor this plan?\n",
      "\n",
      "- **Food‚Äëcentric**: I can suggest a culinary tour or a food market visit.  \n",
      "- **Art & Culture**: Add the Galleria Borghese or the MAXXI museum.  \n",
      "- **Relaxed Pace**: Spread the sites over more days or skip a few.  \n",
      "- **Budget**: I can recommend free or low‚Äëcost alternatives.  \n",
      "\n",
      "Just let me know what you‚Äôre most excited about, and I‚Äôll fine‚Äëtune the itinerary!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize ChatOpenAI with OpenRouter parameters\n",
    "chat = ChatOpenAI(\n",
    "    model=\"openai/gpt-oss-20b\",\n",
    "    temperature=0,\n",
    "    api_key=OpenAi_api_key,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    # You can also add extra headers if needed, e.g.:\n",
    "    # extra_headers={\"HTTP-Referer\": \"https://www.youtube.com\", \"X-Title\": \"getconnection tools\"},\n",
    ")\n",
    "\n",
    "# Example Usage\n",
    "messages = [\n",
    "    SystemMessage(content=\"you are a helpful assistant that help the user to plan an optimized itinerary.\")\n",
    "    ,\n",
    "    HumanMessage(\n",
    "        content=\"i am going to Rome for 2 days, what can I visit\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Invoke the model\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c063d1",
   "metadata": {},
   "source": [
    "### Add Memory\n",
    "keep track previous conversation with the user for better flow up response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da604d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/6gb01wfj6tsbpbbv07qz7nt40000gn/T/ipykernel_2542/2508459009.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "/var/folders/0p/6gb01wfj6tsbpbbv07qz7nt40000gn/T/ipykernel_2542/2508459009.py:5: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(\n",
      "/var/folders/0p/6gb01wfj6tsbpbbv07qz7nt40000gn/T/ipykernel_2542/2508459009.py:9: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  conversation.run(\"Hi there!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hey there! üëã I‚Äôm thrilled you dropped by. I‚Äôm your friendly neighborhood AI, ready to dive into anything you‚Äôre curious about‚Äîwhether it‚Äôs the latest tech trends, a deep dive into the history of the Eiffel Tower, or just a good old-fashioned chat about your favorite pizza topping. \\n\\nIf you‚Äôve got a question, a project you‚Äôre working on, or even a random ‚Äúwhat if‚Äù scenario, just let me know! I can help brainstorm ideas, crunch numbers, explain complex concepts in plain English, or even write a short poem about the sunset over the Pacific. üåÖ\\n\\nWhat‚Äôs on your mind today? Anything specific you‚Äôd like to explore, or are you just in the mood for a friendly chat?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain  \n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=chat, verbose=True, memory=memory,\n",
    ")\n",
    "\n",
    "conversation.run(\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f468cd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ConversationChain in module langchain.chains.conversation.base object:\n",
      "\n",
      "class ConversationChain(langchain.chains.llm.LLMChain)\n",
      " |  ConversationChain(*args: Any, name: Optional[str] = None, memory: langchain_core.memory.BaseMemory = <factory>, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, verbose: bool = <factory>, tags: Optional[list[str]] = None, metadata: Optional[dict[str, Any]] = None, callback_manager: Optional[langchain_core.callbacks.base.BaseCallbackManager] = None, prompt: langchain_core.prompts.base.BasePromptTemplate = PromptTemplate(input_variables=['history', 'input'], input_types={}, partial_variables={}, template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:'), llm: Union[langchain_core.runnables.base.Runnable[Union[langchain_core.prompt_values.PromptValue, str, collections.abc.Sequence[Union[langchain_core.messages.base.BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]], str], langchain_core.runnables.base.Runnable[Union[langchain_core.prompt_values.PromptValue, str, collections.abc.Sequence[Union[langchain_core.messages.base.BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]], langchain_core.messages.base.BaseMessage]], output_key: str = 'response', output_parser: langchain_core.output_parsers.base.BaseLLMOutputParser = <factory>, return_final_only: bool = True, llm_kwargs: dict = <factory>, input_key: str = 'input') -> None\n",
      " |  \n",
      " |  .. deprecated:: 0.2.7 Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead. It will not be removed until langchain==1.0.\n",
      " |  \n",
      " |  Chain to have a conversation and load context from memory.\n",
      " |  \n",
      " |  This class is deprecated in favor of ``RunnableWithMessageHistory``. Please refer\n",
      " |  to this tutorial for more detail: https://python.langchain.com/docs/tutorials/chatbot/\n",
      " |  \n",
      " |  ``RunnableWithMessageHistory`` offers several benefits, including:\n",
      " |  \n",
      " |  - Stream, batch, and async support;\n",
      " |  - More flexible memory handling, including the ability to manage memory\n",
      " |    outside the chain;\n",
      " |  - Support for multiple threads.\n",
      " |  \n",
      " |  Below is a minimal implementation, analogous to using ``ConversationChain`` with\n",
      " |  the default ``ConversationBufferMemory``:\n",
      " |  \n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          from langchain_core.chat_history import InMemoryChatMessageHistory\n",
      " |          from langchain_core.runnables.history import RunnableWithMessageHistory\n",
      " |          from langchain_openai import ChatOpenAI\n",
      " |  \n",
      " |  \n",
      " |          store = {}  # memory is maintained outside the chain\n",
      " |  \n",
      " |          def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
      " |              if session_id not in store:\n",
      " |                  store[session_id] = InMemoryChatMessageHistory()\n",
      " |              return store[session_id]\n",
      " |  \n",
      " |          llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
      " |  \n",
      " |          chain = RunnableWithMessageHistory(llm, get_session_history)\n",
      " |          chain.invoke(\n",
      " |              \"Hi I'm Bob.\",\n",
      " |              config={\"configurable\": {\"session_id\": \"1\"}},\n",
      " |          )  # session_id determines thread\n",
      " |  Memory objects can also be incorporated into the ``get_session_history`` callable:\n",
      " |  \n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          from langchain.memory import ConversationBufferWindowMemory\n",
      " |          from langchain_core.chat_history import InMemoryChatMessageHistory\n",
      " |          from langchain_core.runnables.history import RunnableWithMessageHistory\n",
      " |          from langchain_openai import ChatOpenAI\n",
      " |  \n",
      " |  \n",
      " |          store = {}  # memory is maintained outside the chain\n",
      " |  \n",
      " |          def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
      " |              if session_id not in store:\n",
      " |                  store[session_id] = InMemoryChatMessageHistory()\n",
      " |                  return store[session_id]\n",
      " |  \n",
      " |              memory = ConversationBufferWindowMemory(\n",
      " |                  chat_memory=store[session_id],\n",
      " |                  k=3,\n",
      " |                  return_messages=True,\n",
      " |              )\n",
      " |              assert len(memory.memory_variables) == 1\n",
      " |              key = memory.memory_variables[0]\n",
      " |              messages = memory.load_memory_variables({})[key]\n",
      " |              store[session_id] = InMemoryChatMessageHistory(messages=messages)\n",
      " |              return store[session_id]\n",
      " |  \n",
      " |          llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
      " |  \n",
      " |          chain = RunnableWithMessageHistory(llm, get_session_history)\n",
      " |          chain.invoke(\n",
      " |              \"Hi I'm Bob.\",\n",
      " |              config={\"configurable\": {\"session_id\": \"1\"}},\n",
      " |          )  # session_id determines thread\n",
      " |  \n",
      " |  Example:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          from langchain.chains import ConversationChain\n",
      " |          from langchain_community.llms import OpenAI\n",
      " |  \n",
      " |          conversation = ConversationChain(llm=OpenAI())\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ConversationChain\n",
      " |      langchain.chains.llm.LLMChain\n",
      " |      langchain.chains.base.Chain\n",
      " |      langchain_core.runnables.base.RunnableSerializable[dict[str, Any], dict[str, Any]]\n",
      " |      langchain_core.runnables.base.RunnableSerializable\n",
      " |      langchain_core.load.serializable.Serializable\n",
      " |      pydantic.main.BaseModel\n",
      " |      langchain_core.runnables.base.Runnable\n",
      " |      abc.ABC\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *args: Any, **kwargs: Any) -> None\n",
      " |  \n",
      " |  validate_prompt_input_variables(self) -> typing_extensions.Self\n",
      " |      Validate that prompt input variables are consistent.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  is_lc_serializable() -> bool from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Is this class serializable?\n",
      " |      \n",
      " |      By design, even if a class inherits from Serializable, it is not serializable by\n",
      " |      default. This is to prevent accidental serialization of objects that should not\n",
      " |      be serialized.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Whether the class is serializable. Default is False.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  input_keys\n",
      " |      Use this since so some prompt vars come from history.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'input_key': <class 'str'>, 'memory': <class 'langc...\n",
      " |  \n",
      " |  __class_vars__ = set()\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  __private_attributes__ = {}\n",
      " |  \n",
      " |  __pydantic_complete__ = True\n",
      " |  \n",
      " |  __pydantic_computed_fields__ = {}\n",
      " |  \n",
      " |  __pydantic_core_schema__ = {'function': {'function': <function Convers...\n",
      " |  \n",
      " |  __pydantic_custom_init__ = True\n",
      " |  \n",
      " |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      " |  \n",
      " |  __pydantic_fields__ = {'callback_manager': FieldInfo(annotation=Union[...\n",
      " |  \n",
      " |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      " |  \n",
      " |  __pydantic_parent_namespace__ = None\n",
      " |  \n",
      " |  __pydantic_post_init__ = None\n",
      " |  \n",
      " |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      " |      Model...\n",
      " |  \n",
      " |  __pydantic_setattr_handlers__ = {}\n",
      " |  \n",
      " |  __pydantic_validator__ = SchemaValidator(title=\"ConversationChain\", va...\n",
      " |  \n",
      " |  __signature__ = <Signature (*args: Any, name: Optional[str] = No...t =...\n",
      " |  \n",
      " |  model_config = {'arbitrary_types_allowed': True, 'extra': 'forbid', 'p...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain.chains.llm.LLMChain:\n",
      " |  \n",
      " |  async aapply(self, input_list: 'list[dict[str, Any]]', callbacks: 'Callbacks' = None) -> 'list[dict[str, str]]'\n",
      " |      Utilize the LLM generate method for speed gains.\n",
      " |  \n",
      " |  async aapply_and_parse(self, input_list: 'list[dict[str, Any]]', callbacks: 'Callbacks' = None) -> 'Sequence[Union[str, list[str], dict[str, str]]]'\n",
      " |      Call apply and then parse the results.\n",
      " |  \n",
      " |  async agenerate(self, input_list: 'list[dict[str, Any]]', run_manager: 'Optional[AsyncCallbackManagerForChainRun]' = None) -> 'LLMResult'\n",
      " |      Generate LLM result from inputs.\n",
      " |  \n",
      " |  apply(self, input_list: 'list[dict[str, Any]]', callbacks: 'Callbacks' = None) -> 'list[dict[str, str]]'\n",
      " |      Utilize the LLM generate method for speed gains.\n",
      " |  \n",
      " |  apply_and_parse(self, input_list: 'list[dict[str, Any]]', callbacks: 'Callbacks' = None) -> 'Sequence[Union[str, list[str], dict[str, str]]]'\n",
      " |      Call apply and then parse the results.\n",
      " |  \n",
      " |  async apredict(self, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'str'\n",
      " |      Format prompt with kwargs and pass to LLM.\n",
      " |      \n",
      " |      Args:\n",
      " |          callbacks: Callbacks to pass to LLMChain\n",
      " |          **kwargs: Keys to pass to prompt template.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Completion from LLM.\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              completion = llm.predict(adjective=\"funny\")\n",
      " |  \n",
      " |  async apredict_and_parse(self, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Union[str, list[str], dict[str, str]]'\n",
      " |      Call apredict and then parse the results.\n",
      " |  \n",
      " |  async aprep_prompts(self, input_list: 'list[dict[str, Any]]', run_manager: 'Optional[AsyncCallbackManagerForChainRun]' = None) -> 'tuple[list[PromptValue], Optional[list[str]]]'\n",
      " |      Prepare prompts from inputs.\n",
      " |  \n",
      " |  create_outputs(self, llm_result: 'LLMResult') -> 'list[dict[str, Any]]'\n",
      " |      Create outputs from response.\n",
      " |  \n",
      " |  generate(self, input_list: 'list[dict[str, Any]]', run_manager: 'Optional[CallbackManagerForChainRun]' = None) -> 'LLMResult'\n",
      " |      Generate LLM result from inputs.\n",
      " |  \n",
      " |  predict(self, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'str'\n",
      " |      Format prompt with kwargs and pass to LLM.\n",
      " |      \n",
      " |      Args:\n",
      " |          callbacks: Callbacks to pass to LLMChain\n",
      " |          **kwargs: Keys to pass to prompt template.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Completion from LLM.\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              completion = llm.predict(adjective=\"funny\")\n",
      " |  \n",
      " |  predict_and_parse(self, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Union[str, list[str], dict[str, Any]]'\n",
      " |      Call predict and then parse the results.\n",
      " |  \n",
      " |  prep_prompts(self, input_list: 'list[dict[str, Any]]', run_manager: 'Optional[CallbackManagerForChainRun]' = None) -> 'tuple[list[PromptValue], Optional[list[str]]]'\n",
      " |      Prepare prompts from inputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain.chains.llm.LLMChain:\n",
      " |  \n",
      " |  from_string(llm: 'BaseLanguageModel', template: 'str') -> 'LLMChain' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Create LLMChain from LLM and template.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain.chains.llm.LLMChain:\n",
      " |  \n",
      " |  output_keys\n",
      " |      Will always return text key.\n",
      " |      \n",
      " |      :meta private:\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain.chains.base.Chain:\n",
      " |  \n",
      " |  __call__(self, inputs: Union[dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[list[str]] = None, metadata: Optional[dict[str, Any]] = None, run_name: Optional[str] = None, include_run_info: bool = False) -> dict\n",
      " |      .. deprecated:: 0.1.0 Use :meth:`~invoke` instead. It will not be removed until langchain==1.0.\n",
      " |      \n",
      " |      Execute the chain.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Dictionary of inputs, or single input if chain expects\n",
      " |              only one param. Should contain all inputs specified in\n",
      " |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      " |              memory.\n",
      " |          return_only_outputs: Whether to return only outputs in the\n",
      " |              response. If True, only new keys generated by this chain will be\n",
      " |              returned. If False, both input keys and new keys generated by this\n",
      " |              chain will be returned. Defaults to False.\n",
      " |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      " |              addition to callbacks passed to the chain during construction, but only\n",
      " |              these runtime callbacks will propagate to calls to other objects.\n",
      " |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      " |              addition to tags passed to the chain during construction, but only\n",
      " |              these runtime tags will propagate to calls to other objects.\n",
      " |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      " |          include_run_info: Whether to include run info in the response. Defaults\n",
      " |              to False.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dict of named outputs. Should contain all outputs specified in\n",
      " |              `Chain.output_keys`.\n",
      " |  \n",
      " |  async acall(self, inputs: Union[dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[list[str]] = None, metadata: Optional[dict[str, Any]] = None, run_name: Optional[str] = None, include_run_info: bool = False) -> dict\n",
      " |      .. deprecated:: 0.1.0 Use :meth:`~ainvoke` instead. It will not be removed until langchain==1.0.\n",
      " |      \n",
      " |      Asynchronously execute the chain.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Dictionary of inputs, or single input if chain expects\n",
      " |              only one param. Should contain all inputs specified in\n",
      " |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      " |              memory.\n",
      " |          return_only_outputs: Whether to return only outputs in the\n",
      " |              response. If True, only new keys generated by this chain will be\n",
      " |              returned. If False, both input keys and new keys generated by this\n",
      " |              chain will be returned. Defaults to False.\n",
      " |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      " |              addition to callbacks passed to the chain during construction, but only\n",
      " |              these runtime callbacks will propagate to calls to other objects.\n",
      " |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      " |              addition to tags passed to the chain during construction, but only\n",
      " |              these runtime tags will propagate to calls to other objects.\n",
      " |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      " |          include_run_info: Whether to include run info in the response. Defaults\n",
      " |              to False.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dict of named outputs. Should contain all outputs specified in\n",
      " |              `Chain.output_keys`.\n",
      " |  \n",
      " |  async ainvoke(self, input: dict, config: Optional[langchain_core.runnables.config.RunnableConfig] = None, **kwargs: Any) -> dict\n",
      " |      Transform a single input into an output.\n",
      " |      \n",
      " |      Args:\n",
      " |          input: The input to the ``Runnable``.\n",
      " |          config: A config to use when invoking the ``Runnable``.\n",
      " |              The config supports standard keys like ``'tags'``, ``'metadata'`` for\n",
      " |              tracing purposes, ``'max_concurrency'`` for controlling how much work to\n",
      " |              do in parallel, and other keys. Please refer to the ``RunnableConfig``\n",
      " |              for more details. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The output of the ``Runnable``.\n",
      " |  \n",
      " |  async aprep_inputs(self, inputs: Union[dict[str, Any], Any]) -> dict\n",
      " |      Prepare chain inputs, including adding inputs from memory.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      " |              only one param. Should contain all inputs specified in\n",
      " |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      " |              memory.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary of all inputs, including those added by the chain's memory.\n",
      " |  \n",
      " |  async aprep_outputs(self, inputs: dict, outputs: dict, return_only_outputs: bool = False) -> dict\n",
      " |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      " |              memory.\n",
      " |          outputs: Dictionary of initial chain outputs.\n",
      " |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      " |              inputs are also added to the final outputs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dict of the final chain outputs.\n",
      " |  \n",
      " |  async arun(self, *args: Any, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[list[str]] = None, metadata: Optional[dict[str, Any]] = None, **kwargs: Any) -> Any\n",
      " |      .. deprecated:: 0.1.0 Use :meth:`~ainvoke` instead. It will not be removed until langchain==1.0.\n",
      " |      \n",
      " |      Convenience method for executing chain.\n",
      " |      \n",
      " |      The main difference between this method and `Chain.__call__` is that this\n",
      " |      method expects inputs to be passed directly in as positional arguments or\n",
      " |      keyword arguments, whereas `Chain.__call__` expects a single input dictionary\n",
      " |      with all the inputs\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |          *args: If the chain expects a single input, it can be passed in as the\n",
      " |              sole positional argument.\n",
      " |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      " |              addition to callbacks passed to the chain during construction, but only\n",
      " |              these runtime callbacks will propagate to calls to other objects.\n",
      " |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      " |              addition to tags passed to the chain during construction, but only\n",
      " |              these runtime tags will propagate to calls to other objects.\n",
      " |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      " |              directly as keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The chain output.\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      " |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      " |              # -> \"The temperature in Boise is...\"\n",
      " |      \n",
      " |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      " |              # and 'context' string:\n",
      " |              question = \"What's the temperature in Boise, Idaho?\"\n",
      " |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      " |              await chain.arun(question=question, context=context)\n",
      " |              # -> \"The temperature in Boise is...\"\n",
      " |  \n",
      " |  dict(self, **kwargs: Any) -> dict\n",
      " |      Dictionary representation of chain.\n",
      " |      \n",
      " |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      " |          null.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      " |              method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary representation of the chain.\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              chain.dict(exclude_unset=True)\n",
      " |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      " |  \n",
      " |  get_input_schema(self, config: Optional[langchain_core.runnables.config.RunnableConfig] = None) -> type\n",
      " |      Get a pydantic model that can be used to validate input to the Runnable.\n",
      " |      \n",
      " |      ``Runnable``s that leverage the ``configurable_fields`` and\n",
      " |      ``configurable_alternatives`` methods will have a dynamic input schema that\n",
      " |      depends on which configuration the ``Runnable`` is invoked with.\n",
      " |      \n",
      " |      This method allows to get an input schema for a specific configuration.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A config to use when generating the schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A pydantic model that can be used to validate input.\n",
      " |  \n",
      " |  get_output_schema(self, config: Optional[langchain_core.runnables.config.RunnableConfig] = None) -> type\n",
      " |      Get a pydantic model that can be used to validate output to the ``Runnable``.\n",
      " |      \n",
      " |      ``Runnable``s that leverage the ``configurable_fields`` and\n",
      " |      ``configurable_alternatives`` methods will have a dynamic output schema that\n",
      " |      depends on which configuration the ``Runnable`` is invoked with.\n",
      " |      \n",
      " |      This method allows to get an output schema for a specific configuration.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A config to use when generating the schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A pydantic model that can be used to validate output.\n",
      " |  \n",
      " |  invoke(self, input: dict, config: Optional[langchain_core.runnables.config.RunnableConfig] = None, **kwargs: Any) -> dict\n",
      " |      Transform a single input into an output.\n",
      " |      \n",
      " |      Args:\n",
      " |          input: The input to the ``Runnable``.\n",
      " |          config: A config to use when invoking the ``Runnable``.\n",
      " |              The config supports standard keys like ``'tags'``, ``'metadata'`` for\n",
      " |              tracing purposes, ``'max_concurrency'`` for controlling how much work to\n",
      " |              do in parallel, and other keys. Please refer to the ``RunnableConfig``\n",
      " |              for more details. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The output of the ``Runnable``.\n",
      " |  \n",
      " |  prep_inputs(self, inputs: Union[dict[str, Any], Any]) -> dict\n",
      " |      Prepare chain inputs, including adding inputs from memory.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      " |              only one param. Should contain all inputs specified in\n",
      " |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      " |              memory.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary of all inputs, including those added by the chain's memory.\n",
      " |  \n",
      " |  prep_outputs(self, inputs: dict, outputs: dict, return_only_outputs: bool = False) -> dict\n",
      " |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      " |              memory.\n",
      " |          outputs: Dictionary of initial chain outputs.\n",
      " |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      " |              inputs are also added to the final outputs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dict of the final chain outputs.\n",
      " |  \n",
      " |  run(self, *args: Any, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[list[str]] = None, metadata: Optional[dict[str, Any]] = None, **kwargs: Any) -> Any\n",
      " |      .. deprecated:: 0.1.0 Use :meth:`~invoke` instead. It will not be removed until langchain==1.0.\n",
      " |      \n",
      " |      Convenience method for executing chain.\n",
      " |      \n",
      " |      The main difference between this method and `Chain.__call__` is that this\n",
      " |      method expects inputs to be passed directly in as positional arguments or\n",
      " |      keyword arguments, whereas `Chain.__call__` expects a single input dictionary\n",
      " |      with all the inputs\n",
      " |      \n",
      " |      Args:\n",
      " |          *args: If the chain expects a single input, it can be passed in as the\n",
      " |              sole positional argument.\n",
      " |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      " |              addition to callbacks passed to the chain during construction, but only\n",
      " |              these runtime callbacks will propagate to calls to other objects.\n",
      " |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      " |              addition to tags passed to the chain during construction, but only\n",
      " |              these runtime tags will propagate to calls to other objects.\n",
      " |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      " |              directly as keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The chain output.\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      " |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      " |              # -> \"The temperature in Boise is...\"\n",
      " |      \n",
      " |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      " |              # and 'context' string:\n",
      " |              question = \"What's the temperature in Boise, Idaho?\"\n",
      " |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      " |              chain.run(question=question, context=context)\n",
      " |              # -> \"The temperature in Boise is...\"\n",
      " |  \n",
      " |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      " |      Save the chain.\n",
      " |      \n",
      " |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      " |          null.\n",
      " |      \n",
      " |      Args:\n",
      " |          file_path: Path to file to save the chain to.\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              chain.save(file_path=\"path/chain.yaml\")\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain.chains.base.Chain:\n",
      " |  \n",
      " |  raise_callback_manager_deprecation(values: dict) -> Any from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Raise deprecation warning if callback_manager is used.\n",
      " |  \n",
      " |  set_verbose(verbose: Optional[bool]) -> bool from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Set the chain verbosity.\n",
      " |      \n",
      " |      Defaults to the global setting if not specified by the user.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.runnables.base.RunnableSerializable:\n",
      " |  \n",
      " |  configurable_alternatives(self, which: 'ConfigurableField', *, default_key: 'str' = 'default', prefix_keys: 'bool' = False, **kwargs: 'Union[Runnable[Input, Output], Callable[[], Runnable[Input, Output]]]') -> 'RunnableSerializable[Input, Output]'\n",
      " |      Configure alternatives for ``Runnables`` that can be set at runtime.\n",
      " |      \n",
      " |      Args:\n",
      " |          which: The ``ConfigurableField`` instance that will be used to select the\n",
      " |              alternative.\n",
      " |          default_key: The default key to use if no alternative is selected.\n",
      " |              Defaults to ``'default'``.\n",
      " |          prefix_keys: Whether to prefix the keys with the ``ConfigurableField`` id.\n",
      " |              Defaults to False.\n",
      " |          **kwargs: A dictionary of keys to ``Runnable`` instances or callables that\n",
      " |              return ``Runnable`` instances.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable`` with the alternatives configured.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from langchain_anthropic import ChatAnthropic\n",
      " |          from langchain_core.runnables.utils import ConfigurableField\n",
      " |          from langchain_openai import ChatOpenAI\n",
      " |      \n",
      " |          model = ChatAnthropic(\n",
      " |              model_name=\"claude-3-7-sonnet-20250219\"\n",
      " |          ).configurable_alternatives(\n",
      " |              ConfigurableField(id=\"llm\"),\n",
      " |              default_key=\"anthropic\",\n",
      " |              openai=ChatOpenAI(),\n",
      " |          )\n",
      " |      \n",
      " |          # uses the default model ChatAnthropic\n",
      " |          print(model.invoke(\"which organization created you?\").content)\n",
      " |      \n",
      " |          # uses ChatOpenAI\n",
      " |          print(\n",
      " |              model.with_config(configurable={\"llm\": \"openai\"})\n",
      " |              .invoke(\"which organization created you?\")\n",
      " |              .content\n",
      " |          )\n",
      " |  \n",
      " |  configurable_fields(self, **kwargs: 'AnyConfigurableField') -> 'RunnableSerializable[Input, Output]'\n",
      " |      Configure particular ``Runnable`` fields at runtime.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: A dictionary of ``ConfigurableField`` instances to configure.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If a configuration key is not found in the ``Runnable``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable`` with the fields configured.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from langchain_core.runnables import ConfigurableField\n",
      " |          from langchain_openai import ChatOpenAI\n",
      " |      \n",
      " |          model = ChatOpenAI(max_tokens=20).configurable_fields(\n",
      " |              max_tokens=ConfigurableField(\n",
      " |                  id=\"output_token_number\",\n",
      " |                  name=\"Max tokens in the output\",\n",
      " |                  description=\"The maximum number of tokens in the output\",\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |          # max_tokens = 20\n",
      " |          print(\n",
      " |              \"max_tokens_20: \", model.invoke(\"tell me something about chess\").content\n",
      " |          )\n",
      " |      \n",
      " |          # max_tokens = 200\n",
      " |          print(\n",
      " |              \"max_tokens_200: \",\n",
      " |              model.with_config(configurable={\"output_token_number\": 200})\n",
      " |              .invoke(\"tell me something about chess\")\n",
      " |              .content,\n",
      " |          )\n",
      " |  \n",
      " |  to_json(self) -> 'Union[SerializedConstructor, SerializedNotImplemented]'\n",
      " |      Serialize the ``Runnable`` to JSON.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON-serializable representation of the ``Runnable``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from langchain_core.runnables.base.RunnableSerializable:\n",
      " |  \n",
      " |  __orig_bases__ = (<class 'langchain_core.load.serializable.Serializabl...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  __repr_args__(self) -> Any\n",
      " |  \n",
      " |  to_json_not_implemented(self) -> langchain_core.load.serializable.SerializedNotImplemented\n",
      " |      Serialize a \"not implemented\" object.\n",
      " |      \n",
      " |      Returns:\n",
      " |          SerializedNotImplemented.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  get_lc_namespace() -> list from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Get the namespace of the langchain object.\n",
      " |      \n",
      " |      For example, if the class is `langchain.llms.openai.OpenAI`, then the\n",
      " |      namespace is [\"langchain\", \"llms\", \"openai\"]\n",
      " |      \n",
      " |      Returns:\n",
      " |          The namespace as a list of strings.\n",
      " |  \n",
      " |  lc_id() -> list from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Return a unique identifier for this class for serialization purposes.\n",
      " |      \n",
      " |      The unique identifier is a list of strings that describes the path\n",
      " |      to the object.\n",
      " |      For example, for the class `langchain.llms.openai.OpenAI`, the id is\n",
      " |      [\"langchain\", \"llms\", \"openai\", \"OpenAI\"].\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  lc_attributes\n",
      " |      List of attribute names that should be included in the serialized kwargs.\n",
      " |      \n",
      " |      These attributes must be accepted by the constructor.\n",
      " |      Default is an empty dictionary.\n",
      " |  \n",
      " |  lc_secrets\n",
      " |      A map of constructor argument names to secret ids.\n",
      " |      \n",
      " |      For example,\n",
      " |          {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __copy__(self) -> 'Self'\n",
      " |      Returns a shallow copy of the model.\n",
      " |  \n",
      " |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      " |      Returns a deep copy of the model.\n",
      " |  \n",
      " |  __delattr__(self, item: 'str') -> 'Any'\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __eq__(self, other: 'Any') -> 'bool'\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getattr__(self, item: 'str') -> 'Any'\n",
      " |  \n",
      " |  __getstate__(self) -> 'dict[Any, Any]'\n",
      " |  \n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      So `dict(model)` works.\n",
      " |  \n",
      " |  __pretty__(self, fmt: 'Callable[[Any], Any]', **kwargs: 'Any') -> 'Generator[Any]'\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      " |  \n",
      " |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      " |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      " |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __repr_name__(self) -> 'str'\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |  \n",
      " |  __repr_recursion__(self, object: 'Any') -> 'str'\n",
      " |      Returns the string representation of a recursive object.\n",
      " |  \n",
      " |  __repr_str__(self, join_str: 'str') -> 'str'\n",
      " |  \n",
      " |  __rich_repr__(self) -> 'RichReprResult'\n",
      " |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      " |  \n",
      " |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      " |  \n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      " |      Returns a copy of the model.\n",
      " |      \n",
      " |      !!! warning \"Deprecated\"\n",
      " |          This method is now deprecated; use `model_copy` instead.\n",
      " |      \n",
      " |      If you need `include` or `exclude`, use:\n",
      " |      \n",
      " |      ```python {test=\"skip\" lint=\"skip\"}\n",
      " |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      " |      data = {**data, **(update or {})}\n",
      " |      copied = self.model_validate(data)\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      " |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      " |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      " |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A copy of the model with included, excluded and updated fields as specified.\n",
      " |  \n",
      " |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      " |  \n",
      " |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [`model_copy`](../concepts/models.md#model-copy)\n",
      " |      \n",
      " |      Returns a copy of the model.\n",
      " |      \n",
      " |      !!! note\n",
      " |          The underlying instance's [`__dict__`][object.__dict__] attribute is copied. This\n",
      " |          might have unexpected side effects if you store anything in it, on top of the model\n",
      " |          fields (e.g. the value of [cached properties][functools.cached_property]).\n",
      " |      \n",
      " |      Args:\n",
      " |          update: Values to change/add in the new model. Note: the data is not validated\n",
      " |              before creating the new model. You should trust this data.\n",
      " |          deep: Set to `True` to make a deep copy of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          New model instance.\n",
      " |  \n",
      " |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, exclude_computed_fields: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, fallback: 'Callable[[Any], Any] | None' = None, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [`model_dump`](../concepts/serialization.md#python-mode)\n",
      " |      \n",
      " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode: The mode in which `to_python` should run.\n",
      " |              If mode is 'json', the output will only contain JSON serializable types.\n",
      " |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      " |          include: A set of fields to include in the output.\n",
      " |          exclude: A set of fields to exclude from the output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          exclude_computed_fields: Whether to exclude computed fields.\n",
      " |              While this can be useful for round-tripping, it is usually recommended to use the dedicated\n",
      " |              `round_trip` parameter instead.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          fallback: A function to call when an unknown value is encountered. If not provided,\n",
      " |              a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError] error is raised.\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary representation of the model.\n",
      " |  \n",
      " |  model_dump_json(self, *, indent: 'int | None' = None, ensure_ascii: 'bool' = False, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, exclude_computed_fields: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, fallback: 'Callable[[Any], Any] | None' = None, serialize_as_any: 'bool' = False) -> 'str'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [`model_dump_json`](../concepts/serialization.md#json-mode)\n",
      " |      \n",
      " |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      " |      \n",
      " |      Args:\n",
      " |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      " |          ensure_ascii: If `True`, the output is guaranteed to have all incoming non-ASCII characters escaped.\n",
      " |              If `False` (the default), these characters will be output as-is.\n",
      " |          include: Field(s) to include in the JSON output.\n",
      " |          exclude: Field(s) to exclude from the JSON output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to serialize using field aliases.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          exclude_computed_fields: Whether to exclude computed fields.\n",
      " |              While this can be useful for round-tripping, it is usually recommended to use the dedicated\n",
      " |              `round_trip` parameter instead.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          fallback: A function to call when an unknown value is encountered. If not provided,\n",
      " |              a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError] error is raised.\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string representation of the model.\n",
      " |  \n",
      " |  model_post_init(self, context: 'Any', /) -> 'None'\n",
      " |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      " |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Hook into generating the model's JSON schema.\n",
      " |      \n",
      " |      Args:\n",
      " |          core_schema: A `pydantic-core` CoreSchema.\n",
      " |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      " |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      " |              or just call the handler with the original schema.\n",
      " |          handler: Call into Pydantic's internal JSON schema generation.\n",
      " |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      " |              generation fails.\n",
      " |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      " |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      " |              for a type.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON schema, as a Python object.\n",
      " |  \n",
      " |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      " |      only after basic class initialization is complete. In particular, attributes like `model_fields` will\n",
      " |      be present when this is called, but forward annotations are not guaranteed to be resolved yet,\n",
      " |      meaning that creating an instance of the class may fail.\n",
      " |      \n",
      " |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      " |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      " |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      " |      \n",
      " |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      " |      any kwargs passed to the class definition that aren't used internally by Pydantic.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      " |              by Pydantic.\n",
      " |      \n",
      " |      Note:\n",
      " |          You may want to override [`__pydantic_on_complete__()`][pydantic.main.BaseModel.__pydantic_on_complete__]\n",
      " |          instead, which is called once the class and its fields are fully initialized and ready for validation.\n",
      " |  \n",
      " |  __pydantic_on_complete__() -> 'None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      This is called once the class and its fields are fully initialized and ready to be used.\n",
      " |      \n",
      " |      This typically happens when the class is created (just before\n",
      " |      [`__pydantic_init_subclass__()`][pydantic.main.BaseModel.__pydantic_init_subclass__] is called on the superclass),\n",
      " |      except when forward annotations are used that could not immediately be resolved.\n",
      " |      In that case, it will be called later, when the model is rebuilt automatically or explicitly using\n",
      " |      [`model_rebuild()`][pydantic.main.BaseModel.model_rebuild].\n",
      " |  \n",
      " |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  from_orm(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Creates a new instance of the `Model` class with validated data.\n",
      " |      \n",
      " |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |      \n",
      " |      !!! note\n",
      " |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      " |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      " |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      " |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      " |          an error if extra values are passed, but they will be ignored.\n",
      " |      \n",
      " |      Args:\n",
      " |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      " |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      " |              Otherwise, the field names from the `values` argument will be used.\n",
      " |          values: Trusted or pre-validated data dictionary.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new instance of the `Model` class with validated data.\n",
      " |  \n",
      " |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation', *, union_format: \"Literal['any_of', 'primitive_type_array']\" = 'any_of') -> 'dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Generates a JSON schema for a model class.\n",
      " |      \n",
      " |      Args:\n",
      " |          by_alias: Whether to use attribute aliases or not.\n",
      " |          ref_template: The reference template.\n",
      " |          union_format: The format to use when combining schemas from unions together. Can be one of:\n",
      " |      \n",
      " |              - `'any_of'`: Use the [`anyOf`](https://json-schema.org/understanding-json-schema/reference/combining#anyOf)\n",
      " |              keyword to combine schemas (the default).\n",
      " |              - `'primitive_type_array'`: Use the [`type`](https://json-schema.org/understanding-json-schema/reference/type)\n",
      " |              keyword as an array of strings, containing each type of the combination. If any of the schemas is not a primitive\n",
      " |              type (`string`, `boolean`, `null`, `integer` or `number`) or contains constraints/metadata, falls back to\n",
      " |              `any_of`.\n",
      " |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      " |              `GenerateJsonSchema` with your desired modifications\n",
      " |          mode: The mode in which to generate the schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The JSON schema for the given model class.\n",
      " |  \n",
      " |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Compute the class name for parametrizations of generic classes.\n",
      " |      \n",
      " |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      " |      \n",
      " |      Args:\n",
      " |          params: Tuple of types of the class. Given a generic class\n",
      " |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      " |              the value `(str, int)` would be passed to `params`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      " |  \n",
      " |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Try to rebuild the pydantic-core schema for the model.\n",
      " |      \n",
      " |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      " |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      " |      \n",
      " |      Args:\n",
      " |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      " |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      " |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      " |          _types_namespace: The types namespace, defaults to `None`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      " |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      " |  \n",
      " |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, extra: 'ExtraValues | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Validate a pydantic model instance.\n",
      " |      \n",
      " |      Args:\n",
      " |          obj: The object to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          extra: Whether to ignore, allow, or forbid extra data during model validation.\n",
      " |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.\n",
      " |          from_attributes: Whether to extract data from object attributes.\n",
      " |          context: Additional context to pass to the validator.\n",
      " |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      " |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValidationError: If the object could not be validated.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The validated model instance.\n",
      " |  \n",
      " |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, extra: 'ExtraValues | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [JSON Parsing](../concepts/json.md#json-parsing)\n",
      " |      \n",
      " |      Validate the given JSON data against the Pydantic model.\n",
      " |      \n",
      " |      Args:\n",
      " |          json_data: The JSON data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          extra: Whether to ignore, allow, or forbid extra data during model validation.\n",
      " |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      " |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      " |  \n",
      " |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, extra: 'ExtraValues | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Validate the given object with string data against the Pydantic model.\n",
      " |      \n",
      " |      Args:\n",
      " |          obj: The object containing string data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          extra: Whether to ignore, allow, or forbid extra data during model validation.\n",
      " |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      " |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |  \n",
      " |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  parse_obj(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  update_forward_refs(**localns: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  validate(value: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __fields_set__\n",
      " |  \n",
      " |  model_extra\n",
      " |      Get extra fields set during validation.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      " |  \n",
      " |  model_fields_set\n",
      " |      Returns the set of fields that have been explicitly set on this model instance.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A set of strings representing the fields that have been set,\n",
      " |              i.e. that were not filled from defaults.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __pydantic_extra__\n",
      " |  \n",
      " |  __pydantic_fields_set__\n",
      " |  \n",
      " |  __pydantic_private__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __pydantic_root_model__ = False\n",
      " |  \n",
      " |  model_computed_fields = {}\n",
      " |  \n",
      " |  model_fields = {'callback_manager': FieldInfo(annotation=Union[BaseCal...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.runnables.base.Runnable:\n",
      " |  \n",
      " |  __or__(self, other: 'Union[Runnable[Any, Other], Callable[[Iterator[Any]], Iterator[Other]], Callable[[AsyncIterator[Any]], AsyncIterator[Other]], Callable[[Any], Other], Mapping[str, Union[Runnable[Any, Other], Callable[[Any], Other], Any]]]') -> 'RunnableSerializable[Input, Other]'\n",
      " |      Runnable \"or\" operator.\n",
      " |      \n",
      " |      Compose this ``Runnable`` with another object to create a\n",
      " |      ``RunnableSequence``.\n",
      " |      \n",
      " |      Args:\n",
      " |          other: Another ``Runnable`` or a ``Runnable``-like object.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable``.\n",
      " |  \n",
      " |  __ror__(self, other: 'Union[Runnable[Other, Any], Callable[[Iterator[Other]], Iterator[Any]], Callable[[AsyncIterator[Other]], AsyncIterator[Any]], Callable[[Other], Any], Mapping[str, Union[Runnable[Other, Any], Callable[[Other], Any], Any]]]') -> 'RunnableSerializable[Other, Output]'\n",
      " |      Runnable \"reverse-or\" operator.\n",
      " |      \n",
      " |      Compose this ``Runnable`` with another object to create a\n",
      " |      ``RunnableSequence``.\n",
      " |      \n",
      " |      Args:\n",
      " |          other: Another ``Runnable`` or a ``Runnable``-like object.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable``.\n",
      " |  \n",
      " |  async abatch(self, inputs: 'list[Input]', config: 'Optional[Union[RunnableConfig, list[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'list[Output]'\n",
      " |      Default implementation runs ``ainvoke`` in parallel using ``asyncio.gather``.\n",
      " |      \n",
      " |      The default implementation of ``batch`` works well for IO bound runnables.\n",
      " |      \n",
      " |      Subclasses should override this method if they can batch more efficiently;\n",
      " |      e.g., if the underlying ``Runnable`` uses an API which supports a batch mode.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: A list of inputs to the ``Runnable``.\n",
      " |          config: A config to use when invoking the ``Runnable``.\n",
      " |              The config supports standard keys like ``'tags'``, ``'metadata'`` for\n",
      " |              tracing purposes, ``'max_concurrency'`` for controlling how much work to\n",
      " |              do in parallel, and other keys. Please refer to the ``RunnableConfig``\n",
      " |              for more details. Defaults to None.\n",
      " |          return_exceptions: Whether to return exceptions instead of raising them.\n",
      " |              Defaults to False.\n",
      " |          **kwargs: Additional keyword arguments to pass to the ``Runnable``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of outputs from the ``Runnable``.\n",
      " |  \n",
      " |  async abatch_as_completed(self, inputs: 'Sequence[Input]', config: 'Optional[Union[RunnableConfig, Sequence[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'AsyncIterator[tuple[int, Union[Output, Exception]]]'\n",
      " |      Run ``ainvoke`` in parallel on a list of inputs.\n",
      " |      \n",
      " |      Yields results as they complete.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: A list of inputs to the ``Runnable``.\n",
      " |          config: A config to use when invoking the ``Runnable``.\n",
      " |              The config supports standard keys like ``'tags'``, ``'metadata'`` for\n",
      " |              tracing purposes, ``'max_concurrency'`` for controlling how much work to\n",
      " |              do in parallel, and other keys. Please refer to the ``RunnableConfig``\n",
      " |              for more details. Defaults to None.\n",
      " |          return_exceptions: Whether to return exceptions instead of raising them.\n",
      " |              Defaults to False.\n",
      " |          kwargs: Additional keyword arguments to pass to the ``Runnable``.\n",
      " |      \n",
      " |      Yields:\n",
      " |          A tuple of the index of the input and the output from the ``Runnable``.\n",
      " |  \n",
      " |  as_tool(self, args_schema: 'Optional[type[BaseModel]]' = None, *, name: 'Optional[str]' = None, description: 'Optional[str]' = None, arg_types: 'Optional[dict[str, type]]' = None) -> 'BaseTool'\n",
      " |      .. beta::\n",
      " |         This API is in beta and may change in the future.\n",
      " |      \n",
      " |      Create a ``BaseTool`` from a ``Runnable``.\n",
      " |      \n",
      " |      ``as_tool`` will instantiate a ``BaseTool`` with a name, description, and\n",
      " |      ``args_schema`` from a ``Runnable``. Where possible, schemas are inferred\n",
      " |      from ``runnable.get_input_schema``. Alternatively (e.g., if the\n",
      " |      ``Runnable`` takes a dict as input and the specific dict keys are not typed),\n",
      " |      the schema can be specified directly with ``args_schema``. You can also\n",
      " |      pass ``arg_types`` to just specify the required arguments and their types.\n",
      " |      \n",
      " |      Args:\n",
      " |          args_schema: The schema for the tool. Defaults to None.\n",
      " |          name: The name of the tool. Defaults to None.\n",
      " |          description: The description of the tool. Defaults to None.\n",
      " |          arg_types: A dictionary of argument names to types. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A ``BaseTool`` instance.\n",
      " |      \n",
      " |      Typed dict input:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from typing_extensions import TypedDict\n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |      \n",
      " |      \n",
      " |          class Args(TypedDict):\n",
      " |              a: int\n",
      " |              b: list[int]\n",
      " |      \n",
      " |      \n",
      " |          def f(x: Args) -> str:\n",
      " |              return str(x[\"a\"] * max(x[\"b\"]))\n",
      " |      \n",
      " |      \n",
      " |          runnable = RunnableLambda(f)\n",
      " |          as_tool = runnable.as_tool()\n",
      " |          as_tool.invoke({\"a\": 3, \"b\": [1, 2]})\n",
      " |      \n",
      " |      ``dict`` input, specifying schema via ``args_schema``:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from typing import Any\n",
      " |          from pydantic import BaseModel, Field\n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |      \n",
      " |          def f(x: dict[str, Any]) -> str:\n",
      " |              return str(x[\"a\"] * max(x[\"b\"]))\n",
      " |      \n",
      " |          class FSchema(BaseModel):\n",
      " |              \"\"\"Apply a function to an integer and list of integers.\"\"\"\n",
      " |      \n",
      " |              a: int = Field(..., description=\"Integer\")\n",
      " |              b: list[int] = Field(..., description=\"List of ints\")\n",
      " |      \n",
      " |          runnable = RunnableLambda(f)\n",
      " |          as_tool = runnable.as_tool(FSchema)\n",
      " |          as_tool.invoke({\"a\": 3, \"b\": [1, 2]})\n",
      " |      \n",
      " |      ``dict`` input, specifying schema via ``arg_types``:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from typing import Any\n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |      \n",
      " |      \n",
      " |          def f(x: dict[str, Any]) -> str:\n",
      " |              return str(x[\"a\"] * max(x[\"b\"]))\n",
      " |      \n",
      " |      \n",
      " |          runnable = RunnableLambda(f)\n",
      " |          as_tool = runnable.as_tool(arg_types={\"a\": int, \"b\": list[int]})\n",
      " |          as_tool.invoke({\"a\": 3, \"b\": [1, 2]})\n",
      " |      \n",
      " |      String input:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |      \n",
      " |      \n",
      " |          def f(x: str) -> str:\n",
      " |              return x + \"a\"\n",
      " |      \n",
      " |      \n",
      " |          def g(x: str) -> str:\n",
      " |              return x + \"z\"\n",
      " |      \n",
      " |      \n",
      " |          runnable = RunnableLambda(f) | g\n",
      " |          as_tool = runnable.as_tool()\n",
      " |          as_tool.invoke(\"b\")\n",
      " |      \n",
      " |      .. versionadded:: 0.2.14\n",
      " |  \n",
      " |  assign(self, **kwargs: 'Union[Runnable[dict[str, Any], Any], Callable[[dict[str, Any]], Any], Mapping[str, Union[Runnable[dict[str, Any], Any], Callable[[dict[str, Any]], Any]]]]') -> 'RunnableSerializable[Any, Any]'\n",
      " |      Assigns new fields to the dict output of this ``Runnable``.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from langchain_community.llms.fake import FakeStreamingListLLM\n",
      " |          from langchain_core.output_parsers import StrOutputParser\n",
      " |          from langchain_core.prompts import SystemMessagePromptTemplate\n",
      " |          from langchain_core.runnables import Runnable\n",
      " |          from operator import itemgetter\n",
      " |      \n",
      " |          prompt = (\n",
      " |              SystemMessagePromptTemplate.from_template(\"You are a nice assistant.\")\n",
      " |              + \"{question}\"\n",
      " |          )\n",
      " |          llm = FakeStreamingListLLM(responses=[\"foo-lish\"])\n",
      " |      \n",
      " |          chain: Runnable = prompt | llm | {\"str\": StrOutputParser()}\n",
      " |      \n",
      " |          chain_with_assign = chain.assign(hello=itemgetter(\"str\") | llm)\n",
      " |      \n",
      " |          print(chain_with_assign.input_schema.model_json_schema())\n",
      " |          # {'title': 'PromptInput', 'type': 'object', 'properties':\n",
      " |          {'question': {'title': 'Question', 'type': 'string'}}}\n",
      " |          print(chain_with_assign.output_schema.model_json_schema())\n",
      " |          # {'title': 'RunnableSequenceOutput', 'type': 'object', 'properties':\n",
      " |          {'str': {'title': 'Str',\n",
      " |          'type': 'string'}, 'hello': {'title': 'Hello', 'type': 'string'}}}\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: A mapping of keys to ``Runnable`` or ``Runnable``-like objects\n",
      " |              that will be invoked with the entire output dict of this ``Runnable``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable``.\n",
      " |  \n",
      " |  async astream(self, input: 'Input', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'AsyncIterator[Output]'\n",
      " |      Default implementation of ``astream``, which calls ``ainvoke``.\n",
      " |      \n",
      " |      Subclasses should override this method if they support streaming output.\n",
      " |      \n",
      " |      Args:\n",
      " |          input: The input to the ``Runnable``.\n",
      " |          config: The config to use for the ``Runnable``. Defaults to None.\n",
      " |          kwargs: Additional keyword arguments to pass to the ``Runnable``.\n",
      " |      \n",
      " |      Yields:\n",
      " |          The output of the ``Runnable``.\n",
      " |  \n",
      " |  async astream_events(self, input: 'Any', config: 'Optional[RunnableConfig]' = None, *, version: \"Literal['v1', 'v2']\" = 'v2', include_names: 'Optional[Sequence[str]]' = None, include_types: 'Optional[Sequence[str]]' = None, include_tags: 'Optional[Sequence[str]]' = None, exclude_names: 'Optional[Sequence[str]]' = None, exclude_types: 'Optional[Sequence[str]]' = None, exclude_tags: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'AsyncIterator[StreamEvent]'\n",
      " |      Generate a stream of events.\n",
      " |      \n",
      " |      Use to create an iterator over ``StreamEvents`` that provide real-time information\n",
      " |      about the progress of the ``Runnable``, including ``StreamEvents`` from intermediate\n",
      " |      results.\n",
      " |      \n",
      " |      A ``StreamEvent`` is a dictionary with the following schema:\n",
      " |      \n",
      " |      - ``event``: **str** - Event names are of the format:\n",
      " |        ``on_[runnable_type]_(start|stream|end)``.\n",
      " |      - ``name``: **str** - The name of the ``Runnable`` that generated the event.\n",
      " |      - ``run_id``: **str** - randomly generated ID associated with the given\n",
      " |        execution of the ``Runnable`` that emitted the event. A child ``Runnable`` that gets\n",
      " |        invoked as part of the execution of a parent ``Runnable`` is assigned its own\n",
      " |        unique ID.\n",
      " |      - ``parent_ids``: **list[str]** - The IDs of the parent runnables that generated\n",
      " |        the event. The root ``Runnable`` will have an empty list. The order of the parent\n",
      " |        IDs is from the root to the immediate parent. Only available for v2 version of\n",
      " |        the API. The v1 version of the API will return an empty list.\n",
      " |      - ``tags``: **Optional[list[str]]** - The tags of the ``Runnable`` that generated\n",
      " |        the event.\n",
      " |      - ``metadata``: **Optional[dict[str, Any]]** - The metadata of the ``Runnable`` that\n",
      " |        generated the event.\n",
      " |      - ``data``: **dict[str, Any]**\n",
      " |      \n",
      " |      Below is a table that illustrates some events that might be emitted by various\n",
      " |      chains. Metadata fields have been omitted from the table for brevity.\n",
      " |      Chain definitions have been included after the table.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This reference table is for the v2 version of the schema.\n",
      " |      \n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | event                    | name             | chunk                               | input                                             | output                                              |\n",
      " |      +==========================+==================+=====================================+===================================================+=====================================================+\n",
      " |      | ``on_chat_model_start``  | [model name]     |                                     | ``{\"messages\": [[SystemMessage, HumanMessage]]}`` |                                                     |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_chat_model_stream`` | [model name]     | ``AIMessageChunk(content=\"hello\")`` |                                                   |                                                     |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_chat_model_end``    | [model name]     |                                     | ``{\"messages\": [[SystemMessage, HumanMessage]]}`` | ``AIMessageChunk(content=\"hello world\")``           |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_llm_start``         | [model name]     |                                     | ``{'input': 'hello'}``                            |                                                     |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_llm_stream``        | [model name]     | ``'Hello' ``                        |                                                   |                                                     |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_llm_end``           | [model name]     |                                     | ``'Hello human!'``                                |                                                     |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_chain_start``       | format_docs      |                                     |                                                   |                                                     |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_chain_stream``      | format_docs      | ``'hello world!, goodbye world!'``  |                                                   |                                                     |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_chain_end``         | format_docs      |                                     | ``[Document(...)]``                               | ``'hello world!, goodbye world!'``                  |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_tool_start``        | some_tool        |                                     | ``{\"x\": 1, \"y\": \"2\"}``                            |                                                     |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_tool_end``          | some_tool        |                                     |                                                   | ``{\"x\": 1, \"y\": \"2\"}``                              |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_retriever_start``   | [retriever name] |                                     | ``{\"query\": \"hello\"}``                            |                                                     |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_retriever_end``     | [retriever name] |                                     | ``{\"query\": \"hello\"}``                            | ``[Document(...), ..]``                             |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_prompt_start``      | [template_name]  |                                     | ``{\"question\": \"hello\"}``                         |                                                     |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      | ``on_prompt_end``        | [template_name]  |                                     | ``{\"question\": \"hello\"}``                         | ``ChatPromptValue(messages: [SystemMessage, ...])`` |\n",
      " |      +--------------------------+------------------+-------------------------------------+---------------------------------------------------+-----------------------------------------------------+\n",
      " |      \n",
      " |      In addition to the standard events, users can also dispatch custom events (see example below).\n",
      " |      \n",
      " |      Custom events will be only be surfaced with in the v2 version of the API!\n",
      " |      \n",
      " |      A custom event has following format:\n",
      " |      \n",
      " |      +-----------+------+-----------------------------------------------------------------------------------------------------------+\n",
      " |      | Attribute | Type | Description                                                                                               |\n",
      " |      +===========+======+===========================================================================================================+\n",
      " |      | name      | str  | A user defined name for the event.                                                                        |\n",
      " |      +-----------+------+-----------------------------------------------------------------------------------------------------------+\n",
      " |      | data      | Any  | The data associated with the event. This can be anything, though we suggest making it JSON serializable.  |\n",
      " |      +-----------+------+-----------------------------------------------------------------------------------------------------------+\n",
      " |      \n",
      " |      Here are declarations associated with the standard events shown above:\n",
      " |      \n",
      " |      ``format_docs``:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          def format_docs(docs: list[Document]) -> str:\n",
      " |              '''Format the docs.'''\n",
      " |              return \", \".join([doc.page_content for doc in docs])\n",
      " |      \n",
      " |      \n",
      " |          format_docs = RunnableLambda(format_docs)\n",
      " |      \n",
      " |      ``some_tool``:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          @tool\n",
      " |          def some_tool(x: int, y: str) -> dict:\n",
      " |              '''Some_tool.'''\n",
      " |              return {\"x\": x, \"y\": y}\n",
      " |      \n",
      " |      ``prompt``:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          template = ChatPromptTemplate.from_messages(\n",
      " |              [\n",
      " |                  (\"system\", \"You are Cat Agent 007\"),\n",
      " |                  (\"human\", \"{question}\"),\n",
      " |              ]\n",
      " |          ).with_config({\"run_name\": \"my_template\", \"tags\": [\"my_template\"]})\n",
      " |      \n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |      \n",
      " |      \n",
      " |          async def reverse(s: str) -> str:\n",
      " |              return s[::-1]\n",
      " |      \n",
      " |      \n",
      " |          chain = RunnableLambda(func=reverse)\n",
      " |      \n",
      " |          events = [\n",
      " |              event async for event in chain.astream_events(\"hello\", version=\"v2\")\n",
      " |          ]\n",
      " |      \n",
      " |          # will produce the following events (run_id, and parent_ids\n",
      " |          # has been omitted for brevity):\n",
      " |          [\n",
      " |              {\n",
      " |                  \"data\": {\"input\": \"hello\"},\n",
      " |                  \"event\": \"on_chain_start\",\n",
      " |                  \"metadata\": {},\n",
      " |                  \"name\": \"reverse\",\n",
      " |                  \"tags\": [],\n",
      " |              },\n",
      " |              {\n",
      " |                  \"data\": {\"chunk\": \"olleh\"},\n",
      " |                  \"event\": \"on_chain_stream\",\n",
      " |                  \"metadata\": {},\n",
      " |                  \"name\": \"reverse\",\n",
      " |                  \"tags\": [],\n",
      " |              },\n",
      " |              {\n",
      " |                  \"data\": {\"output\": \"olleh\"},\n",
      " |                  \"event\": \"on_chain_end\",\n",
      " |                  \"metadata\": {},\n",
      " |                  \"name\": \"reverse\",\n",
      " |                  \"tags\": [],\n",
      " |              },\n",
      " |          ]\n",
      " |      \n",
      " |      \n",
      " |      Example: Dispatch Custom Event\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from langchain_core.callbacks.manager import (\n",
      " |              adispatch_custom_event,\n",
      " |          )\n",
      " |          from langchain_core.runnables import RunnableLambda, RunnableConfig\n",
      " |          import asyncio\n",
      " |      \n",
      " |      \n",
      " |          async def slow_thing(some_input: str, config: RunnableConfig) -> str:\n",
      " |              \"\"\"Do something that takes a long time.\"\"\"\n",
      " |              await asyncio.sleep(1) # Placeholder for some slow operation\n",
      " |              await adispatch_custom_event(\n",
      " |                  \"progress_event\",\n",
      " |                  {\"message\": \"Finished step 1 of 3\"},\n",
      " |                  config=config # Must be included for python < 3.10\n",
      " |              )\n",
      " |              await asyncio.sleep(1) # Placeholder for some slow operation\n",
      " |              await adispatch_custom_event(\n",
      " |                  \"progress_event\",\n",
      " |                  {\"message\": \"Finished step 2 of 3\"},\n",
      " |                  config=config # Must be included for python < 3.10\n",
      " |              )\n",
      " |              await asyncio.sleep(1) # Placeholder for some slow operation\n",
      " |              return \"Done\"\n",
      " |      \n",
      " |          slow_thing = RunnableLambda(slow_thing)\n",
      " |      \n",
      " |          async for event in slow_thing.astream_events(\"some_input\", version=\"v2\"):\n",
      " |              print(event)\n",
      " |      \n",
      " |      Args:\n",
      " |          input: The input to the ``Runnable``.\n",
      " |          config: The config to use for the ``Runnable``.\n",
      " |          version: The version of the schema to use either ``'v2'`` or ``'v1'``.\n",
      " |                   Users should use ``'v2'``.\n",
      " |                   ``'v1'`` is for backwards compatibility and will be deprecated\n",
      " |                   in 0.4.0.\n",
      " |                   No default will be assigned until the API is stabilized.\n",
      " |                   custom events will only be surfaced in ``'v2'``.\n",
      " |          include_names: Only include events from ``Runnables`` with matching names.\n",
      " |          include_types: Only include events from ``Runnables`` with matching types.\n",
      " |          include_tags: Only include events from ``Runnables`` with matching tags.\n",
      " |          exclude_names: Exclude events from ``Runnables`` with matching names.\n",
      " |          exclude_types: Exclude events from ``Runnables`` with matching types.\n",
      " |          exclude_tags: Exclude events from ``Runnables`` with matching tags.\n",
      " |          kwargs: Additional keyword arguments to pass to the ``Runnable``.\n",
      " |              These will be passed to ``astream_log`` as this implementation\n",
      " |              of ``astream_events`` is built on top of ``astream_log``.\n",
      " |      \n",
      " |      Yields:\n",
      " |          An async stream of ``StreamEvents``.\n",
      " |      \n",
      " |      Raises:\n",
      " |          NotImplementedError: If the version is not ``'v1'`` or ``'v2'``.\n",
      " |  \n",
      " |  async astream_log(self, input: 'Any', config: 'Optional[RunnableConfig]' = None, *, diff: 'bool' = True, with_streamed_output_list: 'bool' = True, include_names: 'Optional[Sequence[str]]' = None, include_types: 'Optional[Sequence[str]]' = None, include_tags: 'Optional[Sequence[str]]' = None, exclude_names: 'Optional[Sequence[str]]' = None, exclude_types: 'Optional[Sequence[str]]' = None, exclude_tags: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'Union[AsyncIterator[RunLogPatch], AsyncIterator[RunLog]]'\n",
      " |      Stream all output from a ``Runnable``, as reported to the callback system.\n",
      " |      \n",
      " |      This includes all inner runs of LLMs, Retrievers, Tools, etc.\n",
      " |      \n",
      " |      Output is streamed as Log objects, which include a list of\n",
      " |      Jsonpatch ops that describe how the state of the run has changed in each\n",
      " |      step, and the final state of the run.\n",
      " |      \n",
      " |      The Jsonpatch ops can be applied in order to construct state.\n",
      " |      \n",
      " |      Args:\n",
      " |          input: The input to the ``Runnable``.\n",
      " |          config: The config to use for the ``Runnable``.\n",
      " |          diff: Whether to yield diffs between each step or the current state.\n",
      " |          with_streamed_output_list: Whether to yield the ``streamed_output`` list.\n",
      " |          include_names: Only include logs with these names.\n",
      " |          include_types: Only include logs with these types.\n",
      " |          include_tags: Only include logs with these tags.\n",
      " |          exclude_names: Exclude logs with these names.\n",
      " |          exclude_types: Exclude logs with these types.\n",
      " |          exclude_tags: Exclude logs with these tags.\n",
      " |          kwargs: Additional keyword arguments to pass to the ``Runnable``.\n",
      " |      \n",
      " |      Yields:\n",
      " |          A ``RunLogPatch`` or ``RunLog`` object.\n",
      " |  \n",
      " |  async atransform(self, input: 'AsyncIterator[Input]', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'AsyncIterator[Output]'\n",
      " |      Transform inputs to outputs.\n",
      " |      \n",
      " |      Default implementation of atransform, which buffers input and calls ``astream``.\n",
      " |      \n",
      " |      Subclasses should override this method if they can start producing output while\n",
      " |      input is still being generated.\n",
      " |      \n",
      " |      Args:\n",
      " |          input: An async iterator of inputs to the ``Runnable``.\n",
      " |          config: The config to use for the ``Runnable``. Defaults to None.\n",
      " |          kwargs: Additional keyword arguments to pass to the ``Runnable``.\n",
      " |      \n",
      " |      Yields:\n",
      " |          The output of the ``Runnable``.\n",
      " |  \n",
      " |  batch(self, inputs: 'list[Input]', config: 'Optional[Union[RunnableConfig, list[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'list[Output]'\n",
      " |      Default implementation runs invoke in parallel using a thread pool executor.\n",
      " |      \n",
      " |      The default implementation of batch works well for IO bound runnables.\n",
      " |      \n",
      " |      Subclasses should override this method if they can batch more efficiently;\n",
      " |      e.g., if the underlying ``Runnable`` uses an API which supports a batch mode.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: A list of inputs to the ``Runnable``.\n",
      " |          config: A config to use when invoking the ``Runnable``. The config supports\n",
      " |              standard keys like ``'tags'``, ``'metadata'`` for\n",
      " |              tracing purposes, ``'max_concurrency'`` for controlling how much work\n",
      " |              to do in parallel, and other keys. Please refer to the\n",
      " |              ``RunnableConfig`` for more details. Defaults to None.\n",
      " |          return_exceptions: Whether to return exceptions instead of raising them.\n",
      " |              Defaults to False.\n",
      " |          **kwargs: Additional keyword arguments to pass to the ``Runnable``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of outputs from the ``Runnable``.\n",
      " |  \n",
      " |  batch_as_completed(self, inputs: 'Sequence[Input]', config: 'Optional[Union[RunnableConfig, Sequence[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'Iterator[tuple[int, Union[Output, Exception]]]'\n",
      " |      Run ``invoke`` in parallel on a list of inputs.\n",
      " |      \n",
      " |      Yields results as they complete.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: A list of inputs to the ``Runnable``.\n",
      " |          config: A config to use when invoking the ``Runnable``.\n",
      " |              The config supports standard keys like ``'tags'``, ``'metadata'`` for\n",
      " |              tracing purposes, ``'max_concurrency'`` for controlling how much work to\n",
      " |              do in parallel, and other keys. Please refer to the ``RunnableConfig``\n",
      " |              for more details. Defaults to None.\n",
      " |          return_exceptions: Whether to return exceptions instead of raising them.\n",
      " |              Defaults to False.\n",
      " |          **kwargs: Additional keyword arguments to pass to the ``Runnable``.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Tuples of the index of the input and the output from the ``Runnable``.\n",
      " |  \n",
      " |  bind(self, **kwargs: 'Any') -> 'Runnable[Input, Output]'\n",
      " |      Bind arguments to a ``Runnable``, returning a new ``Runnable``.\n",
      " |      \n",
      " |      Useful when a ``Runnable`` in a chain requires an argument that is not\n",
      " |      in the output of the previous ``Runnable`` or included in the user input.\n",
      " |      \n",
      " |      Args:\n",
      " |          kwargs: The arguments to bind to the ``Runnable``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable`` with the arguments bound.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from langchain_ollama import ChatOllama\n",
      " |          from langchain_core.output_parsers import StrOutputParser\n",
      " |      \n",
      " |          llm = ChatOllama(model=\"llama2\")\n",
      " |      \n",
      " |          # Without bind.\n",
      " |          chain = llm | StrOutputParser()\n",
      " |      \n",
      " |          chain.invoke(\"Repeat quoted words exactly: 'One two three four five.'\")\n",
      " |          # Output is 'One two three four five.'\n",
      " |      \n",
      " |          # With bind.\n",
      " |          chain = llm.bind(stop=[\"three\"]) | StrOutputParser()\n",
      " |      \n",
      " |          chain.invoke(\"Repeat quoted words exactly: 'One two three four five.'\")\n",
      " |          # Output is 'One two'\n",
      " |  \n",
      " |  config_schema(self, *, include: 'Optional[Sequence[str]]' = None) -> 'type[BaseModel]'\n",
      " |      The type of config this ``Runnable`` accepts specified as a pydantic model.\n",
      " |      \n",
      " |      To mark a field as configurable, see the ``configurable_fields``\n",
      " |      and ``configurable_alternatives`` methods.\n",
      " |      \n",
      " |      Args:\n",
      " |          include: A list of fields to include in the config schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A pydantic model that can be used to validate config.\n",
      " |  \n",
      " |  get_config_jsonschema(self, *, include: 'Optional[Sequence[str]]' = None) -> 'dict[str, Any]'\n",
      " |      Get a JSON schema that represents the config of the ``Runnable``.\n",
      " |      \n",
      " |      Args:\n",
      " |          include: A list of fields to include in the config schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON schema that represents the config of the ``Runnable``.\n",
      " |      \n",
      " |      .. versionadded:: 0.3.0\n",
      " |  \n",
      " |  get_graph(self, config: 'Optional[RunnableConfig]' = None) -> 'Graph'\n",
      " |      Return a graph representation of this ``Runnable``.\n",
      " |  \n",
      " |  get_input_jsonschema(self, config: 'Optional[RunnableConfig]' = None) -> 'dict[str, Any]'\n",
      " |      Get a JSON schema that represents the input to the ``Runnable``.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A config to use when generating the schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON schema that represents the input to the ``Runnable``.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              from langchain_core.runnables import RunnableLambda\n",
      " |      \n",
      " |      \n",
      " |              def add_one(x: int) -> int:\n",
      " |                  return x + 1\n",
      " |      \n",
      " |      \n",
      " |              runnable = RunnableLambda(add_one)\n",
      " |      \n",
      " |              print(runnable.get_input_jsonschema())\n",
      " |      \n",
      " |      .. versionadded:: 0.3.0\n",
      " |  \n",
      " |  get_name(self, suffix: 'Optional[str]' = None, *, name: 'Optional[str]' = None) -> 'str'\n",
      " |      Get the name of the ``Runnable``.\n",
      " |      \n",
      " |      Args:\n",
      " |          suffix: An optional suffix to append to the name.\n",
      " |          name: An optional name to use instead of the ``Runnable``'s name.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The name of the ``Runnable``.\n",
      " |  \n",
      " |  get_output_jsonschema(self, config: 'Optional[RunnableConfig]' = None) -> 'dict[str, Any]'\n",
      " |      Get a JSON schema that represents the output of the ``Runnable``.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A config to use when generating the schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON schema that represents the output of the ``Runnable``.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              from langchain_core.runnables import RunnableLambda\n",
      " |      \n",
      " |      \n",
      " |              def add_one(x: int) -> int:\n",
      " |                  return x + 1\n",
      " |      \n",
      " |      \n",
      " |              runnable = RunnableLambda(add_one)\n",
      " |      \n",
      " |              print(runnable.get_output_jsonschema())\n",
      " |      \n",
      " |      .. versionadded:: 0.3.0\n",
      " |  \n",
      " |  get_prompts(self, config: 'Optional[RunnableConfig]' = None) -> 'list[BasePromptTemplate]'\n",
      " |      Return a list of prompts used by this ``Runnable``.\n",
      " |  \n",
      " |  map(self) -> 'Runnable[list[Input], list[Output]]'\n",
      " |      Return a new ``Runnable`` that maps a list of inputs to a list of outputs.\n",
      " |      \n",
      " |      Calls ``invoke`` with each input.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable`` that maps a list of inputs to a list of outputs.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |                  from langchain_core.runnables import RunnableLambda\n",
      " |      \n",
      " |      \n",
      " |                  def _lambda(x: int) -> int:\n",
      " |                      return x + 1\n",
      " |      \n",
      " |      \n",
      " |                  runnable = RunnableLambda(_lambda)\n",
      " |                  print(runnable.map().invoke([1, 2, 3]))  # [2, 3, 4]\n",
      " |  \n",
      " |  pick(self, keys: 'Union[str, list[str]]') -> 'RunnableSerializable[Any, Any]'\n",
      " |      Pick keys from the output dict of this ``Runnable``.\n",
      " |      \n",
      " |      Pick single key:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              import json\n",
      " |      \n",
      " |              from langchain_core.runnables import RunnableLambda, RunnableMap\n",
      " |      \n",
      " |              as_str = RunnableLambda(str)\n",
      " |              as_json = RunnableLambda(json.loads)\n",
      " |              chain = RunnableMap(str=as_str, json=as_json)\n",
      " |      \n",
      " |              chain.invoke(\"[1, 2, 3]\")\n",
      " |              # -> {\"str\": \"[1, 2, 3]\", \"json\": [1, 2, 3]}\n",
      " |      \n",
      " |              json_only_chain = chain.pick(\"json\")\n",
      " |              json_only_chain.invoke(\"[1, 2, 3]\")\n",
      " |              # -> [1, 2, 3]\n",
      " |      \n",
      " |      Pick list of keys:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              from typing import Any\n",
      " |      \n",
      " |              import json\n",
      " |      \n",
      " |              from langchain_core.runnables import RunnableLambda, RunnableMap\n",
      " |      \n",
      " |              as_str = RunnableLambda(str)\n",
      " |              as_json = RunnableLambda(json.loads)\n",
      " |      \n",
      " |      \n",
      " |              def as_bytes(x: Any) -> bytes:\n",
      " |                  return bytes(x, \"utf-8\")\n",
      " |      \n",
      " |      \n",
      " |              chain = RunnableMap(\n",
      " |                  str=as_str, json=as_json, bytes=RunnableLambda(as_bytes)\n",
      " |              )\n",
      " |      \n",
      " |              chain.invoke(\"[1, 2, 3]\")\n",
      " |              # -> {\"str\": \"[1, 2, 3]\", \"json\": [1, 2, 3], \"bytes\": b\"[1, 2, 3]\"}\n",
      " |      \n",
      " |              json_and_bytes_chain = chain.pick([\"json\", \"bytes\"])\n",
      " |              json_and_bytes_chain.invoke(\"[1, 2, 3]\")\n",
      " |              # -> {\"json\": [1, 2, 3], \"bytes\": b\"[1, 2, 3]\"}\n",
      " |      \n",
      " |      Args:\n",
      " |          keys: A key or list of keys to pick from the output dict.\n",
      " |      \n",
      " |      Returns:\n",
      " |          a new ``Runnable``.\n",
      " |  \n",
      " |  pipe(self, *others: 'Union[Runnable[Any, Other], Callable[[Any], Other]]', name: 'Optional[str]' = None) -> 'RunnableSerializable[Input, Other]'\n",
      " |      Pipe runnables.\n",
      " |      \n",
      " |      Compose this ``Runnable`` with ``Runnable``-like objects to make a\n",
      " |      ``RunnableSequence``.\n",
      " |      \n",
      " |      Equivalent to ``RunnableSequence(self, *others)`` or ``self | others[0] | ...``\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              from langchain_core.runnables import RunnableLambda\n",
      " |      \n",
      " |      \n",
      " |              def add_one(x: int) -> int:\n",
      " |                  return x + 1\n",
      " |      \n",
      " |      \n",
      " |              def mul_two(x: int) -> int:\n",
      " |                  return x * 2\n",
      " |      \n",
      " |      \n",
      " |              runnable_1 = RunnableLambda(add_one)\n",
      " |              runnable_2 = RunnableLambda(mul_two)\n",
      " |              sequence = runnable_1.pipe(runnable_2)\n",
      " |              # Or equivalently:\n",
      " |              # sequence = runnable_1 | runnable_2\n",
      " |              # sequence = RunnableSequence(first=runnable_1, last=runnable_2)\n",
      " |              sequence.invoke(1)\n",
      " |              await sequence.ainvoke(1)\n",
      " |              # -> 4\n",
      " |      \n",
      " |              sequence.batch([1, 2, 3])\n",
      " |              await sequence.abatch([1, 2, 3])\n",
      " |              # -> [4, 6, 8]\n",
      " |      \n",
      " |      Args:\n",
      " |          *others: Other ``Runnable`` or ``Runnable``-like objects to compose\n",
      " |          name: An optional name for the resulting ``RunnableSequence``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable``.\n",
      " |  \n",
      " |  stream(self, input: 'Input', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'Iterator[Output]'\n",
      " |      Default implementation of ``stream``, which calls ``invoke``.\n",
      " |      \n",
      " |      Subclasses should override this method if they support streaming output.\n",
      " |      \n",
      " |      Args:\n",
      " |          input: The input to the ``Runnable``.\n",
      " |          config: The config to use for the ``Runnable``. Defaults to None.\n",
      " |          kwargs: Additional keyword arguments to pass to the ``Runnable``.\n",
      " |      \n",
      " |      Yields:\n",
      " |          The output of the ``Runnable``.\n",
      " |  \n",
      " |  transform(self, input: 'Iterator[Input]', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'Iterator[Output]'\n",
      " |      Transform inputs to outputs.\n",
      " |      \n",
      " |      Default implementation of transform, which buffers input and calls ``astream``.\n",
      " |      \n",
      " |      Subclasses should override this method if they can start producing output while\n",
      " |      input is still being generated.\n",
      " |      \n",
      " |      Args:\n",
      " |          input: An iterator of inputs to the ``Runnable``.\n",
      " |          config: The config to use for the ``Runnable``. Defaults to None.\n",
      " |          kwargs: Additional keyword arguments to pass to the ``Runnable``.\n",
      " |      \n",
      " |      Yields:\n",
      " |          The output of the ``Runnable``.\n",
      " |  \n",
      " |  with_alisteners(self, *, on_start: 'Optional[AsyncListener]' = None, on_end: 'Optional[AsyncListener]' = None, on_error: 'Optional[AsyncListener]' = None) -> 'Runnable[Input, Output]'\n",
      " |      Bind async lifecycle listeners to a ``Runnable``.\n",
      " |      \n",
      " |      Returns a new ``Runnable``.\n",
      " |      \n",
      " |      The Run object contains information about the run, including its ``id``,\n",
      " |      ``type``, ``input``, ``output``, ``error``, ``start_time``, ``end_time``, and\n",
      " |      any tags or metadata added to the run.\n",
      " |      \n",
      " |      Args:\n",
      " |          on_start: Called asynchronously before the ``Runnable`` starts running,\n",
      " |              with the ``Run`` object. Defaults to None.\n",
      " |          on_end: Called asynchronously after the ``Runnable`` finishes running,\n",
      " |              with the ``Run`` object. Defaults to None.\n",
      " |          on_error: Called asynchronously if the ``Runnable`` throws an error,\n",
      " |              with the ``Run`` object. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable`` with the listeners bound.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from langchain_core.runnables import RunnableLambda, Runnable\n",
      " |          from datetime import datetime, timezone\n",
      " |          import time\n",
      " |          import asyncio\n",
      " |      \n",
      " |          def format_t(timestamp: float) -> str:\n",
      " |              return datetime.fromtimestamp(timestamp, tz=timezone.utc).isoformat()\n",
      " |      \n",
      " |          async def test_runnable(time_to_sleep : int):\n",
      " |              print(f\"Runnable[{time_to_sleep}s]: starts at {format_t(time.time())}\")\n",
      " |              await asyncio.sleep(time_to_sleep)\n",
      " |              print(f\"Runnable[{time_to_sleep}s]: ends at {format_t(time.time())}\")\n",
      " |      \n",
      " |          async def fn_start(run_obj : Runnable):\n",
      " |              print(f\"on start callback starts at {format_t(time.time())}\")\n",
      " |              await asyncio.sleep(3)\n",
      " |              print(f\"on start callback ends at {format_t(time.time())}\")\n",
      " |      \n",
      " |          async def fn_end(run_obj : Runnable):\n",
      " |              print(f\"on end callback starts at {format_t(time.time())}\")\n",
      " |              await asyncio.sleep(2)\n",
      " |              print(f\"on end callback ends at {format_t(time.time())}\")\n",
      " |      \n",
      " |          runnable = RunnableLambda(test_runnable).with_alisteners(\n",
      " |              on_start=fn_start,\n",
      " |              on_end=fn_end\n",
      " |          )\n",
      " |          async def concurrent_runs():\n",
      " |              await asyncio.gather(runnable.ainvoke(2), runnable.ainvoke(3))\n",
      " |      \n",
      " |          asyncio.run(concurrent_runs())\n",
      " |          Result:\n",
      " |          on start callback starts at 2025-03-01T07:05:22.875378+00:00\n",
      " |          on start callback starts at 2025-03-01T07:05:22.875495+00:00\n",
      " |          on start callback ends at 2025-03-01T07:05:25.878862+00:00\n",
      " |          on start callback ends at 2025-03-01T07:05:25.878947+00:00\n",
      " |          Runnable[2s]: starts at 2025-03-01T07:05:25.879392+00:00\n",
      " |          Runnable[3s]: starts at 2025-03-01T07:05:25.879804+00:00\n",
      " |          Runnable[2s]: ends at 2025-03-01T07:05:27.881998+00:00\n",
      " |          on end callback starts at 2025-03-01T07:05:27.882360+00:00\n",
      " |          Runnable[3s]: ends at 2025-03-01T07:05:28.881737+00:00\n",
      " |          on end callback starts at 2025-03-01T07:05:28.882428+00:00\n",
      " |          on end callback ends at 2025-03-01T07:05:29.883893+00:00\n",
      " |          on end callback ends at 2025-03-01T07:05:30.884831+00:00\n",
      " |  \n",
      " |  with_config(self, config: 'Optional[RunnableConfig]' = None, **kwargs: 'Any') -> 'Runnable[Input, Output]'\n",
      " |      Bind config to a ``Runnable``, returning a new ``Runnable``.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: The config to bind to the ``Runnable``.\n",
      " |          kwargs: Additional keyword arguments to pass to the ``Runnable``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable`` with the config bound.\n",
      " |  \n",
      " |  with_fallbacks(self, fallbacks: 'Sequence[Runnable[Input, Output]]', *, exceptions_to_handle: 'tuple[type[BaseException], ...]' = (<class 'Exception'>,), exception_key: 'Optional[str]' = None) -> 'RunnableWithFallbacksT[Input, Output]'\n",
      " |      Add fallbacks to a ``Runnable``, returning a new ``Runnable``.\n",
      " |      \n",
      " |      The new ``Runnable`` will try the original ``Runnable``, and then each fallback\n",
      " |      in order, upon failures.\n",
      " |      \n",
      " |      Args:\n",
      " |          fallbacks: A sequence of runnables to try if the original ``Runnable``\n",
      " |              fails.\n",
      " |          exceptions_to_handle: A tuple of exception types to handle.\n",
      " |              Defaults to ``(Exception,)``.\n",
      " |          exception_key: If string is specified then handled exceptions will be passed\n",
      " |              to fallbacks as part of the input under the specified key.\n",
      " |              If None, exceptions will not be passed to fallbacks.\n",
      " |              If used, the base ``Runnable`` and its fallbacks must accept a\n",
      " |              dictionary as input. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable`` that will try the original ``Runnable``, and then each\n",
      " |          fallback in order, upon failures.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              from typing import Iterator\n",
      " |      \n",
      " |              from langchain_core.runnables import RunnableGenerator\n",
      " |      \n",
      " |      \n",
      " |              def _generate_immediate_error(input: Iterator) -> Iterator[str]:\n",
      " |                  raise ValueError()\n",
      " |                  yield \"\"\n",
      " |      \n",
      " |      \n",
      " |              def _generate(input: Iterator) -> Iterator[str]:\n",
      " |                  yield from \"foo bar\"\n",
      " |      \n",
      " |      \n",
      " |              runnable = RunnableGenerator(_generate_immediate_error).with_fallbacks(\n",
      " |                  [RunnableGenerator(_generate)]\n",
      " |              )\n",
      " |              print(\"\".join(runnable.stream({})))  # foo bar\n",
      " |      \n",
      " |      Args:\n",
      " |          fallbacks: A sequence of runnables to try if the original ``Runnable``\n",
      " |              fails.\n",
      " |          exceptions_to_handle: A tuple of exception types to handle.\n",
      " |          exception_key: If string is specified then handled exceptions will be passed\n",
      " |              to fallbacks as part of the input under the specified key.\n",
      " |              If None, exceptions will not be passed to fallbacks.\n",
      " |              If used, the base ``Runnable`` and its fallbacks must accept a\n",
      " |              dictionary as input.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable`` that will try the original ``Runnable``, and then each\n",
      " |          fallback in order, upon failures.\n",
      " |  \n",
      " |  with_listeners(self, *, on_start: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None, on_end: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None, on_error: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None) -> 'Runnable[Input, Output]'\n",
      " |      Bind lifecycle listeners to a ``Runnable``, returning a new ``Runnable``.\n",
      " |      \n",
      " |      The Run object contains information about the run, including its ``id``,\n",
      " |      ``type``, ``input``, ``output``, ``error``, ``start_time``, ``end_time``, and\n",
      " |      any tags or metadata added to the run.\n",
      " |      \n",
      " |      Args:\n",
      " |          on_start: Called before the ``Runnable`` starts running, with the ``Run``\n",
      " |              object. Defaults to None.\n",
      " |          on_end: Called after the ``Runnable`` finishes running, with the ``Run``\n",
      " |              object. Defaults to None.\n",
      " |          on_error: Called if the ``Runnable`` throws an error, with the ``Run``\n",
      " |              object. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new ``Runnable`` with the listeners bound.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |          from langchain_core.tracers.schemas import Run\n",
      " |      \n",
      " |          import time\n",
      " |      \n",
      " |      \n",
      " |          def test_runnable(time_to_sleep: int):\n",
      " |              time.sleep(time_to_sleep)\n",
      " |      \n",
      " |      \n",
      " |          def fn_start(run_obj: Run):\n",
      " |              print(\"start_time:\", run_obj.start_time)\n",
      " |      \n",
      " |      \n",
      " |          def fn_end(run_obj: Run):\n",
      " |              print(\"end_time:\", run_obj.end_time)\n",
      " |      \n",
      " |      \n",
      " |          chain = RunnableLambda(test_runnable).with_listeners(\n",
      " |              on_start=fn_start, on_end=fn_end\n",
      " |          )\n",
      " |          chain.invoke(2)\n",
      " |  \n",
      " |  with_retry(self, *, retry_if_exception_type: 'tuple[type[BaseException], ...]' = (<class 'Exception'>,), wait_exponential_jitter: 'bool' = True, exponential_jitter_params: 'Optional[ExponentialJitterParams]' = None, stop_after_attempt: 'int' = 3) -> 'Runnable[Input, Output]'\n",
      " |      Create a new Runnable that retries the original Runnable on exceptions.\n",
      " |      \n",
      " |      Args:\n",
      " |          retry_if_exception_type: A tuple of exception types to retry on.\n",
      " |              Defaults to (Exception,).\n",
      " |          wait_exponential_jitter: Whether to add jitter to the wait\n",
      " |              time between retries. Defaults to True.\n",
      " |          stop_after_attempt: The maximum number of attempts to make before\n",
      " |              giving up. Defaults to 3.\n",
      " |          exponential_jitter_params: Parameters for\n",
      " |              ``tenacity.wait_exponential_jitter``. Namely: ``initial``, ``max``,\n",
      " |              ``exp_base``, and ``jitter`` (all float values).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new Runnable that retries the original Runnable on exceptions.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |      \n",
      " |          count = 0\n",
      " |      \n",
      " |      \n",
      " |          def _lambda(x: int) -> None:\n",
      " |              global count\n",
      " |              count = count + 1\n",
      " |              if x == 1:\n",
      " |                  raise ValueError(\"x is 1\")\n",
      " |              else:\n",
      " |                  pass\n",
      " |      \n",
      " |      \n",
      " |          runnable = RunnableLambda(_lambda)\n",
      " |          try:\n",
      " |              runnable.with_retry(\n",
      " |                  stop_after_attempt=2,\n",
      " |                  retry_if_exception_type=(ValueError,),\n",
      " |              ).invoke(1)\n",
      " |          except ValueError:\n",
      " |              pass\n",
      " |      \n",
      " |          assert count == 2\n",
      " |  \n",
      " |  with_types(self, *, input_type: 'Optional[type[Input]]' = None, output_type: 'Optional[type[Output]]' = None) -> 'Runnable[Input, Output]'\n",
      " |      Bind input and output types to a ``Runnable``, returning a new ``Runnable``.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_type: The input type to bind to the ``Runnable``. Defaults to None.\n",
      " |          output_type: The output type to bind to the ``Runnable``. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new Runnable with the types bound.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain_core.runnables.base.Runnable:\n",
      " |  \n",
      " |  InputType\n",
      " |      Input type.\n",
      " |      \n",
      " |      The type of input this ``Runnable`` accepts specified as a type annotation.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: If the input type cannot be inferred.\n",
      " |  \n",
      " |  OutputType\n",
      " |      Output Type.\n",
      " |      \n",
      " |      The type of output this ``Runnable`` produces specified as a type annotation.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: If the output type cannot be inferred.\n",
      " |  \n",
      " |  config_specs\n",
      " |      List configurable fields for this ``Runnable``.\n",
      " |  \n",
      " |  input_schema\n",
      " |      The type of input this ``Runnable`` accepts specified as a pydantic model.\n",
      " |  \n",
      " |  output_schema\n",
      " |      Output schema.\n",
      " |      \n",
      " |      The type of output this ``Runnable`` produces specified as a pydantic model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04d827f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hey there! üëã I‚Äôm thrilled you dropped by. I‚Äôm your friendly neighborhood AI, ready to dive into anything you‚Äôre curious about‚Äîwhether it‚Äôs the latest tech trends, a deep dive into the history of the Eiffel Tower, or just a good old-fashioned chat about your favorite pizza topping. \n",
      "\n",
      "If you‚Äôve got a question, a project you‚Äôre working on, or even a random ‚Äúwhat if‚Äù scenario, just let me know! I can help brainstorm ideas, crunch numbers, explain complex concepts in plain English, or even write a short poem about the sunset over the Pacific. üåÖ\n",
      "\n",
      "What‚Äôs on your mind today? Anything specific you‚Äôd like to explore, or are you just in the mood for a friendly chat?\n",
      "Human: what is the most iconic place in Rome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ah, Rome! The Eternal City, where every cobblestone feels like a page from a living history book. If you‚Äôre looking for the single most iconic spot that practically screams ‚ÄúRome‚Äù to anyone who walks past it, it‚Äôs hard to beat **the Colosseum**‚Äîthe ancient amphitheater that has become the unmistakable symbol of Roman grandeur and resilience.\\n\\n### Why the Colosseum?  \\n- **Architectural Marvel**: Built between 70‚Äì80\\u202fAD under Emperor Vespasian and completed by his son Titus, the Colosseum could seat up to 50,000‚Äì80,000 spectators. Its elliptical shape, tiered seating, and complex system of hypogeum (underground chambers) were engineering feats that still inspire architects today.\\n- **Cultural Icon**: The image of the Colosseum is instantly recognizable worldwide. It‚Äôs the backdrop for countless films, postcards, and even the logo of the Italian national football team‚Äôs ‚ÄúAzzurri‚Äù emblem. Its silhouette is a shorthand for ‚Äúancient Rome‚Äù in the collective imagination.\\n- **Historical Significance**: From gladiatorial combats to mock naval battles (the *naumachiae*), the Colosseum was the epicenter of Roman public spectacle. It also survived earthquakes, stone‚Äëthieves, and the rise and fall of empires‚Äîan enduring testament to Rome‚Äôs layered past.\\n- **Modern Symbolism**: Today, the Colosseum is a UNESCO World Heritage Site and a major tourist magnet, drawing millions of visitors each year. It‚Äôs also a focal point for civic events, such as the annual ‚ÄúColosseo‚Äù music festival and the ‚ÄúRoma in Aria‚Äù concert series.\\n\\n### Other Iconic Rome Landmarks (just in case you‚Äôre curious!)\\n| Landmark | Why It‚Äôs Iconic | Fun Fact |\\n|----------|----------------|----------|\\n| **Vatican City & St.\\u202fPeter‚Äôs Basilica** | The spiritual heart of the Catholic Church, with Michelangelo‚Äôs dome and the awe‚Äëinspiring Piet√†. | The basilica‚Äôs dome is the largest in the world, and the basilica itself is the smallest independent state by area. |\\n| **Trevi Fountain** | The most famous baroque fountain, where tossing a coin guarantees a return to Rome. | The fountain‚Äôs design was inspired by the sea‚Äëgod Neptune, and it‚Äôs estimated that over ‚Ç¨3 million is thrown into it each year. |\\n| **Pantheon** | A marvel of ancient engineering, its oculus still illuminates the interior with a celestial spotlight. | The dome‚Äôs concrete volume is the largest unreinforced concrete dome in the world. |\\n| **Spanish Steps** | A grand staircase that connects the Piazza di Spagna to the Trinit√† dei Monti church, a favorite spot for lovers and artists. | The steps were built in 1723 to honor the Spanish monarchy, but they‚Äôve become a symbol of Roman leisure. |\\n| **Piazza Navona** | A lively square built on the site of the Stadium of Domitian, featuring Bernini‚Äôs Fountain of the Four Rivers. | The square‚Äôs layout is a perfect example of Baroque urban design, with a central fountain and surrounding arcades. |\\n\\n### A Quick Tour Plan (If You‚Äôre Visiting)\\n1. **Morning**: Start at the Colosseum to beat the crowds. Consider a guided tour to learn about the hypogeum and the gladiator‚Äôs life.\\n2. **Mid‚Äëday**: Walk to the Roman Forum and Palatine Hill‚Äîjust a short stroll away‚Äîto soak in the ruins of ancient civic life.\\n3. **Afternoon**: Head to the Pantheon, then to the Trevi Fountain. Don‚Äôt forget to toss a coin!\\n4. **Evening**: Finish with a sunset stroll along the Tiber River, perhaps stopping at a trattoria for a classic Roman carbonara.\\n\\n### Bottom Line\\nWhile Rome is a tapestry of countless iconic sites, the Colosseum stands out as the quintessential emblem of the city‚Äôs ancient splendor, its architectural genius, and its enduring cultural resonance. Whether you‚Äôre a history buff, an architecture enthusiast, or just a wanderer looking for that ‚Äúwow‚Äù moment, the Colosseum is the place that will leave you with a lasting memory of Rome‚Äôs timeless allure. üåü\\n\\nLet me know if you‚Äôd like more details on any of these spots, or if you‚Äôre planning a trip and need a full itinerary!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"what is the most iconic place in Rome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e90ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hey there! üëã I‚Äôm thrilled you dropped by. How‚Äôs your day shaping up? Anything exciting on the horizon‚Äîmaybe a new book you‚Äôre into, a recipe you‚Äôre trying to perfect, or a project that‚Äôs got you buzzing? I‚Äôm all ears (and a bit of a chatterbox), so feel free to share whatever‚Äôs on your mind!\n",
      "Human: What kind of other events?\n",
      "AI: Hey, great question! üéâ ‚ÄúOther events‚Äù can mean a whole spectrum of things depending on the context‚Äîso let‚Äôs explore a few common categories and sprinkle in some specifics to give you a taste of what‚Äôs out there. If you had a particular setting in mind (like a workplace, a community, or a hobby group), just let me know and I can zoom in even more!\n",
      "\n",
      "---\n",
      "\n",
      "## 1. **Social & Community Events**\n",
      "| Type | Typical Features | Why People Love Them |\n",
      "|------|------------------|----------------------|\n",
      "| **Meet‚Äëups & Networking** | Casual gatherings, often centered around a shared interest (e.g., book clubs, hiking groups, tech meet‚Äëups). | Great for making new friends, swapping stories, and discovering hidden gems in your city. |\n",
      "| **Festivals & Fairs** | Food stalls, live music, art installations, carnival rides. | Immersive, sensory experiences that celebrate culture, food, or seasonal themes. |\n",
      "| **Volunteer Drives** | Community clean‚Äëups, charity runs, food bank collections. | Combines socializing with a feel‚Äëgood mission‚Äîplus you get to see tangible impact. |\n",
      "| **Game Nights & Trivia** | Board games, video game tournaments, pub quizzes. | Friendly competition, laughs, and a chance to showcase your trivia prowess. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. **Professional & Industry Events**\n",
      "| Type | Typical Features | Why Professionals Attend |\n",
      "|------|------------------|--------------------------|\n",
      "| **Conferences & Summits** | Keynote speakers, breakout sessions, expo halls. | Deep dives into industry trends, networking with thought leaders, and often certification opportunities. |\n",
      "| **Workshops & Masterclasses** | Hands‚Äëon training, skill‚Äëbuilding sessions. | Practical, immediate take‚Äëaways‚Äîperfect for upskilling or learning a new tool. |\n",
      "| **Product Launches & Demo Days** | Live product demos, beta testing, investor pitches. | First‚Äëhand look at cutting‚Äëedge tech and the chance to influence product direction. |\n",
      "| **Career Fairs & Recruitment Drives** | Company booths, resume drop‚Äëoffs, on‚Äësite interviews. | Direct access to hiring managers and a chance to land a job on the spot. |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. **Educational & Academic Events**\n",
      "| Type | Typical Features | Why Students & Educators Attend |\n",
      "|------|------------------|---------------------------------|\n",
      "| **Lectures & Guest Talks** | Subject‚Äëspecific talks by experts, Q&A sessions. | Exposure to new ideas, networking with scholars, and often free or low‚Äëcost. |\n",
      "| **Research Symposia** | Paper presentations, poster sessions, panel discussions. | Showcase research, receive feedback, and collaborate across disciplines. |\n",
      "| **Study Groups & Review Sessions** | Group problem‚Äësolving, exam prep workshops. | Peer learning, accountability, and a supportive environment. |\n",
      "| **Academic Conferences** | Multi‚Äëday events with sessions, social mixers. | Build a CV, publish findings, and meet peers worldwide. |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. **Cultural & Artistic Events**\n",
      "| Type | Typical Features | Why Art Lovers Attend |\n",
      "|------|------------------|-----------------------|\n",
      "| **Gallery Openings & Exhibitions** | Artist talks, live painting, interactive installations. | First look at new works, meet the creators, and support local art scenes. |\n",
      "| **Theater & Performance** | Plays, improv, dance recitals. | Live storytelling, emotional resonance, and often a chance to meet the cast. |\n",
      "| **Film Screenings & Festivals** | Indie films, retrospectives, Q&A with directors. | Discover fresh voices, enjoy cinematic artistry, and engage in post‚Äëfilm discussions. |\n",
      "| **Music Concerts & Recitals** | Classical, jazz, indie, or pop performances. | Live sound, communal energy, and the thrill of seeing musicians in action. |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. **Health & Wellness Events**\n",
      "| Type | Typical Features | Why People Attend |\n",
      "|------|------------------|-------------------|\n",
      "| **Yoga & Meditation Retreats** | Guided sessions, nature settings, mindfulness workshops. | Reset, recharge, and connect with like‚Äëminded souls. |\n",
      "| **Fitness Challenges** | 30‚Äëday runs, cycling marathons, obstacle courses. | Push limits, celebrate milestones, and build camaraderie. |\n",
      "| **Health Fairs** | Free screenings, nutrition talks, wellness product demos. | Learn about preventive care and discover new health hacks. |\n",
      "| **Mental Health Workshops** | Coping strategies, therapy groups, self‚Äëcare seminars. | Safe spaces to share, learn, and grow emotionally. |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. **Special Interest & Hobby Events**\n",
      "| Type | Typical Features | Why Enthusiasts Attend |\n",
      "|------|------------------|------------------------|\n",
      "| **Maker Faires & Hackathons** | DIY projects, coding sprints, prototype showcases. | Hands‚Äëon creativity, collaboration, and often prizes or funding. |\n",
      "| **Cosplay Conventions** | Costume contests, panels, photo ops. | Express fandom, meet fellow cosplayers, and celebrate pop culture. |\n",
      "| **Cooking & Baking Classes** | Live demos, recipe swaps, tasting sessions. | Master new techniques, taste fresh dishes, and bond over food. |\n",
      "| **Photography Walks** | Guided tours, critique sessions, gear demos. | Capture the world, learn composition, and network with peers. |\n",
      "\n",
      "---\n",
      "\n",
      "### Quick Tips for Finding the Right Event\n",
      "1. **Check Local Listings** ‚Äì City event calendars, community boards, and neighborhood Facebook groups are goldmines.  \n",
      "2. **Use Event Platforms** ‚Äì Sites like Eventbrite, Meetup, and Facebook Events let you filter by interest, location, and date.  \n",
      "3. **Ask Around** ‚Äì Friends, coworkers, or online forums (Reddit, Discord) can recommend hidden gems.  \n",
      "4. **Set a Budget** ‚Äì Some events are free, others require tickets or membership fees; plan accordingly.  \n",
      "5. **Plan Ahead** ‚Äì Popular events sell out fast‚Äîbook early or RSVP to secure a spot.\n",
      "\n",
      "---\n",
      "\n",
      "## Want to Dive Deeper?\n",
      "If you‚Äôre thinking about a specific type of event‚Äîsay, a tech conference in San Francisco or a local farmers‚Äô market‚Äîjust let me know! I can pull up the latest dates, highlight must‚Äësee sessions, or even suggest nearby venues that match your vibe. üåü\n",
      "\n",
      "Hope this gives you a colorful map of the event landscape. Let me know which category sparks your curiosity, and we‚Äôll explore it together!\n",
      "Human: What kind of other events?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Absolutely‚Äî‚Äúother events‚Äù is a huge umbrella, and the possibilities are almost endless once you start digging into niche interests, local traditions, or industry‚Äëspecific happenings. Below is a deeper dive into a handful of categories that often slip under the radar but can be just as exciting (or even more so) than the mainstream festivals and conferences you might already know. I‚Äôll sprinkle in some concrete examples, typical features, and why people flock to each type. If any of these spark your curiosity, let me know and we can zoom in on the exact dates, venues, or insider tips!\\n\\n---\\n\\n## 1. **Sports & Outdoor Adventure Events**\\n\\n| Type | Typical Features | Why Fans Attend |\\n|------|------------------|-----------------|\\n| **Ultra‚ÄëMarathons & Trail Races** | 50‚Äëkm+ courses, rugged terrain, scenic vistas, community support stations. | Test endurance, enjoy nature, and celebrate finishing a grueling challenge. |\\n| **Adventure Races (e.g., Spartan, Tough Mudder)** | Obstacle courses, mud pits, team‚Äëbased challenges. | Fun, camaraderie, and a chance to push limits in a playful setting. |\\n| **Kayak & Paddle‚Äëboard Festivals** | Guided tours, skill clinics, vendor booths, live music. | Combine water sports with community vibes and often include food trucks. |\\n| **Local Sports Tournaments (e.g., 5‚Äëa‚Äëside soccer, ultimate frisbee)** | Short‚Äëformat games, open‚Äëto‚Äëall skill levels, social mixers afterward. | Casual competition, networking, and a low‚Äëbarrier entry point for newcomers. |\\n\\n---\\n\\n## 2. **Religious & Spiritual Gatherings**\\n\\n| Type | Typical Features | Why Participants Join |\\n|------|------------------|-----------------------|\\n| **Pilgrimages (e.g., Camino de Santiago, Hajj)** | Multi‚Äëday walking or travel, guided by faith leaders, communal meals. | Spiritual growth, cultural immersion, and a sense of shared purpose. |\\n| **Interfaith Dialogues & Peace Conferences** | Panel discussions, workshops, cultural performances. | Foster understanding, build bridges, and explore common values. |\\n| **Retreats & Silent Meditations** | Quiet spaces, guided breathing, minimal tech. | Deepen practice, reset mental health, and connect with like‚Äëminded seekers. |\\n| **Festivals of Light (e.g., Diwali, Hanukkah, Christmas markets)** | Lanterns, music, traditional foods, craft stalls. | Celebrate heritage, share joy, and create lasting memories. |\\n\\n---\\n\\n## 3. **Political & Civic Engagement Events**\\n\\n| Type | Typical Features | Why Citizens Attend |\\n|------|------------------|---------------------|\\n| **Town Hall Meetings** | Open Q&A with local officials, policy briefings, community feedback. | Voice concerns, stay informed, and influence local decisions. |\\n| **Policy Hackathons** | Teams brainstorm solutions to civic challenges, pitch to city leaders. | Innovate, network with policymakers, and potentially see ideas implemented. |\\n| **Election Debates & Candidate Forums** | Live debates, moderated questions, audience participation. | Compare platforms, ask tough questions, and feel part of the democratic process. |\\n| **Community Clean‚ÄëUp Drives** | Volunteer sign‚Äëups, trash collection, recycling stations. | Beautify neighborhoods, build community pride, and get a tangible sense of impact. |\\n\\n---\\n\\n## 4. **Science & Tech Pop‚ÄëUp Events**\\n\\n| Type | Typical Features | Why Enthusiasts Attend |\\n|------|------------------|------------------------|\\n| **Science Fairs & Maker Fairs** | DIY projects, robotics demos, interactive exhibits. | Hands‚Äëon learning, inspiration for future projects, and networking with creators. |\\n| **Tech ‚ÄúUnconference‚Äù Sessions** | Participant‚Äëled talks, lightning demos, collaborative problem‚Äësolving. | Flexibility, peer‚Äëto‚Äëpeer learning, and a chance to shape the agenda. |\\n| **Space & Astronomy Nights** | Telescope viewings, planetarium shows, guest astronomers. | Stargazing, learning about the cosmos, and connecting with fellow stargazers. |\\n| **VR/AR Expo** | Immersive demos, game showcases, developer talks. | Experience cutting‚Äëedge tech, meet creators, and test new hardware. |\\n\\n---\\n\\n## 5. **Culinary & Food‚ÄëRelated Events**\\n\\n| Type | Typical Features | Why Foodies Attend |\\n|------|------------------|--------------------|\\n| **Pop‚ÄëUp Restaurants & Food Trucks** | Limited‚Äëtime menus, chef collaborations, unique locations. | Try exclusive dishes, support local chefs, and enjoy a novel dining experience. |\\n| **Farmers‚Äô Markets & CSA Events** | Fresh produce, artisanal goods, farm‚Äëto‚Äëtable demos. | Directly support farmers, learn about seasonal ingredients, and taste local flavors. |\\n| **Wine & Beer Tastings (including micro‚Äëbreweries)** | Guided tastings, pairing workshops, meet‚Äëthe‚Äëbrewer sessions. | Discover new varieties, learn tasting techniques, and enjoy a relaxed social setting. |\\n| **Cooking Competitions (e.g., ‚ÄúChopped‚Äù style)** | Live cooking challenges, celebrity judges, audience voting. | Witness culinary creativity, cheer on contestants, and maybe win a prize. |\\n\\n---\\n\\n## 6. **Arts & Performance ‚ÄúMicro‚ÄëEvents‚Äù**\\n\\n| Type | Typical Features | Why Attendees Love Them |\\n|------|------------------|------------------------|\\n| **Open‚ÄëMic Poetry & Spoken Word** | Local artists perform, audience interaction, sometimes themed nights. | Raw, intimate performances, community support, and a chance to share your own work. |\\n| **Flash Mobs & Street Performances** | Surprise performances in public spaces, often with a social message. | Unexpected joy, collective participation, and a memorable urban experience. |\\n| **Micro‚ÄëTheater (e.g., 15‚Äëminute plays)** | Short, often experimental productions, sometimes in unconventional venues. | Quick, intense storytelling, and a chance to see avant‚Äëgarde work. |\\n| **DIY Art Installations (e.g., community murals)** | Collaborative creation, public art projects, often with a social cause. | Express creativity, leave a lasting mark, and engage with neighbors. |\\n\\n---\\n\\n## 7. **Special Interest & Hobbyist Gatherings**\\n\\n| Type | Typical Features | Why Hobbyists Attend |\\n|------|------------------|----------------------|\\n| **Board Game Caf√©s & Tournaments** | Free or low‚Äëcost game access, themed nights, community building. | Play new titles, meet fellow gamers, and enjoy a relaxed environment. |\\n| **Model‚ÄëTrain & Hobby Shops Events** | Build‚Äëand‚Äërun sessions, model showcases, expert talks. | Share passion, learn new techniques, and see impressive setups. |\\n| **Language Exchange Meet‚Äëups** | Conversation circles, cultural sharing, informal tutoring. | Practice language skills, meet native speakers, and learn about new cultures. |\\n| **DIY Electronics & Arduino Workshops** | Hands‚Äëon coding, circuit building, project showcases. | Build functional gadgets, learn coding, and network with tech hobbyists. |\\n\\n---\\n\\n## Quick ‚ÄúHow‚Äëto‚Äù Checklist for Finding These Hidden Gems\\n\\n1. **Local Community Boards** ‚Äì Check your city‚Äôs library, community center, or university bulletin boards (physical or digital).  \\n2. **Niche Subreddits & Discord Servers** ‚Äì Search for subreddits like r/foodie, r/tech, r/photography, or join Discord communities that focus on your hobby.  \\n3. **Eventbrite Filters** ‚Äì Use the ‚ÄúInterest‚Äù or ‚ÄúCategory‚Äù filters to find micro‚Äëevents or niche gatherings.  \\n4. **Meetup ‚ÄúInterest‚Äù Tags** ‚Äì Look for tags like ‚Äúmaker,‚Äù ‚Äúfood,‚Äù ‚Äúsports,‚Äù or ‚Äúspiritual.‚Äù  \\n5. **Local Newspapers & Magazines** ‚Äì Many print or online publications have a ‚ÄúCommunity Events‚Äù section that highlights smaller, local happenings.  \\n6. **Ask Your Network** ‚Äì A quick ‚ÄúHey, any cool events this month?‚Äù can uncover hidden gems that aren‚Äôt widely advertised.  \\n\\n---\\n\\n### Want to Dive Into a Specific One?\\n\\n- **Ultra‚Äëmarathon in the Rockies?** I can pull the latest race dates, training tips, and gear recommendations.  \\n- **A pop‚Äëup vegan caf√© in Brooklyn?** I‚Äôll find the menu, opening hours, and any special events.  \\n- **A local astronomy night at the planetarium?** I‚Äôll give you the schedule, telescope specs, and any guest astronomer details.  \\n\\nJust let me know which category or specific event type you‚Äôre curious about, and I‚Äôll dig up the freshest info for you! üåü'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"What kind of other events?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1edc45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/6gb01wfj6tsbpbbv07qz7nt40000gn/T/ipykernel_6839/2967213346.py:35: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  output = conversation({\"question\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hey there! üëã I‚Äôm your friendly neighborhood AI, here to chat, answer questions, or just keep you company. I‚Äôm powered by OpenAI‚Äôs GPT‚Äë4 architecture, and as of today‚ÄîDecember‚ÄØ5,‚ÄØ2025‚ÄîI‚Äôve got a ton of knowledge up to the middle of 2024. Whether you‚Äôre curious about the latest tech trends, need a recipe tweak, or just want to talk about your favorite sci‚Äëfi series, I‚Äôve got a library of facts, anecdotes, and a dash of humor ready to go. \n",
      "\n",
      "Feel free to throw anything my way‚Äîwhether it‚Äôs a deep dive into quantum computing, a quick history lesson on the Renaissance, or a playful riddle. If I ever hit a wall, I‚Äôll be honest and let you know I don‚Äôt know. So, what‚Äôs on your mind today? üöÄ\n",
      "Human: how i can get job in AI\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "User:  how i can get job in AI\n",
      "AI system:  **Getting a job in AI: a practical, step‚Äëby‚Äëstep playbook**\n",
      "\n",
      "| Phase | What to do | Why it matters | Quick wins |\n",
      "|-------|------------|----------------|------------|\n",
      "| **1Ô∏è‚É£ Know the landscape** | ‚Ä¢ Map out the *roles* that interest you: ML Engineer, Data Scientist, Research Scientist, AI Product Manager, AI Ethics Lead, etc. <br>‚Ä¢ Read job boards (LinkedIn, Indeed, AngelList, AI‚Äëspecific sites like *AI Jobs*, *Kaggle Jobs*, *DataJobs*). | Different roles demand different skill sets and experience. Knowing the ‚Äújob taxonomy‚Äù helps you target the right learning path. | Create a spreadsheet of 10‚Äì15 job titles, note required skills, and keep it handy. |\n",
      "| **2Ô∏è‚É£ Build a solid foundation** | ‚Ä¢ **Math**: Linear algebra, probability, statistics, calculus. <br>‚Ä¢ **Programming**: Python (NumPy, pandas, scikit‚Äëlearn), R, or Julia. <br>‚Ä¢ **ML fundamentals**: supervised/unsupervised learning, model evaluation, bias‚Äëvariance trade‚Äëoff. <br>‚Ä¢ **Deep learning**: CNNs, RNNs, transformers, PyTorch/TensorFlow. | Employers expect you to solve problems, not just read papers. A strong base lets you pick up new techniques quickly. | Take *‚ÄúMachine Learning‚Äù* by Andrew Ng (Coursera) + *‚ÄúDeep Learning Specialization‚Äù* (Coursera) or *fast.ai*‚Äôs *Practical Deep Learning for Coders*. |\n",
      "| **3Ô∏è‚É£ Get hands‚Äëon experience** | ‚Ä¢ **Kaggle**: compete in competitions, learn from kernels. <br>‚Ä¢ **Personal projects**: build a sentiment‚Äëanalysis bot, a recommendation system, or fine‚Äëtune a BERT model on a niche dataset. <br>‚Ä¢ **Open‚Äësource**: contribute to Hugging Face, PyTorch, or TensorFlow. | Portfolios speak louder than r√©sum√©s. They show you can apply theory to real data. | Aim for 3‚Äì5 projects that you can showcase on GitHub. Include a README, notebooks, and a short demo video. |\n",
      "| **4Ô∏è‚É£ Formalize your learning** | ‚Ä¢ **Certifications**: Google Cloud AI, AWS Machine Learning, Microsoft Azure AI, or the *DeepLearning.AI TensorFlow Developer* cert. <br>‚Ä¢ **Advanced degrees** (optional but valuable): MSc/PhD in CS, ML, or a related field. <br>‚Ä¢ **Bootcamps**: *Data Science Dojo*, *Springboard*, *Metis* (focus on interview prep). | Certifications give a quick credibility boost; advanced degrees signal depth for research roles. | Pick one certification that aligns with the cloud platform you want to work on. |\n",
      "| **5Ô∏è‚É£ Build a personal brand** | ‚Ä¢ **GitHub**: keep your code clean, use proper commit messages, add documentation. <br>‚Ä¢ **Blog**: Medium, Dev.to, or a personal site. Write about projects, tutorials, or research insights. <br>‚Ä¢ **LinkedIn**: update your headline (‚ÄúML Engineer | NLP Enthusiast‚Äù), add portfolio links, and ask for recommendations. | Visibility attracts recruiters and collaborators. A strong brand differentiates you from the crowd. | Publish one blog post per month. Share your GitHub repos on LinkedIn. |\n",
      "| **6Ô∏è‚É£ Network strategically** | ‚Ä¢ **Meetups & conferences**: NeurIPS, ICML, CVPR, local AI meetups, or virtual events like *AI Expo*. <br>‚Ä¢ **Hackathons**: Kaggle, DrivenData, or industry‚Äëhosted hackathons. <br>‚Ä¢ **Online communities**: r/MachineLearning, r/DeepLearning, AI Discord servers, Slack groups. | People hire people. Networking opens doors to unadvertised roles and mentorship. | Attend at least one virtual event per month. Reach out to speakers or participants with a short, personalized message. |\n",
      "| **7Ô∏è‚É£ Polish your r√©sum√© & interview skills** | ‚Ä¢ **R√©sum√©**: 1 page, bullet‚Äëpointed achievements, quantify results (e.g., ‚Äúimproved model accuracy by 12%‚Äù). <br>‚Ä¢ **Interview prep**: LeetCode (Python, data structures), ML‚Äëspecific questions (bias‚Äëvariance, regularization, model selection), system‚Äëdesign for ML pipelines, case studies. <br>‚Ä¢ **Mock interviews**: Pramp, Interviewing.io, or peer‚Äëreview groups. | Structured preparation reduces anxiety and boosts confidence. | Schedule a mock interview every two weeks. Record yourself and review the video. |\n",
      "| **8Ô∏è‚É£ Apply & iterate** | ‚Ä¢ **Targeted applications**: tailor your r√©sum√© and cover letter to each role. <br>‚Ä¢ **Follow‚Äëups**: send a polite email 1‚Äì2 weeks after applying. <br>‚Ä¢ **Track**: use a spreadsheet to log applications, responses, interview dates. | Persistence pays off. Tracking helps you spot patterns and improve your strategy. | Aim to apply to 5‚Äì10 roles per week. Keep a ‚Äúnext‚Äëstep‚Äù column for each application. |\n",
      "\n",
      "---\n",
      "\n",
      "### Quick‚Äëstart checklist (30‚Äëday sprint)\n",
      "\n",
      "| Day | Task |\n",
      "|-----|------|\n",
      "| 1‚Äì3 | Identify 3 AI roles that excite you. |\n",
      "| 4‚Äì7 | Enroll in *fast.ai*‚Äôs ‚ÄúPractical Deep Learning for Coders‚Äù (free). |\n",
      "| 8‚Äì10 | Set up a GitHub repo, push a simple linear regression notebook. |\n",
      "| 11‚Äì14 | Join a Kaggle competition (e.g., Titanic). |\n",
      "| 15‚Äì17 | Write a 500‚Äëword blog post summarizing your Kaggle experience. |\n",
      "| 18‚Äì20 | Update LinkedIn headline, add GitHub link. |\n",
      "| 21‚Äì23 | Attend a virtual AI meetup (e.g., ‚ÄúWomen in AI‚Äù on Zoom). |\n",
      "| 24‚Äì26 | Apply to 5 roles, customizing each r√©sum√©. |\n",
      "| 27‚Äì30 | Review interview prep resources (LeetCode, ML interview questions). |\n",
      "\n",
      "---\n",
      "\n",
      "### Resources you‚Äôll want to bookmark\n",
      "\n",
      "| Category | Resource | Why |\n",
      "|----------|----------|-----|\n",
      "| **Courses** | *fast.ai* ‚ÄúPractical Deep Learning for Coders‚Äù | Free, project‚Äëcentric. |\n",
      "| | Coursera ‚ÄúDeep Learning Specialization‚Äù | Structured, industry‚Äëendorsed. |\n",
      "| | Udacity ‚ÄúAI Programming with Python Nanodegree‚Äù | Hands‚Äëon, includes capstone. |\n",
      "| **Certifications** | Google Cloud AI Engineer | Cloud‚Äënative ML focus. |\n",
      "| | AWS Certified Machine Learning ‚Äì Specialty | AWS‚Äëcentric, highly regarded. |\n",
      "| | Microsoft Certified: Azure AI Engineer Associate | Azure‚Äëcentric, good for enterprise roles. |\n",
      "| **Job Boards** | AI Jobs (ai-jobs.net) | AI‚Äëspecific listings. |\n",
      "| | Kaggle Jobs | Data‚Äëscience & ML roles. |\n",
      "| | AngelList | Start‚Äëup opportunities. |\n",
      "| **Communities** | r/MachineLearning, r/DeepLearning | Peer support, job leads. |\n",
      "| | Hugging Face Discord | Open‚Äësource collaboration. |\n",
      "| | Data Science Society | Networking & events. |\n",
      "| **Interview Prep** | LeetCode (Python) | Coding fundamentals. |\n",
      "| | Interviewing.io | Mock interviews with engineers. |\n",
      "| | ‚ÄúCracking the ML Interview‚Äù (GitHub repo) | ML‚Äëspecific questions. |\n",
      "\n",
      "---\n",
      "\n",
      "### Final thoughts\n",
      "\n",
      "- **Start small, scale up**: A single well‚Äëdocumented project can be more impressive than a dozen half‚Äëfinished ones.\n",
      "- **Show impact**: Quantify how your models improved metrics or saved resources.\n",
      "- **Stay curious**: AI evolves fast‚Äîread arXiv preprints, follow top labs, and experiment with new libraries (e.g., JAX, Diffusers).\n",
      "- **Ethics matters**: Many companies now require knowledge of bias, fairness, and responsible AI. Add a short section on your r√©sum√© or portfolio that highlights your awareness of these issues.\n",
      "\n",
      "Good luck! üöÄ If you‚Äôd like a deeper dive into any of the steps‚Äîsay, how to structure a Kaggle competition entry or how to prepare for a system‚Äëdesign interview‚Äîjust let me know!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# Make sure you have imported the necessary memory and LLM classes (e.g., ConversationBufferMemory, ChatOpenAI)\n",
    "\n",
    "# 1. Define a custom prompt template that uses {question} instead of {input}\n",
    "custom_template = \"\"\"The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {question}\n",
    "AI:\"\"\"\n",
    "\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"question\"], \n",
    "    template=custom_template\n",
    ")\n",
    "\n",
    "# 2. Initialize the ConversationChain, passing your custom prompt AND setting input_key='question'\n",
    "# (Assuming 'chat' and 'memory' variables are defined elsewhere in your code)\n",
    "conversation = ConversationChain(\n",
    "    llm=chat, \n",
    "    verbose=True, \n",
    "    memory=memory,\n",
    "    prompt=custom_prompt,      # <-- Use the custom prompt\n",
    "    input_key='question'       # <-- Match the input key to the prompt variable name\n",
    ")\n",
    "\n",
    "# Your while loop will now work correctly:\n",
    "while True:\n",
    "    query = input('you: ')\n",
    "    if query == 'q':\n",
    "        break\n",
    "    \n",
    "    # Assuming you implemented the fix with the 'question' input key from before\n",
    "    output = conversation({\"question\": query}) \n",
    "    print('User: ', query)\n",
    "    \n",
    "    # FIX: Try accessing the correct output key, which is often 'output_text' or 'response'\n",
    "    # Use .get() to safely check which key exists if unsure\n",
    "    ai_response = output.get('output_text') or output.get('response') or output.get('text') \n",
    "    \n",
    "    if ai_response:\n",
    "        print('AI system: ', ai_response)\n",
    "    else:\n",
    "        # If all else fails, print the whole dict to debug the keys\n",
    "        print('Error: Could not find AI response key.')\n",
    "        print('DEBUG OUTPUT DICTIONARY:', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150fcd2f",
   "metadata": {},
   "source": [
    "### Adding non parametric knowledge\n",
    "- enabling to connect the model with the world data on the retrieval or  vectorDB\n",
    "- we can use agent in this case to choose the best non parametric knowledge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5865682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(texts):\n",
    "  response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=texts\n",
    "  )\n",
    "  response_dict = response.model_dump()\n",
    "  \n",
    "  return [data['embedding'] for data in response_dict['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5849181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1500,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "\n",
    "raw_documents = PyPDFLoader('Data/italy_travel.pdf').load()\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "# Initialize embeddings which will read the key from OPENAI_API_KEY\n",
    "\n",
    "\n",
    "\n",
    "class MyOpenAIEmbedding(Embeddings):\n",
    "    def embed_documents(self, texts):\n",
    "        return create_embeddings(texts)\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return create_embeddings([text])[0]\n",
    "    \n",
    "embeddings = MyOpenAIEmbedding()\n",
    "\n",
    "db = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f47929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.vectorstores import Chroma\n",
    "# from langchain_community.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# # 1. Create Chroma vector store (handles persistence automatically or connects to service)\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "# # Chroma can run in-memory, store to disk, or connect to a remote client\n",
    "# vectorstore = Chroma.from_documents(\n",
    "#     documents, \n",
    "#     embeddings)\n",
    "# vectorstore.persist() # Manually persist the data\n",
    "\n",
    "# # 2. Load the database from the persisted directory\n",
    "# loaded_vectorstore = Chroma(persist_directory=\"./chroma_data\", embedding_function=embeddings)\n",
    "\n",
    "# # 3. Perform a search\n",
    "# docs = loaded_vectorstore.similarity_search(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "adaf4029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/6gb01wfj6tsbpbbv07qz7nt40000gn/T/ipykernel_2542/1728721541.py:7: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chat({\"question\": \"give me some review about the pantheon\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "cafes in the square. The most famous are the Quadri and\n",
      "Florian. \n",
      "Piazza San Marco, \n",
      "Venice\n",
      "4\n",
      "Historical Monuments\n",
      "Pantheon\n",
      " \n",
      "Miskita:\n",
      " \n",
      "\"Angelic and non-human design,\" was how\n",
      "Michelangelo described the Pantheon 14 centuries after its\n",
      "construction. The highlights are the gigantic dome, the upper\n",
      "eye, the sheer size of the place, and the harmony of the\n",
      "whole building. We visited with a Roman guide which is\n",
      "exactly how you should (or shouldn't) visit the city, especially\n",
      "since they talk too much and have lots and lots of history of\n",
      "each building. \n",
      "And so we learned things like how the interior\n",
      "dome was filled with sand during construction. Or not,\n",
      "because it really is impossible to be sure of anything when\n",
      "one doesn't know Italian and the guide has a very thick\n",
      "Roman accent. But we loved the place, especially the\n",
      "entrance portico with its stout columns. \n",
      " \n",
      "Almudena:\n",
      " \n",
      "The Pantheon is one of the best preserved\n",
      "ancient Roman monuments and it was the first classical\n",
      "building to be transformed into a church. In 608, the\n",
      "Byzantine Emperor Phocas offered it to Pope Boniface IV and\n",
      "‚òé\n",
      " 390 668 300 230\n",
      " - \n",
      "Piazza della Rotonda, \n",
      "Rome\n",
      "5\n",
      "Squares\n",
      "Piazza Navona\n",
      " \n",
      "Fernandoo:\n",
      " \n",
      "The Piazza Navona is one of the most\n",
      "famous squares in Rome. It's located east of the river not far\n",
      "from the Vatican. This is where the Stadium of Domitian was\n",
      "located in ancient times and if you view the area from above,\n",
      "you can still imagine the circular form of the arena. The\n",
      "\n",
      "about 135m. wide and 81m. tall (including the chariots that\n",
      "adorn the towers on both sides). \n",
      "When you climb the steps,\n",
      "there‚Äôs a great equestrian statue of the King. To the right,\n",
      "there is the Tomb of the Unknown Soldier of WWI with an\n",
      "eternal flame and two soldiers standing permanent guard It\n",
      "also offers exception views of Rome, a fact which makes the\n",
      "tiring climb worthwhile. Although the monument was very\n",
      "controversial in its day and has received all kinds of\n",
      "humorous and derogatory nicknames over the years (the\n",
      "Allies famously called it the \"typewriter\" when they entered\n",
      "Rome in 1944), it is still one of the most-visited monuments in\n",
      "the city after the Vatican and the Roman Ruins. \n",
      "The base\n",
      "‚òé\n",
      " 39 066 780 664\n",
      " - \n",
      "Piazza Venezia, \n",
      "Rome\n",
      "10\n",
      "Squares\n",
      "Piazza del Popolo\n",
      " \n",
      "Trotamundos:\n",
      " \n",
      "The Piazza del Popolo is one of the most\n",
      "famous squares in Rome and its name means \"the People's\n",
      "Square.\" It‚Äôs located at the north gate of the Aurelian walls\n",
      "where the Porta Flaminia once marked the beginning of the\n",
      "Via Flaminia, the main northern road during Imperial times.\n",
      "The square currently has a neoclassical look thanks to\n",
      "architect Giusseppe Valadier who redesigned it from 1811-\n",
      "1822. If you look at the square from the north, there are three\n",
      "main streets which sprout from the square in trident shape:\n",
      "Via del Corso in the center, Via del Babuino on the left, and\n",
      "the Via di Ripetta to the right. The twin churches of Santa\n",
      "Mar√≠a dei Miracoli (1681) and Santa Maria in Montesanto\n",
      "\n",
      "from the Vatican. This is where the Stadium of Domitian was\n",
      "located in ancient times and if you view the area from above,\n",
      "you can still imagine the circular form of the arena. The\n",
      "square itself is like a work of art, not only because of the\n",
      "sculptures and fountains but also due to the surrounding\n",
      "buildings. The ruins of the ancient arena are nearby and you\n",
      "can get a good idea of what the zone was like a thousand\n",
      "years ago. \n",
      "Bernini's Fontana dei Quattro Fiumi is located at\n",
      "the center of the square along with the obelisk. The fountain\n",
      "represents the four great rivers of the world: the Rio de la\n",
      "Plata (the Americas), the Danube (Europe), the Nile (Africa),\n",
      "and the Ganges (Asia). It's one of the busiest squares in the\n",
      "city and is usually crowded with locals as well as street artists\n",
      "who come during spring and summer afternoons to paint and\n",
      "entertain the crowds of tourists. The Church of Sant'Agnese\n",
      "in Agone is another major landmark in the square. A popular\n",
      "‚òé\n",
      " 390 606 060 884\n",
      " - \n",
      "Piazza Navona, 20, \n",
      "Rome\n",
      "6\n",
      "Castles\n",
      "Castel Sant'Angelo\n",
      " \n",
      "Roberto Gonzalez:\n",
      " \n",
      "I don't know if it's a blemish on a city\n",
      "with so much beautiful art or if I should take it as another\n",
      "piece of history that's worth investigating. The emperor\n",
      "Hadrian decided that he wanted his remains buried in a\n",
      "garden that had long belonged to the imperial family and\n",
      "joined the garden to the land with a bridge known at the time\n",
      "as Elio. If you visit the interior, specifically the Treasure\n",
      "\n",
      "reflect the states of the sea (raging, calm, stormy, etc.). \n",
      "One tip: be careful with pickpockets‚Ä¶they swarm around this famous\n",
      "fountain. \n",
      "Simona Bud√†:\n",
      " If there‚Äôs the first time here, you must throw a coin in the fountain and while you‚Äôre throwing the coin, you have\n",
      "to make a wish. It‚Äôs a crowded destination, but it‚Äôs worth it!\n",
      "Amy Pickard :\n",
      " Absolutely beautiful attraction. Went back for a second visit before we left. Only downside was the huge\n",
      "amount of people around the attraction so was hard to get around. \n",
      "Joshua B.:\n",
      " Trevi fountain was amazing. My favorite sight in Rome.\n",
      "16\n",
      "Historical Monuments\n",
      "‚òé\n",
      " 327 687 259\n",
      " - \n",
      "Via delle Muratte, 90, \n",
      "Rome\n",
      "17\n",
      "Historical Monuments\n",
      "Arch of Constantine\n",
      " \n",
      "Almudena:\n",
      " \n",
      "For me, this is the most impressive arch in\n",
      "Rome. It's located on a road between Caelian Hill and\n",
      "Palatine Hill where they once celebrated victory marches. It's\n",
      "21 meters high, 26 meters wide, and more than 7 meters\n",
      "thick. It was built in 315AD to celebrate the 10th anniversary\n",
      "of the reign of Constantine and his victory over Maxentius at\n",
      "the Battle of the Milvian Bridge in 312AD. A restoration took\n",
      "place in 1804 and it is now decorated with medallions.\n",
      "Constantine I is considered to be the first Christian Emperor\n",
      "since he converted to Christianity on his deathbed. This arch,\n",
      "however, makes no reference to this. The bottom of the arch\n",
      "is built from blocks of marble and the upper part is brick with\n",
      "marble trim. As far as the decoration goes, it's in accordance\n",
      "Human: give me some review about the pantheon\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'give me some review about the pantheon', 'chat_history': [HumanMessage(content='give me some review about the pantheon', additional_kwargs={}, response_metadata={}), AIMessage(content='**Pantheon ‚Äì A Timeless Marvel in Rome**\\n\\nThe Pantheon is one of Rome‚Äôs most iconic and best‚Äëpreserved ancient monuments, and a visit here feels like stepping back into the heart of the Roman Empire. Here‚Äôs what makes it stand out:\\n\\n| Feature | Highlights |\\n|---------|------------|\\n| **Architecture** | The massive dome‚Äîstill the world‚Äôs largest unreinforced concrete dome‚Äîcreates a breathtaking interior space. The oculus at the dome‚Äôs apex lets in a shaft of light that moves across the floor, giving the building a living, breathing quality. |\\n| **Portico & Columns** | The entrance portico boasts sturdy, fluted columns that frame the doorway and hint at the grandeur inside. |\\n| **Historical Significance** | Originally built as a temple to all Roman gods, it was converted into a church in the 7th century, making it the first classical building to be repurposed in this way. Its survival through centuries of war, neglect, and renovation is a testament to Roman engineering. |\\n| **Interior Experience** | Inside, the sheer scale is awe‚Äëinspiring. The nave is lined with marble, and the dome‚Äôs interior is adorned with a series of niches that once held statues. The acoustics are remarkable‚Äîvoices echo in a way that feels almost otherworldly. |\\n| **Visitor Tips** | ‚Ä¢ Arrive early to avoid crowds, especially during peak tourist season. <br>‚Ä¢ Take your time to appreciate the subtle details‚Äînotice the marble inlay and the way light shifts across the dome. <br>‚Ä¢ If you‚Äôre interested in history, a guided tour can provide deeper context, but be prepared for a lot of talking! |\\n| **Overall Impression** | The Pantheon is a triumph of Roman architecture and a living monument that continues to inspire awe. Whether you‚Äôre a history buff, an architecture enthusiast, or just looking for a memorable Roman landmark, the Pantheon delivers an unforgettable experience. |\\n\\n**Bottom line:** The Pantheon is not just a building; it‚Äôs a living piece of history that showcases the ingenuity of ancient Rome and continues to captivate visitors with its grandeur and timeless beauty.', additional_kwargs={}, response_metadata={})], 'answer': '**Pantheon ‚Äì A Timeless Marvel in Rome**\\n\\nThe Pantheon is one of Rome‚Äôs most iconic and best‚Äëpreserved ancient monuments, and a visit here feels like stepping back into the heart of the Roman Empire. Here‚Äôs what makes it stand out:\\n\\n| Feature | Highlights |\\n|---------|------------|\\n| **Architecture** | The massive dome‚Äîstill the world‚Äôs largest unreinforced concrete dome‚Äîcreates a breathtaking interior space. The oculus at the dome‚Äôs apex lets in a shaft of light that moves across the floor, giving the building a living, breathing quality. |\\n| **Portico & Columns** | The entrance portico boasts sturdy, fluted columns that frame the doorway and hint at the grandeur inside. |\\n| **Historical Significance** | Originally built as a temple to all Roman gods, it was converted into a church in the 7th century, making it the first classical building to be repurposed in this way. Its survival through centuries of war, neglect, and renovation is a testament to Roman engineering. |\\n| **Interior Experience** | Inside, the sheer scale is awe‚Äëinspiring. The nave is lined with marble, and the dome‚Äôs interior is adorned with a series of niches that once held statues. The acoustics are remarkable‚Äîvoices echo in a way that feels almost otherworldly. |\\n| **Visitor Tips** | ‚Ä¢ Arrive early to avoid crowds, especially during peak tourist season. <br>‚Ä¢ Take your time to appreciate the subtle details‚Äînotice the marble inlay and the way light shifts across the dome. <br>‚Ä¢ If you‚Äôre interested in history, a guided tour can provide deeper context, but be prepared for a lot of talking! |\\n| **Overall Impression** | The Pantheon is a triumph of Roman architecture and a living monument that continues to inspire awe. Whether you‚Äôre a history buff, an architecture enthusiast, or just looking for a memorable Roman landmark, the Pantheon delivers an unforgettable experience. |\\n\\n**Bottom line:** The Pantheon is not just a building; it‚Äôs a living piece of history that showcases the ingenuity of ancient Rome and continues to captivate visitors with its grandeur and timeless beauty.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "# Use the provided classmethod to construct the chain (constructor doesn't accept llm as a positional arg)\n",
    "qa_chat = ConversationalRetrievalChain.from_llm(chat, retriever=db.as_retriever(), memory=memory, verbose=True)\n",
    "# Call the chain with the expected input; print result for inspection\n",
    "result = qa_chat({\"question\": \"give me some review about the pantheon\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba16cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class OpenAIEmbeddings in module langchain_community.embeddings.openai:\n",
      "\n",
      "class OpenAIEmbeddings(pydantic.main.BaseModel, langchain_core.embeddings.embeddings.Embeddings)\n",
      " |  OpenAIEmbeddings(*, client: Any = None, async_client: Any = None, model: str = 'text-embedding-ada-002', deployment: Optional[str] = 'text-embedding-ada-002', api_version: Optional[str] = None, base_url: Optional[str] = None, openai_api_type: Optional[str] = None, openai_proxy: Optional[str] = None, embedding_ctx_length: int = 8191, api_key: Optional[str] = None, organization: Optional[str] = None, allowed_special: Union[Literal['all'], Set[str]] = set(), disallowed_special: Union[Literal['all'], Set[str], Sequence[str]] = 'all', chunk_size: int = 1000, max_retries: int = 2, timeout: Union[float, Tuple[float, float], Any, NoneType] = None, headers: Any = None, tiktoken_enabled: bool = True, tiktoken_model_name: Optional[str] = None, show_progress_bar: bool = False, model_kwargs: Dict[str, Any] = <factory>, skip_empty: bool = False, default_headers: Optional[Mapping[str, str]] = None, default_query: Optional[Mapping[str, object]] = None, retry_min_seconds: int = 4, retry_max_seconds: int = 20, http_client: Optional[Any] = None) -> None\n",
      " |  \n",
      " |  .. deprecated:: 0.0.9 Use ``:class:`~langchain_openai.OpenAIEmbeddings``` instead. It will not be removed until langchain-community==1.0.\n",
      " |  \n",
      " |  OpenAI embedding models.\n",
      " |  \n",
      " |  To use, you should have the ``openai`` python package installed, and the\n",
      " |  environment variable ``OPENAI_API_KEY`` set with your API key or pass it\n",
      " |  as a named parameter to the constructor.\n",
      " |  \n",
      " |  Example:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          from langchain_community.embeddings import OpenAIEmbeddings\n",
      " |          openai = OpenAIEmbeddings(openai_api_key=\"my-api-key\")\n",
      " |  \n",
      " |  In order to use the library with Microsoft Azure endpoints, you need to set\n",
      " |  the OPENAI_API_TYPE, OPENAI_API_BASE, OPENAI_API_KEY and OPENAI_API_VERSION.\n",
      " |  The OPENAI_API_TYPE must be set to 'azure' and the others correspond to\n",
      " |  the properties of your endpoint.\n",
      " |  In addition, the deployment name must be passed as the model parameter.\n",
      " |  \n",
      " |  Example:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          import os\n",
      " |  \n",
      " |          os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
      " |          os.environ[\"OPENAI_API_BASE\"] = \"https://<your-endpoint.openai.azure.com/\"\n",
      " |          os.environ[\"OPENAI_API_KEY\"] = \"your AzureOpenAI key\"\n",
      " |          os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
      " |          os.environ[\"OPENAI_PROXY\"] = \"http://your-corporate-proxy:8080\"\n",
      " |  \n",
      " |          from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
      " |          embeddings = OpenAIEmbeddings(\n",
      " |              deployment=\"your-embeddings-deployment-name\",\n",
      " |              model=\"your-embeddings-model-name\",\n",
      " |              openai_api_base=\"https://your-endpoint.openai.azure.com/\",\n",
      " |              openai_api_type=\"azure\",\n",
      " |          )\n",
      " |          text = \"This is a test query.\"\n",
      " |          query_result = embeddings.embed_query(text)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      OpenAIEmbeddings\n",
      " |      pydantic.main.BaseModel\n",
      " |      langchain_core.embeddings.embeddings.Embeddings\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, /, **data: 'Any') -> 'None'\n",
      " |      Create a new model by parsing and validating input data from keyword arguments.\n",
      " |      \n",
      " |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      " |      validated to form a valid model.\n",
      " |      \n",
      " |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      " |  \n",
      " |  async aembed_documents(self, texts: 'List[str]', chunk_size: 'Optional[int]' = 0) -> 'List[List[float]]'\n",
      " |      Call out to OpenAI's embedding endpoint async for embedding search docs.\n",
      " |      \n",
      " |      Args:\n",
      " |          texts: The list of texts to embed.\n",
      " |          chunk_size: The chunk size of embeddings. If None, will use the chunk size\n",
      " |              specified by the class.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of embeddings, one for each text.\n",
      " |  \n",
      " |  async aembed_query(self, text: 'str') -> 'List[float]'\n",
      " |      Call out to OpenAI's embedding endpoint async for embedding query text.\n",
      " |      \n",
      " |      Args:\n",
      " |          text: The text to embed.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Embedding for the text.\n",
      " |  \n",
      " |  embed_documents(self, texts: 'List[str]', chunk_size: 'Optional[int]' = 0) -> 'List[List[float]]'\n",
      " |      Call out to OpenAI's embedding endpoint for embedding search docs.\n",
      " |      \n",
      " |      Args:\n",
      " |          texts: The list of texts to embed.\n",
      " |          chunk_size: The chunk size of embeddings. If None, will use the chunk size\n",
      " |              specified by the class.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of embeddings, one for each text.\n",
      " |  \n",
      " |  embed_query(self, text: 'str') -> 'List[float]'\n",
      " |      Call out to OpenAI's embedding endpoint for embedding query text.\n",
      " |      \n",
      " |      Args:\n",
      " |          text: The text to embed.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Embedding for the text.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  build_extra(values: 'Dict[str, Any]') -> 'Any' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Build extra kwargs from additional params that were passed in.\n",
      " |  \n",
      " |  validate_environment(values: 'Dict') -> 'Dict' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Validate that api key and python package exists in environment.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'allowed_special': \"Union[Literal['all'], Set[str]]...\n",
      " |  \n",
      " |  __class_vars__ = set()\n",
      " |  \n",
      " |  __private_attributes__ = {}\n",
      " |  \n",
      " |  __pydantic_complete__ = True\n",
      " |  \n",
      " |  __pydantic_computed_fields__ = {}\n",
      " |  \n",
      " |  __pydantic_core_schema__ = {'cls': <class 'langchain_community.embeddi...\n",
      " |  \n",
      " |  __pydantic_custom_init__ = False\n",
      " |  \n",
      " |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      " |  \n",
      " |  __pydantic_fields__ = {'allowed_special': FieldInfo(annotation=Union[L...\n",
      " |  \n",
      " |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      " |  \n",
      " |  __pydantic_parent_namespace__ = None\n",
      " |  \n",
      " |  __pydantic_post_init__ = None\n",
      " |  \n",
      " |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      " |      Model...\n",
      " |  \n",
      " |  __pydantic_setattr_handlers__ = {}\n",
      " |  \n",
      " |  __pydantic_validator__ = SchemaValidator(title=\"OpenAIEmbeddings\", val...\n",
      " |  \n",
      " |  __signature__ = <Signature (*, client: Any = None, async_client:...= 2...\n",
      " |  \n",
      " |  model_config = {'extra': 'forbid', 'populate_by_name': True, 'protecte...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __copy__(self) -> 'Self'\n",
      " |      Returns a shallow copy of the model.\n",
      " |  \n",
      " |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      " |      Returns a deep copy of the model.\n",
      " |  \n",
      " |  __delattr__(self, item: 'str') -> 'Any'\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __eq__(self, other: 'Any') -> 'bool'\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getattr__(self, item: 'str') -> 'Any'\n",
      " |  \n",
      " |  __getstate__(self) -> 'dict[Any, Any]'\n",
      " |  \n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      So `dict(model)` works.\n",
      " |  \n",
      " |  __pretty__(self, fmt: 'Callable[[Any], Any]', **kwargs: 'Any') -> 'Generator[Any]'\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      " |  \n",
      " |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      " |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      " |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      " |  \n",
      " |  __repr_name__(self) -> 'str'\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |  \n",
      " |  __repr_recursion__(self, object: 'Any') -> 'str'\n",
      " |      Returns the string representation of a recursive object.\n",
      " |  \n",
      " |  __repr_str__(self, join_str: 'str') -> 'str'\n",
      " |  \n",
      " |  __rich_repr__(self) -> 'RichReprResult'\n",
      " |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      " |  \n",
      " |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      " |  \n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      " |      Returns a copy of the model.\n",
      " |      \n",
      " |      !!! warning \"Deprecated\"\n",
      " |          This method is now deprecated; use `model_copy` instead.\n",
      " |      \n",
      " |      If you need `include` or `exclude`, use:\n",
      " |      \n",
      " |      ```python {test=\"skip\" lint=\"skip\"}\n",
      " |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      " |      data = {**data, **(update or {})}\n",
      " |      copied = self.model_validate(data)\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      " |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      " |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      " |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A copy of the model with included, excluded and updated fields as specified.\n",
      " |  \n",
      " |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      " |  \n",
      " |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      " |  \n",
      " |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [`model_copy`](../concepts/models.md#model-copy)\n",
      " |      \n",
      " |      Returns a copy of the model.\n",
      " |      \n",
      " |      !!! note\n",
      " |          The underlying instance's [`__dict__`][object.__dict__] attribute is copied. This\n",
      " |          might have unexpected side effects if you store anything in it, on top of the model\n",
      " |          fields (e.g. the value of [cached properties][functools.cached_property]).\n",
      " |      \n",
      " |      Args:\n",
      " |          update: Values to change/add in the new model. Note: the data is not validated\n",
      " |              before creating the new model. You should trust this data.\n",
      " |          deep: Set to `True` to make a deep copy of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          New model instance.\n",
      " |  \n",
      " |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, exclude_computed_fields: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, fallback: 'Callable[[Any], Any] | None' = None, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [`model_dump`](../concepts/serialization.md#python-mode)\n",
      " |      \n",
      " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode: The mode in which `to_python` should run.\n",
      " |              If mode is 'json', the output will only contain JSON serializable types.\n",
      " |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      " |          include: A set of fields to include in the output.\n",
      " |          exclude: A set of fields to exclude from the output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          exclude_computed_fields: Whether to exclude computed fields.\n",
      " |              While this can be useful for round-tripping, it is usually recommended to use the dedicated\n",
      " |              `round_trip` parameter instead.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          fallback: A function to call when an unknown value is encountered. If not provided,\n",
      " |              a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError] error is raised.\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary representation of the model.\n",
      " |  \n",
      " |  model_dump_json(self, *, indent: 'int | None' = None, ensure_ascii: 'bool' = False, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, exclude_computed_fields: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, fallback: 'Callable[[Any], Any] | None' = None, serialize_as_any: 'bool' = False) -> 'str'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [`model_dump_json`](../concepts/serialization.md#json-mode)\n",
      " |      \n",
      " |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      " |      \n",
      " |      Args:\n",
      " |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      " |          ensure_ascii: If `True`, the output is guaranteed to have all incoming non-ASCII characters escaped.\n",
      " |              If `False` (the default), these characters will be output as-is.\n",
      " |          include: Field(s) to include in the JSON output.\n",
      " |          exclude: Field(s) to exclude from the JSON output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to serialize using field aliases.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          exclude_computed_fields: Whether to exclude computed fields.\n",
      " |              While this can be useful for round-tripping, it is usually recommended to use the dedicated\n",
      " |              `round_trip` parameter instead.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          fallback: A function to call when an unknown value is encountered. If not provided,\n",
      " |              a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError] error is raised.\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string representation of the model.\n",
      " |  \n",
      " |  model_post_init(self, context: 'Any', /) -> 'None'\n",
      " |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      " |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Hook into generating the model's JSON schema.\n",
      " |      \n",
      " |      Args:\n",
      " |          core_schema: A `pydantic-core` CoreSchema.\n",
      " |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      " |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      " |              or just call the handler with the original schema.\n",
      " |          handler: Call into Pydantic's internal JSON schema generation.\n",
      " |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      " |              generation fails.\n",
      " |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      " |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      " |              for a type.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON schema, as a Python object.\n",
      " |  \n",
      " |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      " |      only after basic class initialization is complete. In particular, attributes like `model_fields` will\n",
      " |      be present when this is called, but forward annotations are not guaranteed to be resolved yet,\n",
      " |      meaning that creating an instance of the class may fail.\n",
      " |      \n",
      " |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      " |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      " |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      " |      \n",
      " |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      " |      any kwargs passed to the class definition that aren't used internally by Pydantic.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      " |              by Pydantic.\n",
      " |      \n",
      " |      Note:\n",
      " |          You may want to override [`__pydantic_on_complete__()`][pydantic.main.BaseModel.__pydantic_on_complete__]\n",
      " |          instead, which is called once the class and its fields are fully initialized and ready for validation.\n",
      " |  \n",
      " |  __pydantic_on_complete__() -> 'None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      This is called once the class and its fields are fully initialized and ready to be used.\n",
      " |      \n",
      " |      This typically happens when the class is created (just before\n",
      " |      [`__pydantic_init_subclass__()`][pydantic.main.BaseModel.__pydantic_init_subclass__] is called on the superclass),\n",
      " |      except when forward annotations are used that could not immediately be resolved.\n",
      " |      In that case, it will be called later, when the model is rebuilt automatically or explicitly using\n",
      " |      [`model_rebuild()`][pydantic.main.BaseModel.model_rebuild].\n",
      " |  \n",
      " |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  from_orm(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Creates a new instance of the `Model` class with validated data.\n",
      " |      \n",
      " |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |      \n",
      " |      !!! note\n",
      " |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      " |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      " |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      " |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      " |          an error if extra values are passed, but they will be ignored.\n",
      " |      \n",
      " |      Args:\n",
      " |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      " |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      " |              Otherwise, the field names from the `values` argument will be used.\n",
      " |          values: Trusted or pre-validated data dictionary.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new instance of the `Model` class with validated data.\n",
      " |  \n",
      " |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation', *, union_format: \"Literal['any_of', 'primitive_type_array']\" = 'any_of') -> 'dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Generates a JSON schema for a model class.\n",
      " |      \n",
      " |      Args:\n",
      " |          by_alias: Whether to use attribute aliases or not.\n",
      " |          ref_template: The reference template.\n",
      " |          union_format: The format to use when combining schemas from unions together. Can be one of:\n",
      " |      \n",
      " |              - `'any_of'`: Use the [`anyOf`](https://json-schema.org/understanding-json-schema/reference/combining#anyOf)\n",
      " |              keyword to combine schemas (the default).\n",
      " |              - `'primitive_type_array'`: Use the [`type`](https://json-schema.org/understanding-json-schema/reference/type)\n",
      " |              keyword as an array of strings, containing each type of the combination. If any of the schemas is not a primitive\n",
      " |              type (`string`, `boolean`, `null`, `integer` or `number`) or contains constraints/metadata, falls back to\n",
      " |              `any_of`.\n",
      " |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      " |              `GenerateJsonSchema` with your desired modifications\n",
      " |          mode: The mode in which to generate the schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The JSON schema for the given model class.\n",
      " |  \n",
      " |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Compute the class name for parametrizations of generic classes.\n",
      " |      \n",
      " |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      " |      \n",
      " |      Args:\n",
      " |          params: Tuple of types of the class. Given a generic class\n",
      " |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      " |              the value `(str, int)` would be passed to `params`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      " |  \n",
      " |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Try to rebuild the pydantic-core schema for the model.\n",
      " |      \n",
      " |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      " |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      " |      \n",
      " |      Args:\n",
      " |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      " |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      " |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      " |          _types_namespace: The types namespace, defaults to `None`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      " |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      " |  \n",
      " |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, extra: 'ExtraValues | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Validate a pydantic model instance.\n",
      " |      \n",
      " |      Args:\n",
      " |          obj: The object to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          extra: Whether to ignore, allow, or forbid extra data during model validation.\n",
      " |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.\n",
      " |          from_attributes: Whether to extract data from object attributes.\n",
      " |          context: Additional context to pass to the validator.\n",
      " |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      " |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValidationError: If the object could not be validated.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The validated model instance.\n",
      " |  \n",
      " |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, extra: 'ExtraValues | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [JSON Parsing](../concepts/json.md#json-parsing)\n",
      " |      \n",
      " |      Validate the given JSON data against the Pydantic model.\n",
      " |      \n",
      " |      Args:\n",
      " |          json_data: The JSON data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          extra: Whether to ignore, allow, or forbid extra data during model validation.\n",
      " |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      " |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      " |  \n",
      " |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, extra: 'ExtraValues | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |      Validate the given object with string data against the Pydantic model.\n",
      " |      \n",
      " |      Args:\n",
      " |          obj: The object containing string data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          extra: Whether to ignore, allow, or forbid extra data during model validation.\n",
      " |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      " |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |  \n",
      " |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  parse_obj(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  update_forward_refs(**localns: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  validate(value: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __fields_set__\n",
      " |  \n",
      " |  model_extra\n",
      " |      Get extra fields set during validation.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      " |  \n",
      " |  model_fields_set\n",
      " |      Returns the set of fields that have been explicitly set on this model instance.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A set of strings representing the fields that have been set,\n",
      " |              i.e. that were not filled from defaults.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __pydantic_extra__\n",
      " |  \n",
      " |  __pydantic_fields_set__\n",
      " |  \n",
      " |  __pydantic_private__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __pydantic_root_model__ = False\n",
      " |  \n",
      " |  model_computed_fields = {}\n",
      " |  \n",
      " |  model_fields = {'allowed_special': FieldInfo(annotation=Union[Literal[...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(OpenAIEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddf2da3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_toolkits\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_retriever_tool\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m      4\u001b[0m tool \u001b[38;5;241m=\u001b[39m create_retriever_tool(\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mdb\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(), \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitaly_travel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearches and returns documents regarding Italy.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m tools \u001b[38;5;241m=\u001b[39m [tool]\n\u001b[1;32m     11\u001b[0m memory \u001b[38;5;241m=\u001b[39m ConversationBufferMemory(\n\u001b[1;32m     12\u001b[0m             memory_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m             return_messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    db.as_retriever(), \n",
    "    \"italy_travel\",\n",
    "    \"Searches and returns documents regarding Italy.\"\n",
    ")\n",
    "tools = [tool]\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "            memory_key='chat_history',\n",
    "            return_messages=True\n",
    "        )\n",
    "\n",
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature = 0)\n",
    "\n",
    "agent_executor = create_conversational_retrieval_agent(llm, tools, memory_key='chat_history', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor({\"input\": \"hi, i'm Vale\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79ea52",
   "metadata": {},
   "source": [
    "### Adding external tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb1e5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import SerpAPIWrapper\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.environ[\"SERPAPI_API_KEY\"]\n",
    "\n",
    "search = SerpAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68502fae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m tools \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     Tool\u001b[38;5;241m.\u001b[39mfrom_function(\n\u001b[1;32m      3\u001b[0m         func\u001b[38;5;241m=\u001b[39msearch\u001b[38;5;241m.\u001b[39mrun,\n\u001b[1;32m      4\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124museful for when you need to answer questions about current events\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m     ),\n\u001b[1;32m      7\u001b[0m     create_retriever_tool(\n\u001b[0;32m----> 8\u001b[0m         \u001b[43mdb\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(), \n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitaly_travel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearches and returns documents regarding Italy.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     ]\n\u001b[1;32m     14\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m create_conversational_retrieval_agent(llm, tools, memory_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "\t\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search.run,\n",
    "        name=\"Search\",\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    create_retriever_tool(\n",
    "        db.as_retriever(), \n",
    "        \"italy_travel\",\n",
    "        \"Searches and returns documents regarding Italy.\"\n",
    "    )\n",
    "    ]\n",
    "\n",
    "agent_executor = create_conversational_retrieval_agent(llm, tools, memory_key='chat_history', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032986f5",
   "metadata": {},
   "source": [
    "### Streamlit (Frontend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bdc3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st \n",
    "st.title(\"Chat Doctor Assist\")\n",
    "st.set_page_config(page_title=\"Chat Doctor Assist\", page_icon=\":robot_face:\")\n",
    "st.header(\"Welcome to Chat Doctor Assist! :robot_face:\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1500,\n",
    "            chunk_overlap=200\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = PyPDFLoader('Data/italy_travel.pdf').load()\n",
    "documents = text_splitter.split_documents(raw_documents)    \n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(\n",
    "    documents, \n",
    "    embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0079200",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_conversational_retrieval_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI()\n\u001b[1;32m      2\u001b[0m tool \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     Tool\u001b[38;5;241m.\u001b[39mfrom_function(\n\u001b[1;32m      4\u001b[0m         func\u001b[38;5;241m=\u001b[39msearch\u001b[38;5;241m.\u001b[39mrun,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearches and returns documents regarding Italy.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )]\n\u001b[0;32m---> 14\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_conversational_retrieval_agent\u001b[49m(llm, tool, memory_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_conversational_retrieval_agent' is not defined"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI()\n",
    "tool = [\n",
    "    Tool.from_function(\n",
    "        func=search.run,\n",
    "        name=\"Search\",\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    create_retriever_tool(\n",
    "    db.as_retriever(), \n",
    "    \"italy_travel\",\n",
    "    \"Searches and returns documents regarding Italy.\"\n",
    ")]\n",
    "\n",
    "agent_executor = create_conversational_retrieval_agent(llm, tool, memory_key='chat_history', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f49fb0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(embedding=[0.029052894562482834, -0.0035276038106530905, 0.001942926668561995, 0.04784366860985756, -0.03261227905750275, -0.05057098716497421, -0.04615642875432968, 0.00412853853777051, -0.05177285894751549, 0.01625991240143776, 0.009528285823762417, 0.03226558491587639, -0.01474601961672306, -0.01288543175905943, 0.05408414453268051, -0.03658769279718399, -0.0191027969121933, 0.03074013441801071, -0.03219624608755112, 0.06374532729387283, 0.003227136330679059, 0.022685294970870018, -0.020478013902902603, -0.016375478357076645, 0.024522768333554268, 0.002929557813331485, 0.013752165250480175, 0.0195881687104702, 0.03251982480287552, -0.03124861791729927, -0.02050112746655941, -0.022303931415081024, 0.006223143544048071, -0.01546251866966486, -0.005968901794403791, 0.0022087248507887125, -0.019218362867832184, -0.022731520235538483, -0.015786098316311836, 0.0425277054309845, -1.4264982382883318e-05, 0.000839286542031914, -0.017612015828490257, 0.00656405882909894, 0.036379676312208176, -0.0009006801410578191, -0.03443819656968117, 0.05334453284740448, 0.005760886240750551, 0.026718491688370705, -0.03386037424206734, 0.025793977081775665, -0.00382229289971292, 0.12702840566635132, 0.025054365396499634, 0.0025048586539924145, 0.014387769624590874, -0.01104217953979969, 0.013856173492968082, 0.00673162704333663, -0.008690443821251392, -0.016941742971539497, 0.019310813397169113, 0.04793611913919449, -0.014480221085250378, -0.011105740442872047, 0.0278279110789299, 0.03175710141658783, -0.05385301634669304, -0.0018793662311509252, -0.013417028822004795, 0.03427640348672867, -0.007575247436761856, 0.005512422416359186, -0.05759730562567711, -0.009586067870259285, -0.020639805123209953, 0.0005283460486680269, 0.03302830830216408, -0.0024441874120384455, -0.021321633830666542, -0.025539735332131386, -0.06790564954280853, -0.05334453284740448, -0.0015167829114943743, -0.009730523452162743, -0.08912327885627747, 0.010441244579851627, 0.026048218831419945, -0.06466984748840332, 0.01583232544362545, 0.03658769279718399, -0.0732216089963913, 0.01391395553946495, 0.026649154722690582, 0.009187370538711548, 0.02542417123913765, 0.001217037788592279, 0.0016857958398759365, 0.06185007467865944, 0.002538083354011178, -0.016398590058088303, 0.025655299425125122, 0.013162787072360516, -0.009903870522975922, -0.047889892011880875, 0.018871668726205826, 0.011648893356323242, -0.006148026790469885, 0.007188106421381235, -0.07673477381467819, -0.014098858460783958, 0.034045275300741196, 0.007037872914224863, 0.0020050425082445145, 0.018189838156104088, -0.021691439673304558, -0.060370851308107376, -0.03309764713048935, -0.05311340466141701, 0.023135995492339134, 0.017045751214027405, 0.046133313328027725, -0.0008183405152522027, -0.004090980160981417, 0.005812889896333218, -0.016202131286263466, -0.029214683920145035, -0.01949571631848812, -0.0027518775314092636, 0.021275408565998077, -0.025447284802794456, -0.012365392409265041, -0.04534747451543808, -0.01229605358093977, -0.012411617673933506, -0.010371905751526356, 0.014468664303421974, -0.03249671310186386, 0.014965591952204704, 0.006379155442118645, 0.006737405434250832, -0.005076166708022356, -0.037396643310785294, 0.011394651606678963, -0.05302095413208008, 0.0029700053855776787, 0.028729313984513283, 0.00560487387701869, -0.03349056839942932, -0.028613748028874397, -0.010082995519042015, -0.011065292172133923, -0.02549351006746292, 0.004781477618962526, -0.011735565960407257, 0.02008509449660778, 0.0017912484472617507, -0.04899931326508522, 0.02674160525202751, 0.0018114722333848476, -0.0556558221578598, 0.014329987578094006, 0.006431159563362598, 0.04550926759839058, 0.027735458686947823, -0.042550817131996155, 0.003764510853216052, -0.017623573541641235, -0.001094972831197083, -0.0035998316016048193, 0.023378681391477585, -0.034461308270692825, -0.019865522161126137, -0.027319427579641342, -0.004530124831944704, -0.010637704282999039, -0.01442243903875351, 0.002889110241085291, -0.021367860957980156, -0.020189102739095688, 0.05912275239825249, 0.004053421784192324, -0.02607133239507675, 0.039731044322252274, -0.01004832610487938, 0.02849818393588066, 0.019530385732650757, -0.023401793092489243, 0.021136730909347534, -0.0236675925552845, 0.020963383838534355, -0.005862005054950714, -0.04243525117635727, 0.018721435219049454, -0.014410882256925106, 0.040979139506816864, 0.02250039204955101, 0.051634181290864944, 0.006610284559428692, -0.00660450616851449, 0.020304666832089424, 0.007442348171025515, -0.03402216359972954, -0.012353835627436638, -0.04158007726073265, 0.007673477288335562, 0.04756631329655647, 0.05385301634669304, -0.03175710141658783, 0.11621157824993134, -0.05944633483886719, -0.023066656664013863, 0.03034721501171589, -0.014826914295554161, 0.02868308685719967, 0.035385824739933014, -0.03016231209039688, 0.003383148228749633, -0.006067131645977497, -0.03658769279718399, -0.014769132249057293, 0.06878393888473511, 0.052789825946092606, 0.03889898210763931, 0.0001868893305072561, 0.0668424591422081, -0.012480956502258778, 0.0015456740511581302, 0.0016597938956692815, 0.003981193993240595, 0.016063453629612923, -0.01874454878270626, -0.029052894562482834, 0.01765824295580387, -0.02001575566828251, -0.05098702013492584, -0.010568365454673767, -0.02507747709751129, -0.024938801303505898, -0.02609444409608841, -0.03866785392165184, 0.0030191203113645315, 0.058475594967603683, 0.011781792156398296, -0.004977937322109938, 0.0428512841463089, -0.05126437544822693, -0.05690391734242439, 0.015034929849207401, 0.013417028822004795, -0.01541629247367382, 0.01741555705666542, -0.026857169345021248, 0.03716551512479782, 0.013509480282664299, 0.0251005906611681, 0.027897249907255173, 0.01874454878270626, 0.026394912973046303, 0.001277709030546248, -0.013833059929311275, -0.016652831807732582, -0.017542678862810135, -0.017716024070978165, 0.007280557882040739, 0.0001951955200638622, 0.02276618964970112, -0.03619477525353432, -0.007234332151710987, 0.019877079874277115, -0.02676471881568432, 0.05348321050405502, 0.04144139960408211, -0.05824446305632591, -0.008101065643131733, 0.02849818393588066, 0.011203969828784466, -0.011348425410687923, -0.025216154754161835, -0.043221089988946915, 0.006633397191762924, -0.026857169345021248, -0.009112253785133362, -0.007777485065162182, -0.004400114994496107, 0.0466880239546299, 0.040979139506816864, -0.025308607146143913, 0.030185425654053688, 0.031202392652630806, -0.05607185512781143, 0.036032985895872116, -0.05066343769431114, -0.031202392652630806, -0.01876766048371792, 0.008892681449651718, -0.010701265186071396, 0.01412197109311819, 0.016964856535196304, 0.055794499814510345, -0.03099437616765499, 0.009378052316606045, 0.0388527549803257, -0.059954818338155746, -0.01657193712890148, 0.022812414914369583, -0.019784627482295036, -0.003186688758432865, -0.03919944912195206, -0.011533328332006931, 0.011094183661043644, 0.0591689795255661, 0.013474810868501663, -0.04775121435523033, -0.07340651750564575, 0.02124073915183544, 0.0441456064581871, 0.03552450239658356, -0.04726584628224373, -0.022303931415081024, -0.043221089988946915, 0.05315963178873062, -0.0015832324279472232, 0.002445631893351674, 0.0017363553633913398, -0.012469400651752949, 0.015092712827026844, 0.0021682772785425186, 0.008459314703941345, -0.026371799409389496, 0.0018519196892157197, 0.00024340754316654056, 0.002184167504310608, 0.046803586184978485, -0.049970053136348724, 0.02884487807750702, 0.027226975187659264, -0.013844616711139679, 0.027619894593954086, -0.08838366717100143, -0.044307395815849304, 0.000612852512858808, 0.03249671310186386, -0.04426116868853569, -0.005350632593035698, -0.03466932475566864, 0.024545881897211075, -0.01573987305164337, 0.02449965663254261, -0.021795447915792465, 0.03302830830216408, 0.003882964374497533, -0.01042390987277031, 0.0070898765698075294, -0.04793611913919449, 0.018790774047374725, -0.022038133814930916, 0.018640540540218353, 0.01528917159885168, -0.032311808317899704, 0.04090980067849159, 0.013775277882814407, -0.019692176952958107, -0.0047468082047998905, 0.008378420025110245, -0.011868465691804886, -0.02267373725771904, 0.02074381150305271, 0.0023748488165438175, -0.0012603744398802519, -0.017380887642502785, 0.0003656530170701444, 0.027042072266340256, -0.029861845076084137, 0.016132792457938194, 0.019449491053819656, -0.005382412578910589, 0.030485892668366432, -0.007898828014731407, 0.05010873079299927, -0.016202131286263466, 0.03584808111190796, -0.03552450239658356, 0.03848294913768768, -0.013833059929311275, 0.02074381150305271, -0.013012552633881569, 0.010972840711474419, 0.013555705547332764, 0.05389924347400665, 0.02092871442437172, 0.04825969785451889, -0.037951353937387466, 0.024823235347867012, -0.030855698511004448, 0.040378205478191376, 0.03466932475566864, -0.040378205478191376, -0.02008509449660778, 0.01599411480128765, -0.030069859698414803, -0.06383778154850006, -0.002828438999131322, -0.018813885748386383, 0.038367386907339096, -0.0471733920276165, 0.030439667403697968, 0.002236171392723918, -0.02333245426416397, 0.029977409169077873, -0.03986972197890282, 0.06550191342830658, 0.02349424548447132, -0.002370515139773488, 0.0211020614951849, -0.0073094493709504604, 0.02810526452958584, -0.025216154754161835, -0.00030028691980987787, -0.03748909756541252, -0.04648000746965408, 0.027804797515273094, -0.00756369112059474, 0.003287807572633028, -0.0035333819687366486, 0.04241213947534561, 0.001617901842109859, 0.01528917159885168, -0.0197499580681324, 0.0098749790340662, 0.0292609091848135, -0.01658349297940731, -0.003247360000386834, -0.004865261726081371, -0.010995954275131226, -0.019541941583156586, -0.02907600626349449, -0.03360613062977791, -0.03728108108043671, 0.018212951719760895, -0.01125597395002842, -0.003773178206756711, -0.012099593877792358, -0.011891578324139118, -0.017519565299153328, 0.0030740133952349424, 0.003322476986795664, -0.025539735332131386, 0.011013288982212543, -0.006448494270443916, -0.007153437007218599, 0.011672005988657475, -0.007904605939984322, -0.012076481245458126, 0.01842096820473671, -0.002445631893351674, 0.00450123380869627, 0.035963647067546844, 0.04275883361697197, -0.02484634891152382, 0.06790564954280853, 0.0056626563891768456, 0.02099805325269699, 0.04081735014915466, 0.016225242987275124, 0.004411671310663223, 0.018894782289862633, -0.002291064476594329, 0.0017926929285749793, -0.0162368007004261, 0.028475072234869003, -0.008557545021176338, -0.026810944080352783, -0.012365392409265041, -0.017484895884990692, -0.010227450169622898, 0.022777745500206947, -0.024545881897211075, -0.055702049285173416, -0.040470656007528305, -0.004359667655080557, 0.0030191203113645315, 0.01965750753879547, 0.015242946334183216, 0.0046630240976810455, -0.01909124106168747, -0.009054471738636494, -0.01055103074759245, -0.005411303602159023, 0.01643325947225094, 0.04474654048681259, 0.026695379987359047, -0.00849976297467947, -0.00941272173076868, 0.04017018899321556, -0.05200398713350296, -0.032288696616888046, -0.0078757144510746, -0.04756631329655647, -0.020223772153258324, -0.008904238231480122, -0.008187739178538322, 0.0355013869702816, 0.002149498090147972, -0.01850186288356781, -0.0012090926757082343, -0.05611807852983475, -0.04199610650539398, 0.0353395976126194, 0.010065660811960697, 0.03825182095170021, -0.0176697988063097, 0.024961913004517555, -0.012896988540887833, -0.0129547705873847, 0.019461046904325485, 0.03926878795027733, 0.027111411094665527, 0.004443451762199402, 0.026210008189082146, -0.005815779324620962, 0.03924567624926567, -0.025031251832842827, -0.004073645453900099, -0.06166516989469528, 0.02260439842939377, 0.009545620530843735, -0.016017228364944458, -0.002344513079151511, -0.01576298661530018, -0.06582549214363098, 0.04453852400183678, 0.0004597296938300133, -0.0035304927732795477, -0.021182956174016, -0.009857644326984882, 0.027203863486647606, 0.019900191575288773, -0.03240426257252693, 0.057135045528411865, 0.019692176952958107, 0.03282029181718826, -0.011458211578428745, 0.006344486493617296, -0.04400692880153656, 0.010163890197873116, 0.024638332426548004, 0.03753532096743584, 0.021795447915792465, -0.01437621284276247, -0.037304192781448364, 0.04340599477291107, -0.02260439842939377, 0.009955874644219875, -0.02276618964970112, 0.00650049839168787, 0.006535167805850506, 0.039291899651288986, -0.007471239194273949, 0.022627511993050575, -0.0033773700706660748, 0.04102536663413048, -0.00804906152188778, 0.01008877344429493, 0.02810526452958584, -0.014272205531597137, -0.025146815925836563, 0.015566526912152767, -0.04849082976579666, 0.006257812958210707, -0.011937803588807583, -0.04208856076002121, -0.008522875607013702, -0.012446287088096142, -0.004850816447287798, 0.03275095671415329, -0.0014098858227953315, -0.026718491688370705, -0.020778480917215347, -0.0005778220947831869, -0.010504805482923985, -0.0009649628773331642, 0.009158479981124401, -0.02734254114329815, -0.04040132090449333, -0.005515311844646931, 0.014572672545909882, 0.018016492947936058, 0.009060249663889408, -0.00904869381338358, 0.004226768389344215, 0.01825917698442936, 0.021483425050973892, 0.01100173220038414, -0.0021133841946721077, -0.023020431399345398, 0.02551662176847458, -0.01216893270611763, -0.05209643766283989, 0.012654303573071957, -0.03459998592734337, -0.01593633182346821, -0.0428512841463089, 0.026857169345021248, 0.004547459539026022, 0.003261805512011051, -0.05140305310487747, -0.029376473277807236, 0.015092712827026844, -0.0175889041274786, -0.007049429230391979, 0.03741975873708725, -0.019819296896457672, -0.021795447915792465, -0.005093501415103674, -0.02500813826918602, 0.0013896620366722345, 0.010897723957896233, 0.014341543428599834, 0.0015658978372812271, -0.019045015797019005, 0.02142564207315445, 0.02523926831781864, 0.024869462475180626, 0.019622838124632835, 0.0035622729919850826, 0.01108840573579073, -0.011238639242947102, -0.010805272497236729, 0.0148731404915452, -0.008320637978613377, 0.030023634433746338, -0.02567841298878193, 0.01824762113392353, 0.018536532297730446, 0.006344486493617296, -0.015439406037330627, -0.004304774571210146, -0.009447391144931316, 0.006621840875595808, -0.043128639459609985, -0.0019703733269125223, 0.009343382902443409, -0.004047643393278122, -0.008788674138486385, -0.0030162311159074306, 0.005726216826587915, 4.9521157052367926e-05, 0.007419235538691282, -0.032311808317899704, -0.03880653157830238, -0.0020859376527369022, -0.04724273085594177, 0.002276618964970112, -0.0087944520637393, -0.019726846367120743, 0.005304406397044659, -0.0348542258143425, -0.015982558950781822, 0.02173766680061817, 0.020535796880722046, -0.02875242568552494, -0.005287072155624628, -0.009071806445717812, -0.015809211879968643, 0.010007877834141254, -0.0062635913491249084, 0.009204705245792866, -0.008863790892064571, -0.002369070425629616, 0.01832851581275463, 0.018120499327778816, -0.03728108108043671, 0.04812102019786835, 0.016028784215450287, 0.02875242568552494, -0.044723428785800934, -0.006252034567296505, 0.0195881687104702, 0.012792980298399925, 0.02593265473842621, 0.010943950153887272, -0.01690707355737686, 0.07275935262441635, 0.01138309482485056, 0.01255029533058405, 0.008806007914245129, -0.017207540571689606, 0.012804537080228329, -0.04682670161128044, 0.010054104030132294, 0.0171035323292017, -0.005538424476981163, -0.01624835655093193, 0.003986972384154797, -0.007852601818740368, 0.01312811765819788, -0.0007713924860581756, -0.0866733118891716, -0.0014272205298766494, -0.01004832610487938, -0.0019761514849960804, 0.011567997746169567, -0.018363185226917267, 0.012249828316271305, 0.010897723957896233, 0.010643482208251953, 0.04784366860985756, 0.016063453629612923, -0.006361821200698614, 0.04493144527077675, -0.02343646250665188, 0.04844460263848305, -0.029214683920145035, 0.021321633830666542, 0.003348478814586997, -0.00824552122503519, 0.043960701674222946, 0.03284340724349022, 0.0052466243505477905, -0.0013781056040897965, 0.006864526309072971, 0.01261963415890932, 0.03076324611902237, 0.016791509464383125, -0.0019703733269125223, -0.021367860957980156, 0.018028048798441887, -0.012977883219718933, 0.00828596856445074, 0.015947889536619186, 0.024360978975892067, 0.034623097628355026, 0.011527550406754017, -0.0042181010358035564, 0.006737405434250832, -0.003227136330679059, -0.023783156648278236, -0.03577874228358269, 0.0038136255461722612, -0.015312285162508488, -0.0009974653366953135, 0.005203287582844496, 0.01825917698442936, -0.008597992360591888, 0.011099961586296558, 0.018039604648947716, -0.008361085318028927, 0.010863054543733597, -0.01488469634205103, 0.005538424476981163, -0.010262119583785534, -0.0030884589068591595, -0.006101801060140133, -0.05653411149978638, -0.03711928799748421, -0.009614959359169006, -0.024291640147566795, 0.00487392907962203, 0.029353361576795578, 0.05066343769431114, -0.0064138248562812805, 0.017970265820622444, -0.010267898440361023, -0.008788674138486385, -0.03178021311759949, -0.020790038630366325, 0.05094079300761223, 0.002454299246892333, -0.025724638253450394, -0.007609916850924492, -0.0013188788434490561, -0.0015398957766592503, 0.005850448273122311, -0.02440720424056053, 0.02184167504310608, 0.0316646508872509, 0.009326048195362091, 0.0017580236308276653, -0.04148762300610542, 0.022292375564575195, -0.012943214736878872, -0.008025948889553547, -0.04241213947534561, -0.0024586329236626625, 0.040979139506816864, -0.021645214408636093, -0.010995954275131226, -0.01616746187210083, -0.009262488223612309, 7.480087515432388e-05, 0.007748594041913748, 0.008933128789067268, -0.014722906053066254, 0.042712606489658356, -0.007286336272954941, -0.05602562800049782, -0.003816514741629362, -0.027550555765628815, 0.014156640507280827, 0.019726846367120743, 0.0252623800188303, 0.021136730909347534, 0.02676471881568432, 0.03457687422633171, 0.03245048597455025, -0.03880653157830238, 0.013359245844185352, 0.009534063749015331, 0.0017710246611386538, 0.02300887554883957, 0.04044754430651665, 0.022442609071731567, 0.012342279776930809, -0.005567315500229597, 0.013625044375658035, 0.013301463797688484, -0.04077112674713135, 0.03226558491587639, 0.08708934485912323, -0.012480956502258778, -0.0006601617205888033, -0.0007222775602713227, -0.015728317201137543, -0.00016774896357674152, -0.02549351006746292, -0.02066291682422161, -0.00637337751686573, -0.009158479981124401, 0.0059140087105333805, 0.03841361030936241, -0.043036188930273056, -0.025377945974469185, 0.03041655384004116, 0.01701108179986477, -0.009528285823762417, -0.018779216334223747, -0.00456479424610734, -0.026626041159033775, 0.029538264498114586, -0.012896988540887833, 0.04058622196316719, 0.06050952896475792, 0.019484160467982292, 0.018224507570266724, -0.035131581127643585, 0.013971737585961819, -0.0003986972151324153, 0.020027313381433487, 0.0029194459784775972, 0.007598360069096088, 0.03515469655394554, -0.002163943601772189, -0.0006673844764009118, 0.01925303228199482, 0.00570599315688014, 0.049369119107723236, 0.02207280322909355, -0.004148762673139572, -0.024037398397922516, 0.06175762414932251, 0.035801853984594345, -0.016699057072401047, 0.013983294367790222, -0.01851341873407364, 0.032381147146224976, -0.014526447281241417, 0.006772074848413467, -0.026441138237714767, -0.0215874332934618, -0.005003938917070627, -0.014110415242612362, -0.022639067843556404, 0.026857169345021248, -0.007315227296203375, -0.015971001237630844, -0.005651099607348442, -0.013012552633881569, -0.017276879400014877, 0.03314387425780296, -0.01308189146220684, -0.011232861317694187, 0.010389240458607674, -0.009678519330918789, 0.00875400472432375, 0.011637336574494839, 0.042458366602659225, -0.0029194459784775972, 0.02759678289294243, -0.014318430796265602, 0.023020431399345398, 0.011695118620991707, 0.011099961586296558, 0.012665859423577785, 0.030370328575372696, 0.013393915258347988, 0.029653828591108322, 0.009031359106302261, -0.020061982795596123, 0.0012625412782654166, 0.020558908581733704, -0.04449230059981346, 0.0010220227995887399, -0.016953298822045326, 0.0054141925647854805, 0.00018580591131467372, -0.019796183332800865, 0.002071492141112685, -0.01792404055595398, 0.006176917813718319, -0.03806691616773605, 0.034715548157691956, -0.002241949550807476, -0.02567841298878193, 0.028382619842886925, -0.04675736278295517, -0.014722906053066254, 0.04340599477291107, 0.024152962490916252, -0.05242001637816429, -0.04053999483585358, 0.01859431341290474, 0.014179753139615059, 0.015589639544487, 0.02357514016330242, -0.04060933366417885, 0.007494352292269468, 0.022477278485894203, 0.0063675991259515285, -0.0005933510255999863, 0.030116086825728416, -0.011059514246881008, 0.005997793283313513, -0.011822239495813847, -0.011388872750103474, 0.01999264396727085, -0.006442715879529715, -0.0053217411041259766, 0.005495087709277868, 0.00783526711165905, -0.047704990953207016, -0.008817564696073532, 0.03344434127211571, 0.031641535460948944, -0.016953298822045326, -0.016317695379257202, 0.03894520923495293, 0.022974206134676933, -0.013983294367790222, 0.018952563405036926, -0.018201395869255066, 0.042620155960321426, -0.016317695379257202, 0.004729473497718573, -0.02399117313325405, -0.0007190273609012365, 0.022465722635388374, 0.014457108452916145, -0.00870777852833271, -0.01717287115752697, -0.020686030387878418, 0.02176077850162983, -0.0002840356610249728, 1.831650843087118e-05, -0.0029411143623292446, -0.026903396472334862, 0.017219098284840584, 0.05094079300761223, 0.026787830516695976, -0.020651360973715782, 0.00260308850556612, 0.010805272497236729, 0.05075589194893837, 0.002439853735268116, -0.01028523314744234, 0.014988704584538937, -0.009222039952874184, 0.016352364793419838, -0.023632923141121864, 0.006176917813718319, 0.04190365597605705, 0.01999264396727085, 0.01892945170402527, 0.002656536875292659, -0.0316646508872509, 0.03899143263697624, -0.0029151123017072678, 0.020374005660414696, -0.007887271232903004, 0.001103640184737742, 0.02632557414472103, 0.0069685340858995914, -0.03325943648815155, -0.015566526912152767, -0.01657193712890148, -0.017149759456515312, 0.012353835627436638, 0.00764458579942584, 0.012261384166777134, 0.02349424548447132, -0.00991542637348175, 0.0027952142991125584, 0.027134524658322334, -0.010533696040511131, -0.04708094149827957, 0.007817932404577732, 0.0052841827273368835, 0.009360717609524727, 0.01691862940788269, 0.025978880003094673, -0.01208803802728653, 0.020651360973715782, 0.018201395869255066, 0.007315227296203375, -0.005992014892399311, 0.0271807499229908, -0.002922335173934698, -0.013393915258347988, -0.0025193041656166315, 0.02567841298878193, -0.004232546780258417, -0.0035507166758179665, 0.008124178275465965, 0.022361714392900467, -0.0195881687104702, 0.003677837550640106, 0.012238271534442902, 0.04567105695605278, -0.002175500150769949, -0.03284340724349022, 0.017473340034484863, 0.007812154479324818, -0.0037298414390534163, -0.006471607368439436, 0.02951515093445778, -0.053067177534103394, -0.005974680185317993, -0.029307134449481964, -0.010637704282999039, 0.012515625916421413, -0.006662288680672646, 0.006049796938896179, 0.0067951874807477, 0.004509901162236929, 0.008476649411022663, 0.016352364793419838, 0.011868465691804886, 0.024545881897211075, -0.03298208490014076, 0.013960180804133415, -0.005105058196932077, -0.05144927650690079, -0.030185425654053688, -0.025377945974469185, -0.042134784162044525, -0.03492356464266777, -0.009274044074118137, 0.008730891160666943, 0.00862688384950161, -0.030393440276384354, -0.021471867337822914, -0.04419183358550072, -0.05154172703623772, -0.006494720000773668, -0.005402636248618364, -0.0431748665869236, 0.010891946032643318, -0.05357566103339195, -0.001176590216346085, -0.016791509464383125, 0.026533588767051697, 0.05357566103339195, 0.03325943648815155, -0.008470871485769749, -0.017357774078845978, 0.03702683746814728, -0.003700950415804982, 0.03619477525353432, 0.014191309921443462, 0.013047222048044205, 0.00837264209985733, 0.025562848895788193, 0.02741187810897827, -0.0005738495383411646, 0.0025828646030277014, 0.017716024070978165, -0.02433786541223526, -0.00921626202762127, 0.013659713789820671, -0.0351778082549572, 0.01858275756239891, -0.02258128672838211, 0.04400692880153656, -0.006483163684606552, 0.04144139960408211, 0.03681882098317146, 0.047335185110569, 0.01141198631376028, -0.03499290347099304, 0.034877341240644455, 0.03783578798174858, 0.02276618964970112, 0.028197716921567917, -0.021125175058841705, -0.001713242381811142, -0.007910383865237236, 0.003871407825499773, 0.02840573340654373, -0.011469768360257149, -0.0030248984694480896, -0.015346954576671124, -0.007997057400643826, 0.00011276558507233858, 0.005853337701410055, 0.005385301541537046, 0.04241213947534561, -0.005105058196932077, 0.011700896546244621, 0.009609181433916092, -0.05098702013492584, 0.011596889235079288, -0.011631558649241924, -0.010649261064827442, -0.03802069276571274, 0.00792194064706564, 0.007592582143843174, -0.0018056939588859677, -0.010487470775842667, 0.00941272173076868, 0.01378683466464281, -0.025632187724113464, 0.0010668040486052632, 0.01991174928843975, 0.032797180116176605, -0.006673844996839762, -0.004879707470536232, 0.01412197109311819, 0.009470503777265549, 0.02443031780421734, 0.0198308527469635, -0.015404736623167992, 0.04084046557545662, -0.022523503750562668, 0.017392443493008614, -0.03931501507759094, 0.004798812326043844, 0.11140409857034683, -0.009944317862391472, -0.029723167419433594, 0.0259095411747694, 0.0026305350475013256, 0.010614591650664806, -0.017820032313466072, -0.0008970687631517649, 0.02500813826918602, -0.009175814688205719, -0.006835635285824537, 0.009123810566961765, 0.033952824771404266, 0.036795709282159805, -0.027781685814261436, 0.04058622196316719, -0.0019761514849960804, -0.037304192781448364, 0.004527235869318247, -0.02750433050096035, 0.0024615221191197634, 0.01424909196794033, -0.028867989778518677, 0.009649628773331642, 0.0039667487144470215, 0.015474075451493263, 0.0030913481023162603, 0.03691127523779869, -0.03568629175424576, -0.012007142417132854, 0.07007826119661331, -0.006425381638109684, 0.036379676312208176, -0.004836370702832937, -0.028451958671212196, -0.008077952079474926, -0.005916898138821125, 0.007078320253640413, 0.016652831807732582, 0.0098749790340662, 0.005957345478236675, 0.011377316899597645, -0.007846823893487453, 0.014237536117434502, 0.021691439673304558, 0.0012639857595786452, 0.00647738529369235, 0.014665124006569386, -0.002526527037844062, 0.021483425050973892, 0.024545881897211075, 0.02349424548447132, -0.003986972384154797, -5.9181620599702e-05, -0.0036518354900181293, -0.03617165982723236, -0.03848294913768768, -0.009591846726834774, 0.01749645173549652, -0.006835635285824537, 0.011492880992591381, -0.018524976447224617, 0.016444815322756767, -0.020813150331377983, 0.00660450616851449, 0.011417764239013195, -0.024522768333554268, -0.004492566455155611, -0.038714077323675156, -0.02290486730635166, 0.0058388919569551945, -0.01867520995438099, 0.003955191932618618, -0.0013376581482589245, -0.0024095179978758097, 0.04509323462843895, 0.006211587227880955, -0.012145820073783398, -0.01891789399087429, 0.012642746791243553, 0.02373693138360977, -0.030069859698414803, 0.009950095787644386, -0.014584229327738285, 0.014191309921443462, 0.0028038816526532173, 0.01768135465681553, 0.01825917698442936, 0.016883959993720055, -0.01941482163965702, -0.007898828014731407, 0.00046948043745942414, 0.009279821999371052, -0.01632925122976303, 0.00038497394416481256, 0.003371591679751873, -0.043706461787223816, -0.004157429561018944, 0.008944685570895672, -0.027689233422279358, 0.006257812958210707, 0.00747701758518815, 0.0015658978372812271, 0.01333613321185112, -0.019726846367120743, 0.009516729041934013, 0.020316224545240402, 0.006107579451054335, 0.008765560574829578, -0.02325155958533287, 0.04601775109767914, -0.0017291324911639094, -0.020050425082445145, -0.0023502912372350693, 0.0045041232369840145, 0.020466458052396774, 0.007586803752928972, -0.004723695572465658, -0.02632557414472103, 0.04784366860985756, 0.008719335310161114, 0.03792824223637581, 0.01416819728910923, -0.030901923775672913, -0.004561905283480883, 0.005870672408491373, 0.035455163568258286, 0.003261805512011051, 0.03790512681007385, 0.024199187755584717, 0.01568209007382393, -0.0001714506361167878, 0.024384090676903725, 0.0003465126792434603, 0.007222775835543871, 0.03016231209039688, -0.014826914295554161, -0.014341543428599834, 0.011984029784798622, -0.011949360370635986, -0.011880021542310715, 0.04169563949108124, 0.005370856262743473, 0.008170404471457005, 0.018039604648947716, -0.01658349297940731, -0.017230654135346413, -0.044469185173511505, 0.02801281400024891, 0.02373693138360977, 0.0042007663287222385, 0.0046341330744326115, -0.06152649223804474, -0.025447284802794456, 0.00014553892833646387, -0.017438670620322227, 0.007095654960721731, 0.01600567065179348, -0.023043544963002205, -0.007586803752928972, -0.013174342922866344, 0.010325680486857891, -0.018467193469405174, 0.005437305662781, 0.01883699931204319, 0.025308607146143913, -0.010134998708963394, 0.025401057675480843, 0.01333613321185112, -0.0394999161362648, -0.023297786712646484, -0.03524714708328247, -0.006720070727169514, -0.04060933366417885, 0.0014069967437535524, -0.0028414400294423103, -0.010938172228634357, -0.005107947159558535, 0.02326311729848385, -0.015138938091695309, 0.0031115717720240355, 0.029376473277807236, -0.03677259758114815, -0.03381414711475372, 0.002500524977222085, 0.020790038630366325, 0.00014039270172361284, -0.026233121752738953, -0.014341543428599834, -0.03316698595881462, 0.034461308270692825, -0.005518200807273388, -0.013417028822004795, -0.014017963781952858, -0.005243735387921333, -0.012862319126725197, -0.037627771496772766, -0.007685033604502678, -0.01976151391863823, 0.012203602120280266, 0.0004698415577877313, -0.034877341240644455, 0.015578082762658596, -0.009349160827696323, 0.014399326406419277, -0.054546404629945755, -0.021529650315642357, 0.02000419981777668, -9.064583719009534e-05, -0.0015947888605296612, 0.04211167246103287, -0.0014821136137470603, -0.010759047232568264, 0.0028327726759016514, -0.005726216826587915, 0.019068127498030663, 0.027735458686947823, 0.023031987249851227, -0.023875607177615166, 0.0001475251920055598, -0.056719012558460236, -0.036379676312208176, 0.006644953973591328, -0.03235803544521332, 0.013705939054489136, -0.0062462566420435905, -0.03827493265271187, -0.03728108108043671, -0.0215874332934618, 0.04611020162701607, -0.006974312476813793, -0.011845352128148079, 0.0039118556305766106, -0.003435152117162943, 0.003412039251998067, 0.012319166213274002, -0.04678047448396683, 0.030485892668366432, -0.042458366602659225, -0.00917003583163023, 0.00937227439135313, -0.012561852112412453, -0.025193043053150177, -0.0044376733712852, -0.04169563949108124, 0.028821764513850212, 0.008782895281910896, 0.0002927029854618013, 0.008638439700007439, 0.015982558950781822, 0.0010357460705563426, -0.022350158542394638, 0.012573407962918282, -0.02551662176847458, -0.020790038630366325, -0.015439406037330627, -0.024938801303505898, 0.009817196987569332, -0.01565897837281227, 0.01834007166326046, -0.000212710743653588, 0.02523926831781864, 0.015959445387125015, 0.0036402789410203695, -0.01112885307520628, 0.001948704943060875, 0.004856594372540712, 0.00849976297467947, -0.0218301173299551, 0.006200030911713839, -0.047288957983255386, 0.015058043412864208, 0.006852969527244568, 0.006165361497551203, 0.0023950724862515926, -0.008349528536200523, 0.017877815291285515, 0.04315175116062164, 0.006893417332321405, -0.019807741045951843, -0.04507012292742729, 0.035640064626932144, -0.01616746187210083, 0.012249828316271305, -0.010337237268686295, 0.0021133841946721077, -0.002785102464258671, 0.010672373697161674, -0.05699636787176132, -0.020974941551685333, 0.07201974093914032, 0.018559643998742104, -0.02276618964970112, 0.022396383807063103, 0.01999264396727085, 0.01634080894291401, 0.010181224904954433, -0.039707932621240616, -0.013705939054489136, 0.037211742252111435, 0.0039002990815788507, -0.0351778082549572, 0.04835215210914612, -0.0014669457450509071, 0.019981086254119873, 0.01071859896183014, 0.010325680486857891, 0.010504805482923985, 0.007396122440695763, 0.04853705316781998, 0.027643008157610893, 0.029653828591108322, -0.014595785178244114, -0.01768135465681553, 0.033213213086128235, 0.010759047232568264, 0.018813885748386383, 0.01071859896183014, -0.0023127328604459763, 0.029977409169077873, 0.025216154754161835, 0.0030075637623667717, 0.010377684608101845, -0.011435098946094513, 0.01129642128944397, -0.013705939054489136, -0.041048478335142136, 0.005847559310495853, 0.009736302308738232, 0.0013513814192265272, 0.03143351897597313, -0.0031115717720240355, -0.011151965707540512, 0.01866365224123001, 0.03168776258826256, -0.005760886240750551, 0.013775277882814407, -0.029376473277807236, 0.004654356744140387, -0.026371799409389496, -0.0025221933610737324, 0.02891421690583229, -0.006344486493617296, -0.016467928886413574, 0.027851024642586708, -0.010146555490791798, -0.02159898914396763, -0.015497188083827496, -0.017115090042352676, -0.009811419062316418, 0.0036720591597259045, -0.019461046904325485, -0.008418867364525795, -0.024938801303505898, 0.008361085318028927, 0.0353395976126194, 0.021807005628943443, 0.003943635616451502, -0.022535061463713646, 0.0015615641605108976, -0.026302460581064224, 0.007349896710366011, -0.011648893356323242, 0.02408362366259098, -0.024314751848578453, 0.031387295573949814, -0.018964121118187904, 0.01642170362174511, -0.005908230785280466, -0.03360613062977791, -0.03386037424206734, 0.002503414172679186, -0.0048219249583780766, -0.0036749483551830053, -0.010776381939649582, 0.0037673998158425093, -0.009938539937138557, 0.02507747709751129, -0.00702631613239646, -0.01691862940788269, -0.009354939684271812, -0.022789303213357925, 0.027134524658322334, 0.0061249141581356525, 0.014896253123879433, -0.013578818179666996, 0.0393381267786026, 0.006899195723235607, 0.02549351006746292], index=0, object='embedding')\n",
      "{'data': [{'embedding': [0.029052894562482834, -0.0035276038106530905, 0.001942926668561995, 0.04784366860985756, -0.03261227905750275, -0.05057098716497421, -0.04615642875432968, 0.00412853853777051, -0.05177285894751549, 0.01625991240143776, 0.009528285823762417, 0.03226558491587639, -0.01474601961672306, -0.01288543175905943, 0.05408414453268051, -0.03658769279718399, -0.0191027969121933, 0.03074013441801071, -0.03219624608755112, 0.06374532729387283, 0.003227136330679059, 0.022685294970870018, -0.020478013902902603, -0.016375478357076645, 0.024522768333554268, 0.002929557813331485, 0.013752165250480175, 0.0195881687104702, 0.03251982480287552, -0.03124861791729927, -0.02050112746655941, -0.022303931415081024, 0.006223143544048071, -0.01546251866966486, -0.005968901794403791, 0.0022087248507887125, -0.019218362867832184, -0.022731520235538483, -0.015786098316311836, 0.0425277054309845, -1.4264982382883318e-05, 0.000839286542031914, -0.017612015828490257, 0.00656405882909894, 0.036379676312208176, -0.0009006801410578191, -0.03443819656968117, 0.05334453284740448, 0.005760886240750551, 0.026718491688370705, -0.03386037424206734, 0.025793977081775665, -0.00382229289971292, 0.12702840566635132, 0.025054365396499634, 0.0025048586539924145, 0.014387769624590874, -0.01104217953979969, 0.013856173492968082, 0.00673162704333663, -0.008690443821251392, -0.016941742971539497, 0.019310813397169113, 0.04793611913919449, -0.014480221085250378, -0.011105740442872047, 0.0278279110789299, 0.03175710141658783, -0.05385301634669304, -0.0018793662311509252, -0.013417028822004795, 0.03427640348672867, -0.007575247436761856, 0.005512422416359186, -0.05759730562567711, -0.009586067870259285, -0.020639805123209953, 0.0005283460486680269, 0.03302830830216408, -0.0024441874120384455, -0.021321633830666542, -0.025539735332131386, -0.06790564954280853, -0.05334453284740448, -0.0015167829114943743, -0.009730523452162743, -0.08912327885627747, 0.010441244579851627, 0.026048218831419945, -0.06466984748840332, 0.01583232544362545, 0.03658769279718399, -0.0732216089963913, 0.01391395553946495, 0.026649154722690582, 0.009187370538711548, 0.02542417123913765, 0.001217037788592279, 0.0016857958398759365, 0.06185007467865944, 0.002538083354011178, -0.016398590058088303, 0.025655299425125122, 0.013162787072360516, -0.009903870522975922, -0.047889892011880875, 0.018871668726205826, 0.011648893356323242, -0.006148026790469885, 0.007188106421381235, -0.07673477381467819, -0.014098858460783958, 0.034045275300741196, 0.007037872914224863, 0.0020050425082445145, 0.018189838156104088, -0.021691439673304558, -0.060370851308107376, -0.03309764713048935, -0.05311340466141701, 0.023135995492339134, 0.017045751214027405, 0.046133313328027725, -0.0008183405152522027, -0.004090980160981417, 0.005812889896333218, -0.016202131286263466, -0.029214683920145035, -0.01949571631848812, -0.0027518775314092636, 0.021275408565998077, -0.025447284802794456, -0.012365392409265041, -0.04534747451543808, -0.01229605358093977, -0.012411617673933506, -0.010371905751526356, 0.014468664303421974, -0.03249671310186386, 0.014965591952204704, 0.006379155442118645, 0.006737405434250832, -0.005076166708022356, -0.037396643310785294, 0.011394651606678963, -0.05302095413208008, 0.0029700053855776787, 0.028729313984513283, 0.00560487387701869, -0.03349056839942932, -0.028613748028874397, -0.010082995519042015, -0.011065292172133923, -0.02549351006746292, 0.004781477618962526, -0.011735565960407257, 0.02008509449660778, 0.0017912484472617507, -0.04899931326508522, 0.02674160525202751, 0.0018114722333848476, -0.0556558221578598, 0.014329987578094006, 0.006431159563362598, 0.04550926759839058, 0.027735458686947823, -0.042550817131996155, 0.003764510853216052, -0.017623573541641235, -0.001094972831197083, -0.0035998316016048193, 0.023378681391477585, -0.034461308270692825, -0.019865522161126137, -0.027319427579641342, -0.004530124831944704, -0.010637704282999039, -0.01442243903875351, 0.002889110241085291, -0.021367860957980156, -0.020189102739095688, 0.05912275239825249, 0.004053421784192324, -0.02607133239507675, 0.039731044322252274, -0.01004832610487938, 0.02849818393588066, 0.019530385732650757, -0.023401793092489243, 0.021136730909347534, -0.0236675925552845, 0.020963383838534355, -0.005862005054950714, -0.04243525117635727, 0.018721435219049454, -0.014410882256925106, 0.040979139506816864, 0.02250039204955101, 0.051634181290864944, 0.006610284559428692, -0.00660450616851449, 0.020304666832089424, 0.007442348171025515, -0.03402216359972954, -0.012353835627436638, -0.04158007726073265, 0.007673477288335562, 0.04756631329655647, 0.05385301634669304, -0.03175710141658783, 0.11621157824993134, -0.05944633483886719, -0.023066656664013863, 0.03034721501171589, -0.014826914295554161, 0.02868308685719967, 0.035385824739933014, -0.03016231209039688, 0.003383148228749633, -0.006067131645977497, -0.03658769279718399, -0.014769132249057293, 0.06878393888473511, 0.052789825946092606, 0.03889898210763931, 0.0001868893305072561, 0.0668424591422081, -0.012480956502258778, 0.0015456740511581302, 0.0016597938956692815, 0.003981193993240595, 0.016063453629612923, -0.01874454878270626, -0.029052894562482834, 0.01765824295580387, -0.02001575566828251, -0.05098702013492584, -0.010568365454673767, -0.02507747709751129, -0.024938801303505898, -0.02609444409608841, -0.03866785392165184, 0.0030191203113645315, 0.058475594967603683, 0.011781792156398296, -0.004977937322109938, 0.0428512841463089, -0.05126437544822693, -0.05690391734242439, 0.015034929849207401, 0.013417028822004795, -0.01541629247367382, 0.01741555705666542, -0.026857169345021248, 0.03716551512479782, 0.013509480282664299, 0.0251005906611681, 0.027897249907255173, 0.01874454878270626, 0.026394912973046303, 0.001277709030546248, -0.013833059929311275, -0.016652831807732582, -0.017542678862810135, -0.017716024070978165, 0.007280557882040739, 0.0001951955200638622, 0.02276618964970112, -0.03619477525353432, -0.007234332151710987, 0.019877079874277115, -0.02676471881568432, 0.05348321050405502, 0.04144139960408211, -0.05824446305632591, -0.008101065643131733, 0.02849818393588066, 0.011203969828784466, -0.011348425410687923, -0.025216154754161835, -0.043221089988946915, 0.006633397191762924, -0.026857169345021248, -0.009112253785133362, -0.007777485065162182, -0.004400114994496107, 0.0466880239546299, 0.040979139506816864, -0.025308607146143913, 0.030185425654053688, 0.031202392652630806, -0.05607185512781143, 0.036032985895872116, -0.05066343769431114, -0.031202392652630806, -0.01876766048371792, 0.008892681449651718, -0.010701265186071396, 0.01412197109311819, 0.016964856535196304, 0.055794499814510345, -0.03099437616765499, 0.009378052316606045, 0.0388527549803257, -0.059954818338155746, -0.01657193712890148, 0.022812414914369583, -0.019784627482295036, -0.003186688758432865, -0.03919944912195206, -0.011533328332006931, 0.011094183661043644, 0.0591689795255661, 0.013474810868501663, -0.04775121435523033, -0.07340651750564575, 0.02124073915183544, 0.0441456064581871, 0.03552450239658356, -0.04726584628224373, -0.022303931415081024, -0.043221089988946915, 0.05315963178873062, -0.0015832324279472232, 0.002445631893351674, 0.0017363553633913398, -0.012469400651752949, 0.015092712827026844, 0.0021682772785425186, 0.008459314703941345, -0.026371799409389496, 0.0018519196892157197, 0.00024340754316654056, 0.002184167504310608, 0.046803586184978485, -0.049970053136348724, 0.02884487807750702, 0.027226975187659264, -0.013844616711139679, 0.027619894593954086, -0.08838366717100143, -0.044307395815849304, 0.000612852512858808, 0.03249671310186386, -0.04426116868853569, -0.005350632593035698, -0.03466932475566864, 0.024545881897211075, -0.01573987305164337, 0.02449965663254261, -0.021795447915792465, 0.03302830830216408, 0.003882964374497533, -0.01042390987277031, 0.0070898765698075294, -0.04793611913919449, 0.018790774047374725, -0.022038133814930916, 0.018640540540218353, 0.01528917159885168, -0.032311808317899704, 0.04090980067849159, 0.013775277882814407, -0.019692176952958107, -0.0047468082047998905, 0.008378420025110245, -0.011868465691804886, -0.02267373725771904, 0.02074381150305271, 0.0023748488165438175, -0.0012603744398802519, -0.017380887642502785, 0.0003656530170701444, 0.027042072266340256, -0.029861845076084137, 0.016132792457938194, 0.019449491053819656, -0.005382412578910589, 0.030485892668366432, -0.007898828014731407, 0.05010873079299927, -0.016202131286263466, 0.03584808111190796, -0.03552450239658356, 0.03848294913768768, -0.013833059929311275, 0.02074381150305271, -0.013012552633881569, 0.010972840711474419, 0.013555705547332764, 0.05389924347400665, 0.02092871442437172, 0.04825969785451889, -0.037951353937387466, 0.024823235347867012, -0.030855698511004448, 0.040378205478191376, 0.03466932475566864, -0.040378205478191376, -0.02008509449660778, 0.01599411480128765, -0.030069859698414803, -0.06383778154850006, -0.002828438999131322, -0.018813885748386383, 0.038367386907339096, -0.0471733920276165, 0.030439667403697968, 0.002236171392723918, -0.02333245426416397, 0.029977409169077873, -0.03986972197890282, 0.06550191342830658, 0.02349424548447132, -0.002370515139773488, 0.0211020614951849, -0.0073094493709504604, 0.02810526452958584, -0.025216154754161835, -0.00030028691980987787, -0.03748909756541252, -0.04648000746965408, 0.027804797515273094, -0.00756369112059474, 0.003287807572633028, -0.0035333819687366486, 0.04241213947534561, 0.001617901842109859, 0.01528917159885168, -0.0197499580681324, 0.0098749790340662, 0.0292609091848135, -0.01658349297940731, -0.003247360000386834, -0.004865261726081371, -0.010995954275131226, -0.019541941583156586, -0.02907600626349449, -0.03360613062977791, -0.03728108108043671, 0.018212951719760895, -0.01125597395002842, -0.003773178206756711, -0.012099593877792358, -0.011891578324139118, -0.017519565299153328, 0.0030740133952349424, 0.003322476986795664, -0.025539735332131386, 0.011013288982212543, -0.006448494270443916, -0.007153437007218599, 0.011672005988657475, -0.007904605939984322, -0.012076481245458126, 0.01842096820473671, -0.002445631893351674, 0.00450123380869627, 0.035963647067546844, 0.04275883361697197, -0.02484634891152382, 0.06790564954280853, 0.0056626563891768456, 0.02099805325269699, 0.04081735014915466, 0.016225242987275124, 0.004411671310663223, 0.018894782289862633, -0.002291064476594329, 0.0017926929285749793, -0.0162368007004261, 0.028475072234869003, -0.008557545021176338, -0.026810944080352783, -0.012365392409265041, -0.017484895884990692, -0.010227450169622898, 0.022777745500206947, -0.024545881897211075, -0.055702049285173416, -0.040470656007528305, -0.004359667655080557, 0.0030191203113645315, 0.01965750753879547, 0.015242946334183216, 0.0046630240976810455, -0.01909124106168747, -0.009054471738636494, -0.01055103074759245, -0.005411303602159023, 0.01643325947225094, 0.04474654048681259, 0.026695379987359047, -0.00849976297467947, -0.00941272173076868, 0.04017018899321556, -0.05200398713350296, -0.032288696616888046, -0.0078757144510746, -0.04756631329655647, -0.020223772153258324, -0.008904238231480122, -0.008187739178538322, 0.0355013869702816, 0.002149498090147972, -0.01850186288356781, -0.0012090926757082343, -0.05611807852983475, -0.04199610650539398, 0.0353395976126194, 0.010065660811960697, 0.03825182095170021, -0.0176697988063097, 0.024961913004517555, -0.012896988540887833, -0.0129547705873847, 0.019461046904325485, 0.03926878795027733, 0.027111411094665527, 0.004443451762199402, 0.026210008189082146, -0.005815779324620962, 0.03924567624926567, -0.025031251832842827, -0.004073645453900099, -0.06166516989469528, 0.02260439842939377, 0.009545620530843735, -0.016017228364944458, -0.002344513079151511, -0.01576298661530018, -0.06582549214363098, 0.04453852400183678, 0.0004597296938300133, -0.0035304927732795477, -0.021182956174016, -0.009857644326984882, 0.027203863486647606, 0.019900191575288773, -0.03240426257252693, 0.057135045528411865, 0.019692176952958107, 0.03282029181718826, -0.011458211578428745, 0.006344486493617296, -0.04400692880153656, 0.010163890197873116, 0.024638332426548004, 0.03753532096743584, 0.021795447915792465, -0.01437621284276247, -0.037304192781448364, 0.04340599477291107, -0.02260439842939377, 0.009955874644219875, -0.02276618964970112, 0.00650049839168787, 0.006535167805850506, 0.039291899651288986, -0.007471239194273949, 0.022627511993050575, -0.0033773700706660748, 0.04102536663413048, -0.00804906152188778, 0.01008877344429493, 0.02810526452958584, -0.014272205531597137, -0.025146815925836563, 0.015566526912152767, -0.04849082976579666, 0.006257812958210707, -0.011937803588807583, -0.04208856076002121, -0.008522875607013702, -0.012446287088096142, -0.004850816447287798, 0.03275095671415329, -0.0014098858227953315, -0.026718491688370705, -0.020778480917215347, -0.0005778220947831869, -0.010504805482923985, -0.0009649628773331642, 0.009158479981124401, -0.02734254114329815, -0.04040132090449333, -0.005515311844646931, 0.014572672545909882, 0.018016492947936058, 0.009060249663889408, -0.00904869381338358, 0.004226768389344215, 0.01825917698442936, 0.021483425050973892, 0.01100173220038414, -0.0021133841946721077, -0.023020431399345398, 0.02551662176847458, -0.01216893270611763, -0.05209643766283989, 0.012654303573071957, -0.03459998592734337, -0.01593633182346821, -0.0428512841463089, 0.026857169345021248, 0.004547459539026022, 0.003261805512011051, -0.05140305310487747, -0.029376473277807236, 0.015092712827026844, -0.0175889041274786, -0.007049429230391979, 0.03741975873708725, -0.019819296896457672, -0.021795447915792465, -0.005093501415103674, -0.02500813826918602, 0.0013896620366722345, 0.010897723957896233, 0.014341543428599834, 0.0015658978372812271, -0.019045015797019005, 0.02142564207315445, 0.02523926831781864, 0.024869462475180626, 0.019622838124632835, 0.0035622729919850826, 0.01108840573579073, -0.011238639242947102, -0.010805272497236729, 0.0148731404915452, -0.008320637978613377, 0.030023634433746338, -0.02567841298878193, 0.01824762113392353, 0.018536532297730446, 0.006344486493617296, -0.015439406037330627, -0.004304774571210146, -0.009447391144931316, 0.006621840875595808, -0.043128639459609985, -0.0019703733269125223, 0.009343382902443409, -0.004047643393278122, -0.008788674138486385, -0.0030162311159074306, 0.005726216826587915, 4.9521157052367926e-05, 0.007419235538691282, -0.032311808317899704, -0.03880653157830238, -0.0020859376527369022, -0.04724273085594177, 0.002276618964970112, -0.0087944520637393, -0.019726846367120743, 0.005304406397044659, -0.0348542258143425, -0.015982558950781822, 0.02173766680061817, 0.020535796880722046, -0.02875242568552494, -0.005287072155624628, -0.009071806445717812, -0.015809211879968643, 0.010007877834141254, -0.0062635913491249084, 0.009204705245792866, -0.008863790892064571, -0.002369070425629616, 0.01832851581275463, 0.018120499327778816, -0.03728108108043671, 0.04812102019786835, 0.016028784215450287, 0.02875242568552494, -0.044723428785800934, -0.006252034567296505, 0.0195881687104702, 0.012792980298399925, 0.02593265473842621, 0.010943950153887272, -0.01690707355737686, 0.07275935262441635, 0.01138309482485056, 0.01255029533058405, 0.008806007914245129, -0.017207540571689606, 0.012804537080228329, -0.04682670161128044, 0.010054104030132294, 0.0171035323292017, -0.005538424476981163, -0.01624835655093193, 0.003986972384154797, -0.007852601818740368, 0.01312811765819788, -0.0007713924860581756, -0.0866733118891716, -0.0014272205298766494, -0.01004832610487938, -0.0019761514849960804, 0.011567997746169567, -0.018363185226917267, 0.012249828316271305, 0.010897723957896233, 0.010643482208251953, 0.04784366860985756, 0.016063453629612923, -0.006361821200698614, 0.04493144527077675, -0.02343646250665188, 0.04844460263848305, -0.029214683920145035, 0.021321633830666542, 0.003348478814586997, -0.00824552122503519, 0.043960701674222946, 0.03284340724349022, 0.0052466243505477905, -0.0013781056040897965, 0.006864526309072971, 0.01261963415890932, 0.03076324611902237, 0.016791509464383125, -0.0019703733269125223, -0.021367860957980156, 0.018028048798441887, -0.012977883219718933, 0.00828596856445074, 0.015947889536619186, 0.024360978975892067, 0.034623097628355026, 0.011527550406754017, -0.0042181010358035564, 0.006737405434250832, -0.003227136330679059, -0.023783156648278236, -0.03577874228358269, 0.0038136255461722612, -0.015312285162508488, -0.0009974653366953135, 0.005203287582844496, 0.01825917698442936, -0.008597992360591888, 0.011099961586296558, 0.018039604648947716, -0.008361085318028927, 0.010863054543733597, -0.01488469634205103, 0.005538424476981163, -0.010262119583785534, -0.0030884589068591595, -0.006101801060140133, -0.05653411149978638, -0.03711928799748421, -0.009614959359169006, -0.024291640147566795, 0.00487392907962203, 0.029353361576795578, 0.05066343769431114, -0.0064138248562812805, 0.017970265820622444, -0.010267898440361023, -0.008788674138486385, -0.03178021311759949, -0.020790038630366325, 0.05094079300761223, 0.002454299246892333, -0.025724638253450394, -0.007609916850924492, -0.0013188788434490561, -0.0015398957766592503, 0.005850448273122311, -0.02440720424056053, 0.02184167504310608, 0.0316646508872509, 0.009326048195362091, 0.0017580236308276653, -0.04148762300610542, 0.022292375564575195, -0.012943214736878872, -0.008025948889553547, -0.04241213947534561, -0.0024586329236626625, 0.040979139506816864, -0.021645214408636093, -0.010995954275131226, -0.01616746187210083, -0.009262488223612309, 7.480087515432388e-05, 0.007748594041913748, 0.008933128789067268, -0.014722906053066254, 0.042712606489658356, -0.007286336272954941, -0.05602562800049782, -0.003816514741629362, -0.027550555765628815, 0.014156640507280827, 0.019726846367120743, 0.0252623800188303, 0.021136730909347534, 0.02676471881568432, 0.03457687422633171, 0.03245048597455025, -0.03880653157830238, 0.013359245844185352, 0.009534063749015331, 0.0017710246611386538, 0.02300887554883957, 0.04044754430651665, 0.022442609071731567, 0.012342279776930809, -0.005567315500229597, 0.013625044375658035, 0.013301463797688484, -0.04077112674713135, 0.03226558491587639, 0.08708934485912323, -0.012480956502258778, -0.0006601617205888033, -0.0007222775602713227, -0.015728317201137543, -0.00016774896357674152, -0.02549351006746292, -0.02066291682422161, -0.00637337751686573, -0.009158479981124401, 0.0059140087105333805, 0.03841361030936241, -0.043036188930273056, -0.025377945974469185, 0.03041655384004116, 0.01701108179986477, -0.009528285823762417, -0.018779216334223747, -0.00456479424610734, -0.026626041159033775, 0.029538264498114586, -0.012896988540887833, 0.04058622196316719, 0.06050952896475792, 0.019484160467982292, 0.018224507570266724, -0.035131581127643585, 0.013971737585961819, -0.0003986972151324153, 0.020027313381433487, 0.0029194459784775972, 0.007598360069096088, 0.03515469655394554, -0.002163943601772189, -0.0006673844764009118, 0.01925303228199482, 0.00570599315688014, 0.049369119107723236, 0.02207280322909355, -0.004148762673139572, -0.024037398397922516, 0.06175762414932251, 0.035801853984594345, -0.016699057072401047, 0.013983294367790222, -0.01851341873407364, 0.032381147146224976, -0.014526447281241417, 0.006772074848413467, -0.026441138237714767, -0.0215874332934618, -0.005003938917070627, -0.014110415242612362, -0.022639067843556404, 0.026857169345021248, -0.007315227296203375, -0.015971001237630844, -0.005651099607348442, -0.013012552633881569, -0.017276879400014877, 0.03314387425780296, -0.01308189146220684, -0.011232861317694187, 0.010389240458607674, -0.009678519330918789, 0.00875400472432375, 0.011637336574494839, 0.042458366602659225, -0.0029194459784775972, 0.02759678289294243, -0.014318430796265602, 0.023020431399345398, 0.011695118620991707, 0.011099961586296558, 0.012665859423577785, 0.030370328575372696, 0.013393915258347988, 0.029653828591108322, 0.009031359106302261, -0.020061982795596123, 0.0012625412782654166, 0.020558908581733704, -0.04449230059981346, 0.0010220227995887399, -0.016953298822045326, 0.0054141925647854805, 0.00018580591131467372, -0.019796183332800865, 0.002071492141112685, -0.01792404055595398, 0.006176917813718319, -0.03806691616773605, 0.034715548157691956, -0.002241949550807476, -0.02567841298878193, 0.028382619842886925, -0.04675736278295517, -0.014722906053066254, 0.04340599477291107, 0.024152962490916252, -0.05242001637816429, -0.04053999483585358, 0.01859431341290474, 0.014179753139615059, 0.015589639544487, 0.02357514016330242, -0.04060933366417885, 0.007494352292269468, 0.022477278485894203, 0.0063675991259515285, -0.0005933510255999863, 0.030116086825728416, -0.011059514246881008, 0.005997793283313513, -0.011822239495813847, -0.011388872750103474, 0.01999264396727085, -0.006442715879529715, -0.0053217411041259766, 0.005495087709277868, 0.00783526711165905, -0.047704990953207016, -0.008817564696073532, 0.03344434127211571, 0.031641535460948944, -0.016953298822045326, -0.016317695379257202, 0.03894520923495293, 0.022974206134676933, -0.013983294367790222, 0.018952563405036926, -0.018201395869255066, 0.042620155960321426, -0.016317695379257202, 0.004729473497718573, -0.02399117313325405, -0.0007190273609012365, 0.022465722635388374, 0.014457108452916145, -0.00870777852833271, -0.01717287115752697, -0.020686030387878418, 0.02176077850162983, -0.0002840356610249728, 1.831650843087118e-05, -0.0029411143623292446, -0.026903396472334862, 0.017219098284840584, 0.05094079300761223, 0.026787830516695976, -0.020651360973715782, 0.00260308850556612, 0.010805272497236729, 0.05075589194893837, 0.002439853735268116, -0.01028523314744234, 0.014988704584538937, -0.009222039952874184, 0.016352364793419838, -0.023632923141121864, 0.006176917813718319, 0.04190365597605705, 0.01999264396727085, 0.01892945170402527, 0.002656536875292659, -0.0316646508872509, 0.03899143263697624, -0.0029151123017072678, 0.020374005660414696, -0.007887271232903004, 0.001103640184737742, 0.02632557414472103, 0.0069685340858995914, -0.03325943648815155, -0.015566526912152767, -0.01657193712890148, -0.017149759456515312, 0.012353835627436638, 0.00764458579942584, 0.012261384166777134, 0.02349424548447132, -0.00991542637348175, 0.0027952142991125584, 0.027134524658322334, -0.010533696040511131, -0.04708094149827957, 0.007817932404577732, 0.0052841827273368835, 0.009360717609524727, 0.01691862940788269, 0.025978880003094673, -0.01208803802728653, 0.020651360973715782, 0.018201395869255066, 0.007315227296203375, -0.005992014892399311, 0.0271807499229908, -0.002922335173934698, -0.013393915258347988, -0.0025193041656166315, 0.02567841298878193, -0.004232546780258417, -0.0035507166758179665, 0.008124178275465965, 0.022361714392900467, -0.0195881687104702, 0.003677837550640106, 0.012238271534442902, 0.04567105695605278, -0.002175500150769949, -0.03284340724349022, 0.017473340034484863, 0.007812154479324818, -0.0037298414390534163, -0.006471607368439436, 0.02951515093445778, -0.053067177534103394, -0.005974680185317993, -0.029307134449481964, -0.010637704282999039, 0.012515625916421413, -0.006662288680672646, 0.006049796938896179, 0.0067951874807477, 0.004509901162236929, 0.008476649411022663, 0.016352364793419838, 0.011868465691804886, 0.024545881897211075, -0.03298208490014076, 0.013960180804133415, -0.005105058196932077, -0.05144927650690079, -0.030185425654053688, -0.025377945974469185, -0.042134784162044525, -0.03492356464266777, -0.009274044074118137, 0.008730891160666943, 0.00862688384950161, -0.030393440276384354, -0.021471867337822914, -0.04419183358550072, -0.05154172703623772, -0.006494720000773668, -0.005402636248618364, -0.0431748665869236, 0.010891946032643318, -0.05357566103339195, -0.001176590216346085, -0.016791509464383125, 0.026533588767051697, 0.05357566103339195, 0.03325943648815155, -0.008470871485769749, -0.017357774078845978, 0.03702683746814728, -0.003700950415804982, 0.03619477525353432, 0.014191309921443462, 0.013047222048044205, 0.00837264209985733, 0.025562848895788193, 0.02741187810897827, -0.0005738495383411646, 0.0025828646030277014, 0.017716024070978165, -0.02433786541223526, -0.00921626202762127, 0.013659713789820671, -0.0351778082549572, 0.01858275756239891, -0.02258128672838211, 0.04400692880153656, -0.006483163684606552, 0.04144139960408211, 0.03681882098317146, 0.047335185110569, 0.01141198631376028, -0.03499290347099304, 0.034877341240644455, 0.03783578798174858, 0.02276618964970112, 0.028197716921567917, -0.021125175058841705, -0.001713242381811142, -0.007910383865237236, 0.003871407825499773, 0.02840573340654373, -0.011469768360257149, -0.0030248984694480896, -0.015346954576671124, -0.007997057400643826, 0.00011276558507233858, 0.005853337701410055, 0.005385301541537046, 0.04241213947534561, -0.005105058196932077, 0.011700896546244621, 0.009609181433916092, -0.05098702013492584, 0.011596889235079288, -0.011631558649241924, -0.010649261064827442, -0.03802069276571274, 0.00792194064706564, 0.007592582143843174, -0.0018056939588859677, -0.010487470775842667, 0.00941272173076868, 0.01378683466464281, -0.025632187724113464, 0.0010668040486052632, 0.01991174928843975, 0.032797180116176605, -0.006673844996839762, -0.004879707470536232, 0.01412197109311819, 0.009470503777265549, 0.02443031780421734, 0.0198308527469635, -0.015404736623167992, 0.04084046557545662, -0.022523503750562668, 0.017392443493008614, -0.03931501507759094, 0.004798812326043844, 0.11140409857034683, -0.009944317862391472, -0.029723167419433594, 0.0259095411747694, 0.0026305350475013256, 0.010614591650664806, -0.017820032313466072, -0.0008970687631517649, 0.02500813826918602, -0.009175814688205719, -0.006835635285824537, 0.009123810566961765, 0.033952824771404266, 0.036795709282159805, -0.027781685814261436, 0.04058622196316719, -0.0019761514849960804, -0.037304192781448364, 0.004527235869318247, -0.02750433050096035, 0.0024615221191197634, 0.01424909196794033, -0.028867989778518677, 0.009649628773331642, 0.0039667487144470215, 0.015474075451493263, 0.0030913481023162603, 0.03691127523779869, -0.03568629175424576, -0.012007142417132854, 0.07007826119661331, -0.006425381638109684, 0.036379676312208176, -0.004836370702832937, -0.028451958671212196, -0.008077952079474926, -0.005916898138821125, 0.007078320253640413, 0.016652831807732582, 0.0098749790340662, 0.005957345478236675, 0.011377316899597645, -0.007846823893487453, 0.014237536117434502, 0.021691439673304558, 0.0012639857595786452, 0.00647738529369235, 0.014665124006569386, -0.002526527037844062, 0.021483425050973892, 0.024545881897211075, 0.02349424548447132, -0.003986972384154797, -5.9181620599702e-05, -0.0036518354900181293, -0.03617165982723236, -0.03848294913768768, -0.009591846726834774, 0.01749645173549652, -0.006835635285824537, 0.011492880992591381, -0.018524976447224617, 0.016444815322756767, -0.020813150331377983, 0.00660450616851449, 0.011417764239013195, -0.024522768333554268, -0.004492566455155611, -0.038714077323675156, -0.02290486730635166, 0.0058388919569551945, -0.01867520995438099, 0.003955191932618618, -0.0013376581482589245, -0.0024095179978758097, 0.04509323462843895, 0.006211587227880955, -0.012145820073783398, -0.01891789399087429, 0.012642746791243553, 0.02373693138360977, -0.030069859698414803, 0.009950095787644386, -0.014584229327738285, 0.014191309921443462, 0.0028038816526532173, 0.01768135465681553, 0.01825917698442936, 0.016883959993720055, -0.01941482163965702, -0.007898828014731407, 0.00046948043745942414, 0.009279821999371052, -0.01632925122976303, 0.00038497394416481256, 0.003371591679751873, -0.043706461787223816, -0.004157429561018944, 0.008944685570895672, -0.027689233422279358, 0.006257812958210707, 0.00747701758518815, 0.0015658978372812271, 0.01333613321185112, -0.019726846367120743, 0.009516729041934013, 0.020316224545240402, 0.006107579451054335, 0.008765560574829578, -0.02325155958533287, 0.04601775109767914, -0.0017291324911639094, -0.020050425082445145, -0.0023502912372350693, 0.0045041232369840145, 0.020466458052396774, 0.007586803752928972, -0.004723695572465658, -0.02632557414472103, 0.04784366860985756, 0.008719335310161114, 0.03792824223637581, 0.01416819728910923, -0.030901923775672913, -0.004561905283480883, 0.005870672408491373, 0.035455163568258286, 0.003261805512011051, 0.03790512681007385, 0.024199187755584717, 0.01568209007382393, -0.0001714506361167878, 0.024384090676903725, 0.0003465126792434603, 0.007222775835543871, 0.03016231209039688, -0.014826914295554161, -0.014341543428599834, 0.011984029784798622, -0.011949360370635986, -0.011880021542310715, 0.04169563949108124, 0.005370856262743473, 0.008170404471457005, 0.018039604648947716, -0.01658349297940731, -0.017230654135346413, -0.044469185173511505, 0.02801281400024891, 0.02373693138360977, 0.0042007663287222385, 0.0046341330744326115, -0.06152649223804474, -0.025447284802794456, 0.00014553892833646387, -0.017438670620322227, 0.007095654960721731, 0.01600567065179348, -0.023043544963002205, -0.007586803752928972, -0.013174342922866344, 0.010325680486857891, -0.018467193469405174, 0.005437305662781, 0.01883699931204319, 0.025308607146143913, -0.010134998708963394, 0.025401057675480843, 0.01333613321185112, -0.0394999161362648, -0.023297786712646484, -0.03524714708328247, -0.006720070727169514, -0.04060933366417885, 0.0014069967437535524, -0.0028414400294423103, -0.010938172228634357, -0.005107947159558535, 0.02326311729848385, -0.015138938091695309, 0.0031115717720240355, 0.029376473277807236, -0.03677259758114815, -0.03381414711475372, 0.002500524977222085, 0.020790038630366325, 0.00014039270172361284, -0.026233121752738953, -0.014341543428599834, -0.03316698595881462, 0.034461308270692825, -0.005518200807273388, -0.013417028822004795, -0.014017963781952858, -0.005243735387921333, -0.012862319126725197, -0.037627771496772766, -0.007685033604502678, -0.01976151391863823, 0.012203602120280266, 0.0004698415577877313, -0.034877341240644455, 0.015578082762658596, -0.009349160827696323, 0.014399326406419277, -0.054546404629945755, -0.021529650315642357, 0.02000419981777668, -9.064583719009534e-05, -0.0015947888605296612, 0.04211167246103287, -0.0014821136137470603, -0.010759047232568264, 0.0028327726759016514, -0.005726216826587915, 0.019068127498030663, 0.027735458686947823, 0.023031987249851227, -0.023875607177615166, 0.0001475251920055598, -0.056719012558460236, -0.036379676312208176, 0.006644953973591328, -0.03235803544521332, 0.013705939054489136, -0.0062462566420435905, -0.03827493265271187, -0.03728108108043671, -0.0215874332934618, 0.04611020162701607, -0.006974312476813793, -0.011845352128148079, 0.0039118556305766106, -0.003435152117162943, 0.003412039251998067, 0.012319166213274002, -0.04678047448396683, 0.030485892668366432, -0.042458366602659225, -0.00917003583163023, 0.00937227439135313, -0.012561852112412453, -0.025193043053150177, -0.0044376733712852, -0.04169563949108124, 0.028821764513850212, 0.008782895281910896, 0.0002927029854618013, 0.008638439700007439, 0.015982558950781822, 0.0010357460705563426, -0.022350158542394638, 0.012573407962918282, -0.02551662176847458, -0.020790038630366325, -0.015439406037330627, -0.024938801303505898, 0.009817196987569332, -0.01565897837281227, 0.01834007166326046, -0.000212710743653588, 0.02523926831781864, 0.015959445387125015, 0.0036402789410203695, -0.01112885307520628, 0.001948704943060875, 0.004856594372540712, 0.00849976297467947, -0.0218301173299551, 0.006200030911713839, -0.047288957983255386, 0.015058043412864208, 0.006852969527244568, 0.006165361497551203, 0.0023950724862515926, -0.008349528536200523, 0.017877815291285515, 0.04315175116062164, 0.006893417332321405, -0.019807741045951843, -0.04507012292742729, 0.035640064626932144, -0.01616746187210083, 0.012249828316271305, -0.010337237268686295, 0.0021133841946721077, -0.002785102464258671, 0.010672373697161674, -0.05699636787176132, -0.020974941551685333, 0.07201974093914032, 0.018559643998742104, -0.02276618964970112, 0.022396383807063103, 0.01999264396727085, 0.01634080894291401, 0.010181224904954433, -0.039707932621240616, -0.013705939054489136, 0.037211742252111435, 0.0039002990815788507, -0.0351778082549572, 0.04835215210914612, -0.0014669457450509071, 0.019981086254119873, 0.01071859896183014, 0.010325680486857891, 0.010504805482923985, 0.007396122440695763, 0.04853705316781998, 0.027643008157610893, 0.029653828591108322, -0.014595785178244114, -0.01768135465681553, 0.033213213086128235, 0.010759047232568264, 0.018813885748386383, 0.01071859896183014, -0.0023127328604459763, 0.029977409169077873, 0.025216154754161835, 0.0030075637623667717, 0.010377684608101845, -0.011435098946094513, 0.01129642128944397, -0.013705939054489136, -0.041048478335142136, 0.005847559310495853, 0.009736302308738232, 0.0013513814192265272, 0.03143351897597313, -0.0031115717720240355, -0.011151965707540512, 0.01866365224123001, 0.03168776258826256, -0.005760886240750551, 0.013775277882814407, -0.029376473277807236, 0.004654356744140387, -0.026371799409389496, -0.0025221933610737324, 0.02891421690583229, -0.006344486493617296, -0.016467928886413574, 0.027851024642586708, -0.010146555490791798, -0.02159898914396763, -0.015497188083827496, -0.017115090042352676, -0.009811419062316418, 0.0036720591597259045, -0.019461046904325485, -0.008418867364525795, -0.024938801303505898, 0.008361085318028927, 0.0353395976126194, 0.021807005628943443, 0.003943635616451502, -0.022535061463713646, 0.0015615641605108976, -0.026302460581064224, 0.007349896710366011, -0.011648893356323242, 0.02408362366259098, -0.024314751848578453, 0.031387295573949814, -0.018964121118187904, 0.01642170362174511, -0.005908230785280466, -0.03360613062977791, -0.03386037424206734, 0.002503414172679186, -0.0048219249583780766, -0.0036749483551830053, -0.010776381939649582, 0.0037673998158425093, -0.009938539937138557, 0.02507747709751129, -0.00702631613239646, -0.01691862940788269, -0.009354939684271812, -0.022789303213357925, 0.027134524658322334, 0.0061249141581356525, 0.014896253123879433, -0.013578818179666996, 0.0393381267786026, 0.006899195723235607, 0.02549351006746292], 'index': 0, 'object': 'embedding'}], 'model': 'text-embedding-3-small', 'object': 'list', 'usage': {'prompt_tokens': 2, 'total_tokens': 2, 'cost': 4e-08}, 'provider': 'OpenAI', 'id': 'gen-emb-1765551223-zI9H3Feg69NeG5kyBO1K'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\ndata=[Embedding(embedding=[inside the list we have 1536 float numbers fixed for openai embedding model]\\nindex=0, object='embedding')], model='text-embedding-3-small',\\nobject='list', usage=Usage(prompt_tokens=2, total_tokens=2, cost=4e-08),\\nprovider='OpenAI', id='gen-emb-1765550110-Wixyb0kqKn6e0fIjuW3q'\\n\\n\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=\"Help me\"\n",
    "  )\n",
    "\n",
    "print(response.data[0])\n",
    "\n",
    "response_dict = response.model_dump()\n",
    "print(response_dict)\n",
    "'''\n",
    "\n",
    "data=[Embedding(embedding=[inside the list we have 1536 float numbers fixed for openai embedding model]\n",
    "index=0, object='embedding')], model='text-embedding-3-small',\n",
    "object='list', usage=Usage(prompt_tokens=2, total_tokens=2, cost=4e-08),\n",
    "provider='OpenAI', id='gen-emb-1765550110-Wixyb0kqKn6e0fIjuW3q'\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a create_embeddings function\n",
    "def create_embeddings(texts):\n",
    "  response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=texts\n",
    "  )\n",
    "  response_dict = response.model_dump()\n",
    "  \n",
    "  return [data['embedding'] for data in response_dict['data']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "206208bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.012280828319489956,\n",
       "  0.0064641619101166725,\n",
       "  0.005881416145712137,\n",
       "  0.04381385073065758,\n",
       "  -0.023633580654859543,\n",
       "  -0.042583610862493515,\n",
       "  -0.03729573264718056,\n",
       "  -0.001110859215259552,\n",
       "  -0.05093630030751228,\n",
       "  -0.011957081034779549,\n",
       "  -0.004200626164674759,\n",
       "  0.03129560872912407,\n",
       "  -0.02479907125234604,\n",
       "  -0.03250426799058914,\n",
       "  0.0615120567381382,\n",
       "  -0.03472733497619629,\n",
       "  -0.02857612818479538,\n",
       "  0.02088172547519207,\n",
       "  -0.01420173142105341,\n",
       "  0.03602232411503792,\n",
       "  0.0037123067304491997,\n",
       "  0.018809739500284195,\n",
       "  -0.008374272845685482,\n",
       "  -0.01673775538802147,\n",
       "  0.044547680765390396,\n",
       "  0.01016028132289648,\n",
       "  0.02259758859872818,\n",
       "  0.02279183641076088,\n",
       "  0.04266994446516037,\n",
       "  -0.028079714626073837,\n",
       "  0.009059539064764977,\n",
       "  -0.04424551501870155,\n",
       "  0.008115274831652641,\n",
       "  -0.020719850435853004,\n",
       "  -0.009922866709530354,\n",
       "  -0.0009314490598626435,\n",
       "  -0.018572324886918068,\n",
       "  -0.014018273912370205,\n",
       "  -0.022468088194727898,\n",
       "  0.024000493809580803,\n",
       "  -0.02566239982843399,\n",
       "  -0.0030890924390405416,\n",
       "  0.010192655958235264,\n",
       "  -0.011730457656085491,\n",
       "  0.02443215809762478,\n",
       "  -0.008832915686070919,\n",
       "  -0.01147145964205265,\n",
       "  0.05046147108078003,\n",
       "  0.00212324527092278,\n",
       "  0.00751094613224268,\n",
       "  -0.0303675327450037,\n",
       "  0.03772739693522453,\n",
       "  -0.02207959070801735,\n",
       "  0.16998910903930664,\n",
       "  0.03019486740231514,\n",
       "  0.030820779502391815,\n",
       "  0.03397192433476448,\n",
       "  -0.018421242013573647,\n",
       "  0.010467841289937496,\n",
       "  0.015917593613266945,\n",
       "  -0.005897603463381529,\n",
       "  -0.010381508618593216,\n",
       "  0.026633642613887787,\n",
       "  0.06215955317020416,\n",
       "  -0.010759214870631695,\n",
       "  -0.03671298548579216,\n",
       "  0.02371991239488125,\n",
       "  0.015993135049939156,\n",
       "  -0.05387161299586296,\n",
       "  0.006588265299797058,\n",
       "  -0.023935744538903236,\n",
       "  0.008989393711090088,\n",
       "  -0.007381447125226259,\n",
       "  -0.0018939238507300615,\n",
       "  -0.04213036596775055,\n",
       "  -0.018831323832273483,\n",
       "  -0.030453864485025406,\n",
       "  -0.00610264390707016,\n",
       "  0.028144463896751404,\n",
       "  -0.017126252874732018,\n",
       "  -0.01793562062084675,\n",
       "  -0.0320078544318676,\n",
       "  -0.05672059208154678,\n",
       "  -0.05007297545671463,\n",
       "  -0.01843203417956829,\n",
       "  -0.002152922097593546,\n",
       "  -0.07264897972345352,\n",
       "  0.007964192889630795,\n",
       "  0.028295546770095825,\n",
       "  -0.053267285227775574,\n",
       "  0.0033399967942386866,\n",
       "  0.03058336302638054,\n",
       "  -0.09030401706695557,\n",
       "  -0.004432645160704851,\n",
       "  0.010527195408940315,\n",
       "  0.015788095071911812,\n",
       "  0.029072541743516922,\n",
       "  0.012928323820233345,\n",
       "  0.018615491688251495,\n",
       "  0.0607350654900074,\n",
       "  0.02311558462679386,\n",
       "  -0.015485930256545544,\n",
       "  0.015960760414600372,\n",
       "  0.020061563700437546,\n",
       "  -0.010359925217926502,\n",
       "  -0.04092170670628548,\n",
       "  0.020428478717803955,\n",
       "  0.028662461787462234,\n",
       "  -0.012993073090910912,\n",
       "  -0.01246428582817316,\n",
       "  -0.028856709599494934,\n",
       "  0.016673006117343903,\n",
       "  0.02857612818479538,\n",
       "  0.009307745844125748,\n",
       "  -0.0048184446059167385,\n",
       "  0.0014811456203460693,\n",
       "  -0.00966926384717226,\n",
       "  -0.05266295373439789,\n",
       "  -0.003366975812241435,\n",
       "  -0.05050463601946831,\n",
       "  0.018950030207633972,\n",
       "  -0.007537925150245428,\n",
       "  0.036626655608415604,\n",
       "  0.00420332420617342,\n",
       "  -0.007775340229272842,\n",
       "  0.022187506780028343,\n",
       "  0.006269913166761398,\n",
       "  -0.040576376020908356,\n",
       "  -0.033518675714731216,\n",
       "  0.017924830317497253,\n",
       "  0.00916745513677597,\n",
       "  -0.03781372681260109,\n",
       "  -0.007834693416953087,\n",
       "  -0.03839647397398949,\n",
       "  0.0026371947024017572,\n",
       "  -0.00024534002295695245,\n",
       "  -0.0245832409709692,\n",
       "  0.021842176094651222,\n",
       "  -0.03919505327939987,\n",
       "  0.008876082487404346,\n",
       "  0.01965148374438286,\n",
       "  0.0008296034066006541,\n",
       "  -0.008018150925636292,\n",
       "  -0.03630290552973747,\n",
       "  0.027777550742030144,\n",
       "  -0.07031799852848053,\n",
       "  0.010780797339975834,\n",
       "  0.023547247052192688,\n",
       "  0.009237600490450859,\n",
       "  -0.041331786662340164,\n",
       "  -0.03291434794664383,\n",
       "  -0.005115213338285685,\n",
       "  -0.025770315900444984,\n",
       "  -0.023568831384181976,\n",
       "  0.015766512602567673,\n",
       "  -0.008827519603073597,\n",
       "  0.002472622785717249,\n",
       "  0.013176530599594116,\n",
       "  -0.03958354890346527,\n",
       "  0.01174124889075756,\n",
       "  0.0026358456816524267,\n",
       "  -0.04605850204825401,\n",
       "  -0.006140414159744978,\n",
       "  0.011568583548069,\n",
       "  0.0590084083378315,\n",
       "  0.02747538685798645,\n",
       "  -0.02713005617260933,\n",
       "  -0.004073824733495712,\n",
       "  -0.02173426002264023,\n",
       "  -0.009113497100770473,\n",
       "  -0.005482127424329519,\n",
       "  -0.002819302724674344,\n",
       "  -0.017072293907403946,\n",
       "  -0.02441057562828064,\n",
       "  -0.011590166948735714,\n",
       "  0.004829236306250095,\n",
       "  -0.01509743370115757,\n",
       "  -0.003874180605635047,\n",
       "  0.005371513310819864,\n",
       "  -0.023590413853526115,\n",
       "  -0.010225030593574047,\n",
       "  0.0305617805570364,\n",
       "  0.017093876376748085,\n",
       "  -0.03293592855334282,\n",
       "  0.039518799632787704,\n",
       "  -0.0029110312461853027,\n",
       "  0.03992887958884239,\n",
       "  0.020719850435853004,\n",
       "  -0.008104483596980572,\n",
       "  0.01756870746612549,\n",
       "  -0.046360667794942856,\n",
       "  0.025791898369789124,\n",
       "  0.002167760394513607,\n",
       "  -0.040425293147563934,\n",
       "  0.022144341841340065,\n",
       "  -0.006329267285764217,\n",
       "  0.051454298198223114,\n",
       "  0.04102962091565132,\n",
       "  0.04323110729455948,\n",
       "  0.0075217378325760365,\n",
       "  -0.022748669609427452,\n",
       "  0.02749696932733059,\n",
       "  -0.026158811524510384,\n",
       "  -0.01801116205751896,\n",
       "  -0.00867643766105175,\n",
       "  -0.012852782383561134,\n",
       "  0.009021768346428871,\n",
       "  0.048518985509872437,\n",
       "  0.0607350654900074,\n",
       "  -0.041115954518318176,\n",
       "  0.11464984714984894,\n",
       "  -0.032633766531944275,\n",
       "  -0.024993320927023888,\n",
       "  0.032396350055933,\n",
       "  -0.020191064104437828,\n",
       "  0.019964439794421196,\n",
       "  0.03492158278822899,\n",
       "  -0.04394335299730301,\n",
       "  -0.009124288335442543,\n",
       "  0.0020760318730026484,\n",
       "  -0.020914100110530853,\n",
       "  -0.01951119303703308,\n",
       "  0.0431879386305809,\n",
       "  0.05313778668642044,\n",
       "  0.0410727895796299,\n",
       "  0.009836533106863499,\n",
       "  0.06263438612222672,\n",
       "  0.016111843287944794,\n",
       "  0.0031943104695528746,\n",
       "  -0.001460911356844008,\n",
       "  0.021259430795907974,\n",
       "  0.02022343873977661,\n",
       "  -0.0034964748192578554,\n",
       "  -0.010386904701590538,\n",
       "  0.01121246162801981,\n",
       "  -0.008325710892677307,\n",
       "  -0.03546116128563881,\n",
       "  -0.004154761787503958,\n",
       "  -0.04303685948252678,\n",
       "  -0.02548973448574543,\n",
       "  -0.00968005508184433,\n",
       "  -0.023763079196214676,\n",
       "  0.007483967114239931,\n",
       "  0.052188124507665634,\n",
       "  -0.001757680089212954,\n",
       "  0.015593846328556538,\n",
       "  0.04644700139760971,\n",
       "  -0.03995046392083168,\n",
       "  -0.04847581684589386,\n",
       "  0.024561656638979912,\n",
       "  0.036950401961803436,\n",
       "  -0.004902079235762358,\n",
       "  0.014525478705763817,\n",
       "  -0.009647680446505547,\n",
       "  0.020504020154476166,\n",
       "  0.012162121012806892,\n",
       "  0.04446134716272354,\n",
       "  0.02769121713936329,\n",
       "  0.027000555768609047,\n",
       "  -0.007694403175264597,\n",
       "  0.004351708572357893,\n",
       "  -0.009653076529502869,\n",
       "  -0.01889607310295105,\n",
       "  -0.012183704413473606,\n",
       "  0.00532564939931035,\n",
       "  -0.0021758542861789465,\n",
       "  -0.0011587468907237053,\n",
       "  0.02007235586643219,\n",
       "  -0.040943291038274765,\n",
       "  -0.01841045171022415,\n",
       "  0.002116500400006771,\n",
       "  -0.02548973448574543,\n",
       "  0.059958070516586304,\n",
       "  0.049425479024648666,\n",
       "  -0.05313778668642044,\n",
       "  -0.010743026621639729,\n",
       "  0.003291434608399868,\n",
       "  -0.0003163284563925117,\n",
       "  -0.01502189226448536,\n",
       "  -0.006793305277824402,\n",
       "  -0.020234229043126106,\n",
       "  0.0046161022037267685,\n",
       "  -0.0006275983760133386,\n",
       "  -0.02803654782474041,\n",
       "  0.0038768784143030643,\n",
       "  0.0034964748192578554,\n",
       "  0.03215893730521202,\n",
       "  0.034468334168195724,\n",
       "  -0.016942795366048813,\n",
       "  0.022705502808094025,\n",
       "  0.03507266566157341,\n",
       "  -0.04739665985107422,\n",
       "  0.053785279393196106,\n",
       "  -0.03440358489751816,\n",
       "  -0.031187692657113075,\n",
       "  -0.03146827593445778,\n",
       "  0.033561840653419495,\n",
       "  -0.00682028429582715,\n",
       "  0.024540074169635773,\n",
       "  0.008827519603073597,\n",
       "  0.04536784067749977,\n",
       "  -0.017406834289431572,\n",
       "  0.037187814712524414,\n",
       "  0.037144649773836136,\n",
       "  -0.04120228812098503,\n",
       "  0.009561347775161266,\n",
       "  0.00718180276453495,\n",
       "  0.007127844728529453,\n",
       "  -0.012788033112883568,\n",
       "  -0.04541100561618805,\n",
       "  -0.024086827412247658,\n",
       "  0.005638605449348688,\n",
       "  0.04105120524764061,\n",
       "  -0.007586487103253603,\n",
       "  -0.050720468163490295,\n",
       "  -0.04938231036067009,\n",
       "  0.015043475665152073,\n",
       "  0.04033895954489708,\n",
       "  0.03131719306111336,\n",
       "  -0.0458858385682106,\n",
       "  -0.02965528704226017,\n",
       "  -0.014136982150375843,\n",
       "  0.02583506517112255,\n",
       "  -0.017266543582081795,\n",
       "  -0.0007142683025449514,\n",
       "  0.009280766360461712,\n",
       "  0.005811270792037249,\n",
       "  0.036410823464393616,\n",
       "  -0.015960760414600372,\n",
       "  -0.005929978098720312,\n",
       "  -0.008169232867658138,\n",
       "  -0.006237538531422615,\n",
       "  0.0029056353960186243,\n",
       "  0.0023134469520300627,\n",
       "  0.04977080971002579,\n",
       "  -0.045281507074832916,\n",
       "  0.03405825421214104,\n",
       "  0.0176442489027977,\n",
       "  0.002406524494290352,\n",
       "  0.024842238053679466,\n",
       "  -0.0892680287361145,\n",
       "  -0.03269851580262184,\n",
       "  0.00486430898308754,\n",
       "  0.04092170670628548,\n",
       "  -0.039497215300798416,\n",
       "  -0.00931314192712307,\n",
       "  -0.01074842270463705,\n",
       "  0.009458827786147594,\n",
       "  -0.01916586235165596,\n",
       "  0.01220528781414032,\n",
       "  -0.03401508927345276,\n",
       "  0.014039857313036919,\n",
       "  -0.010796984657645226,\n",
       "  0.018982404842972755,\n",
       "  0.027583302929997444,\n",
       "  -0.04886431619524956,\n",
       "  0.03308701142668724,\n",
       "  -0.002565700327977538,\n",
       "  0.015874426811933517,\n",
       "  0.008115274831652641,\n",
       "  -0.029396288096904755,\n",
       "  0.03576332703232765,\n",
       "  0.010451653972268105,\n",
       "  -0.009599118493497372,\n",
       "  -0.008471397683024406,\n",
       "  0.0007102214731276035,\n",
       "  -0.0031943104695528746,\n",
       "  -0.006485745310783386,\n",
       "  0.01702912710607052,\n",
       "  -0.0040684291161596775,\n",
       "  0.01237795315682888,\n",
       "  -0.019003989174962044,\n",
       "  0.003048623912036419,\n",
       "  0.04597216844558716,\n",
       "  -0.036453988403081894,\n",
       "  0.0012100068852305412,\n",
       "  0.011665708385407925,\n",
       "  -0.00801275484263897,\n",
       "  0.041159119457006454,\n",
       "  -0.019942857325077057,\n",
       "  0.02948262169957161,\n",
       "  -0.028252379968762398,\n",
       "  0.03621657192707062,\n",
       "  -0.0348999984562397,\n",
       "  0.03323809430003166,\n",
       "  -0.004904777277261019,\n",
       "  0.0024335032794624567,\n",
       "  0.0012181006604805589,\n",
       "  0.014083024114370346,\n",
       "  -0.006172788795083761,\n",
       "  0.05689325928688049,\n",
       "  0.025079652667045593,\n",
       "  0.043295856565237045,\n",
       "  -0.03686406835913658,\n",
       "  0.023568831384181976,\n",
       "  -0.041526034474372864,\n",
       "  0.042216695845127106,\n",
       "  0.0187018234282732,\n",
       "  -0.05227445811033249,\n",
       "  -0.00669078528881073,\n",
       "  0.009145871736109257,\n",
       "  -0.042044032365083694,\n",
       "  -0.039518799632787704,\n",
       "  0.006895825732499361,\n",
       "  -0.04200086370110512,\n",
       "  0.04346852004528046,\n",
       "  -0.03213735297322273,\n",
       "  0.03992887958884239,\n",
       "  0.002324238419532776,\n",
       "  -0.02240333892405033,\n",
       "  0.03692881762981415,\n",
       "  -0.03945405036211014,\n",
       "  0.022273840382695198,\n",
       "  0.03185677155852318,\n",
       "  -0.004405666142702103,\n",
       "  0.021626343950629234,\n",
       "  -0.009043351747095585,\n",
       "  0.041288621723651886,\n",
       "  -0.03928138315677643,\n",
       "  0.003272549482062459,\n",
       "  -0.033928755670785904,\n",
       "  -0.04217353090643883,\n",
       "  0.009545160457491875,\n",
       "  -0.009372495114803314,\n",
       "  0.022727087140083313,\n",
       "  -0.01319811400026083,\n",
       "  0.03269851580262184,\n",
       "  0.0008019499946385622,\n",
       "  0.026547309011220932,\n",
       "  -0.021011224016547203,\n",
       "  0.011665708385407925,\n",
       "  0.008827519603073597,\n",
       "  -0.006906616967171431,\n",
       "  -0.00975559651851654,\n",
       "  -0.012259244918823242,\n",
       "  -0.0201478973031044,\n",
       "  -0.02857612818479538,\n",
       "  -0.027626467868685722,\n",
       "  -0.0160039272159338,\n",
       "  -0.05447594076395035,\n",
       "  0.011136920191347599,\n",
       "  -0.006054081488400698,\n",
       "  -0.01796799525618553,\n",
       "  -0.0354827456176281,\n",
       "  -0.01121246162801981,\n",
       "  -0.00025950398412533104,\n",
       "  0.023935744538903236,\n",
       "  0.0027127356734126806,\n",
       "  -0.02186376042664051,\n",
       "  0.004985714331269264,\n",
       "  -0.01502189226448536,\n",
       "  -0.026115646585822105,\n",
       "  0.020741434767842293,\n",
       "  -0.0045648422092199326,\n",
       "  -0.010640506632626057,\n",
       "  0.01926298625767231,\n",
       "  0.010090135969221592,\n",
       "  -0.012194495648145676,\n",
       "  0.030086951330304146,\n",
       "  0.033885590732097626,\n",
       "  -0.01793562062084675,\n",
       "  0.03919505327939987,\n",
       "  0.021507637575268745,\n",
       "  0.019813356921076775,\n",
       "  0.02751855179667473,\n",
       "  0.01671617105603218,\n",
       "  0.015842052176594734,\n",
       "  0.017870871350169182,\n",
       "  0.019273778423666954,\n",
       "  -0.007489362731575966,\n",
       "  0.0037311918567866087,\n",
       "  0.027216387912631035,\n",
       "  0.004111595451831818,\n",
       "  -0.021896135061979294,\n",
       "  -0.018842114135622978,\n",
       "  -0.029223622754216194,\n",
       "  -0.009010977111756802,\n",
       "  0.02656889334321022,\n",
       "  -0.03781372681260109,\n",
       "  -0.0483894869685173,\n",
       "  -0.036065492779016495,\n",
       "  -0.011611750349402428,\n",
       "  0.020741434767842293,\n",
       "  -0.0039767008274793625,\n",
       "  0.017762955278158188,\n",
       "  -0.08201608061790466,\n",
       "  -0.01066209003329277,\n",
       "  -0.038763388991355896,\n",
       "  -0.016068676486611366,\n",
       "  0.005719542503356934,\n",
       "  -0.0030297385528683662,\n",
       "  0.05387161299586296,\n",
       "  0.026072479784488678,\n",
       "  -0.00574112543836236,\n",
       "  -0.015669386833906174,\n",
       "  0.043835435062646866,\n",
       "  -0.03945405036211014,\n",
       "  -0.01654350571334362,\n",
       "  0.007602674420922995,\n",
       "  -0.04122387245297432,\n",
       "  -0.013921150006353855,\n",
       "  -0.00036792573519051075,\n",
       "  0.006280704867094755,\n",
       "  0.029374705627560616,\n",
       "  0.00792642217129469,\n",
       "  0.0032995285000652075,\n",
       "  0.028532961383461952,\n",
       "  -0.060476064682006836,\n",
       "  -0.03127402439713478,\n",
       "  0.029698453843593597,\n",
       "  0.010975046083331108,\n",
       "  0.034123003482818604,\n",
       "  -0.020234229043126106,\n",
       "  0.023072417825460434,\n",
       "  -0.01617659255862236,\n",
       "  -0.004392176866531372,\n",
       "  0.030863944441080093,\n",
       "  0.04467717930674553,\n",
       "  0.012054204940795898,\n",
       "  0.024086827412247658,\n",
       "  0.02786388248205185,\n",
       "  -0.015485930256545544,\n",
       "  0.04756932705640793,\n",
       "  -0.01992127299308777,\n",
       "  -0.0002829419681802392,\n",
       "  -0.05680692568421364,\n",
       "  0.025058070197701454,\n",
       "  0.0032024041283875704,\n",
       "  -0.018129870295524597,\n",
       "  0.002765344688668847,\n",
       "  -0.016327673569321632,\n",
       "  -0.05853357911109924,\n",
       "  0.048216819763183594,\n",
       "  0.006555890664458275,\n",
       "  -0.0007223620195873082,\n",
       "  -0.023655163124203682,\n",
       "  -0.013176530599594116,\n",
       "  0.005897603463381529,\n",
       "  0.00027619724278338253,\n",
       "  -0.011784415692090988,\n",
       "  0.04467717930674553,\n",
       "  0.02402207814157009,\n",
       "  0.03921663388609886,\n",
       "  -0.030971860513091087,\n",
       "  0.008228586986660957,\n",
       "  -0.04558367282152176,\n",
       "  -0.0005854436894878745,\n",
       "  0.036087073385715485,\n",
       "  0.01544276438653469,\n",
       "  0.013413945212960243,\n",
       "  0.0052177333272993565,\n",
       "  -0.036626655608415604,\n",
       "  0.03215893730521202,\n",
       "  -0.021119140088558197,\n",
       "  0.012021830305457115,\n",
       "  -0.011023608036339283,\n",
       "  0.00212324527092278,\n",
       "  -0.014158564619719982,\n",
       "  0.04463401436805725,\n",
       "  0.01610105112195015,\n",
       "  0.03656190261244774,\n",
       "  -0.007802318781614304,\n",
       "  0.03293592855334282,\n",
       "  -0.007996567524969578,\n",
       "  0.029892701655626297,\n",
       "  0.024475324898958206,\n",
       "  0.004713226575404406,\n",
       "  0.0008565823663957417,\n",
       "  0.010122510604560375,\n",
       "  -0.027755968272686005,\n",
       "  -0.005455148406326771,\n",
       "  -0.007251948118209839,\n",
       "  -0.03224526718258858,\n",
       "  -0.02857612818479538,\n",
       "  -0.010942671447992325,\n",
       "  0.003555828705430031,\n",
       "  0.03019486740231514,\n",
       "  0.0013395060086622834,\n",
       "  -0.029763203114271164,\n",
       "  -0.015226932242512703,\n",
       "  -0.0047617885284125805,\n",
       "  -0.020212646573781967,\n",
       "  -0.009852721355855465,\n",
       "  0.004359802231192589,\n",
       "  -0.03684248402714729,\n",
       "  -0.03602232411503792,\n",
       "  -0.00965847261250019,\n",
       "  0.02240333892405033,\n",
       "  0.016457173973321915,\n",
       "  0.01008473988622427,\n",
       "  -0.010694464668631554,\n",
       "  0.002580538857728243,\n",
       "  0.038569141179323196,\n",
       "  0.015345639549195766,\n",
       "  0.0017333989962935448,\n",
       "  -0.03429567068815231,\n",
       "  -0.022921334952116013,\n",
       "  0.014946350827813148,\n",
       "  -0.0014649581862613559,\n",
       "  -0.06915250420570374,\n",
       "  0.010608131997287273,\n",
       "  -0.026137229055166245,\n",
       "  -0.021993258967995644,\n",
       "  -0.041871365159749985,\n",
       "  0.02693580649793148,\n",
       "  -0.0059677488170564175,\n",
       "  -0.016964377835392952,\n",
       "  -0.042238280177116394,\n",
       "  -0.02371991239488125,\n",
       "  0.008255565539002419,\n",
       "  -0.014752102084457874,\n",
       "  -0.01230241172015667,\n",
       "  0.0408785380423069,\n",
       "  -0.01502189226448536,\n",
       "  -0.0356769934296608,\n",
       "  0.003272549482062459,\n",
       "  -0.025964563712477684,\n",
       "  -0.0072681354358792305,\n",
       "  0.007462383713573217,\n",
       "  0.02296450175344944,\n",
       "  -0.004154761787503958,\n",
       "  0.0039200447499752045,\n",
       "  0.010462446138262749,\n",
       "  0.016673006117343903,\n",
       "  0.03000061772763729,\n",
       "  0.02691422402858734,\n",
       "  0.01553988829255104,\n",
       "  0.021486053243279457,\n",
       "  -0.0028327922336757183,\n",
       "  -0.016306091099977493,\n",
       "  0.018583117052912712,\n",
       "  -0.00975559651851654,\n",
       "  0.032094188034534454,\n",
       "  -0.021475262939929962,\n",
       "  0.022187506780028343,\n",
       "  -0.0015917593846097589,\n",
       "  0.003145748283714056,\n",
       "  -0.032310016453266144,\n",
       "  -0.012410327792167664,\n",
       "  -0.01047863345593214,\n",
       "  0.010581153444945812,\n",
       "  -0.0289214588701725,\n",
       "  -0.01580967754125595,\n",
       "  -0.012518243864178658,\n",
       "  0.0007803667685948312,\n",
       "  -0.01520534884184599,\n",
       "  0.009232204407453537,\n",
       "  0.0015809678006917238,\n",
       "  -0.0030459261033684015,\n",
       "  -0.006259121932089329,\n",
       "  -0.02600773051381111,\n",
       "  -0.025209153071045876,\n",
       "  -0.004103501792997122,\n",
       "  -0.04579950496554375,\n",
       "  0.0010454352013766766,\n",
       "  -0.029763203114271164,\n",
       "  -0.02441057562828064,\n",
       "  0.018097495660185814,\n",
       "  -0.031921520829200745,\n",
       "  -0.014989517629146576,\n",
       "  0.03330284357070923,\n",
       "  0.01273407507687807,\n",
       "  -0.025791898369789124,\n",
       "  -0.014180148020386696,\n",
       "  -0.010381508618593216,\n",
       "  -0.010370717383921146,\n",
       "  0.00917824637144804,\n",
       "  -0.023223500698804855,\n",
       "  0.005298670381307602,\n",
       "  -0.013187321834266186,\n",
       "  0.007527133449912071,\n",
       "  0.028446629643440247,\n",
       "  0.03703673556447029,\n",
       "  -0.03796480968594551,\n",
       "  0.044375013560056686,\n",
       "  0.018734198063611984,\n",
       "  0.02205800823867321,\n",
       "  -0.04847581684589386,\n",
       "  0.013759275898337364,\n",
       "  0.027216387912631035,\n",
       "  -0.012949907220900059,\n",
       "  0.052188124507665634,\n",
       "  0.003240174613893032,\n",
       "  -0.011320376768708229,\n",
       "  0.06526753306388855,\n",
       "  0.005832854192703962,\n",
       "  0.001558035728521645,\n",
       "  0.014180148020386696,\n",
       "  -0.026978973299264908,\n",
       "  0.01916586235165596,\n",
       "  -0.05965590476989746,\n",
       "  0.017266543582081795,\n",
       "  0.010133301839232445,\n",
       "  -0.010823964141309261,\n",
       "  -0.02046085335314274,\n",
       "  -0.010003803297877312,\n",
       "  -0.005881416145712137,\n",
       "  0.017730580642819405,\n",
       "  0.0019384392071515322,\n",
       "  -0.03666982054710388,\n",
       "  0.009210621006786823,\n",
       "  -0.011989455670118332,\n",
       "  -0.0059137907810509205,\n",
       "  0.03539641201496124,\n",
       "  -0.014255689457058907,\n",
       "  0.015075850300490856,\n",
       "  0.00028918086900375783,\n",
       "  0.012129746377468109,\n",
       "  0.056332096457481384,\n",
       "  0.006469557527452707,\n",
       "  -0.006755535025149584,\n",
       "  0.0520586259663105,\n",
       "  -0.007937213405966759,\n",
       "  0.05568460002541542,\n",
       "  -0.02460482344031334,\n",
       "  0.013748484663665295,\n",
       "  0.016629839316010475,\n",
       "  -0.01024661399424076,\n",
       "  0.03436041995882988,\n",
       "  0.02639622800052166,\n",
       "  -0.010937275364995003,\n",
       "  -0.012712491676211357,\n",
       "  0.026180395856499672,\n",
       "  -0.00470513291656971,\n",
       "  0.022317007184028625,\n",
       "  -0.0037743584252893925,\n",
       "  -0.002378196455538273,\n",
       "  -0.020007606595754623,\n",
       "  0.017169417813420296,\n",
       "  -0.004195230081677437,\n",
       "  0.006998345721513033,\n",
       "  0.001388068194501102,\n",
       "  0.027583302929997444,\n",
       "  0.019834941253066063,\n",
       "  -0.0005453124758787453,\n",
       "  -0.010332946665585041,\n",
       "  0.013780859299004078,\n",
       "  -0.0017563311848789454,\n",
       "  -0.011352751404047012,\n",
       "  -0.05175646021962166,\n",
       "  0.010041574016213417,\n",
       "  -0.010106323286890984,\n",
       "  0.008196212351322174,\n",
       "  0.020655101165175438,\n",
       "  0.016899628564715385,\n",
       "  -0.008838311769068241,\n",
       "  0.004840027540922165,\n",
       "  0.02203642576932907,\n",
       "  -0.027022140100598335,\n",
       "  0.006534307263791561,\n",
       "  -0.01246428582817316,\n",
       "  0.0041250851936638355,\n",
       "  -0.015248515643179417,\n",
       "  -0.0007581091485917568,\n",
       "  -0.001388068194501102,\n",
       "  -0.06526753306388855,\n",
       "  -0.033540260046720505,\n",
       "  -0.012626159004867077,\n",
       "  -0.02624514512717724,\n",
       "  0.01733129285275936,\n",
       "  0.042065612971782684,\n",
       "  0.04696499556303024,\n",
       "  -0.003450610674917698,\n",
       "  0.013964316807687283,\n",
       "  -0.01043007057160139,\n",
       "  -0.006512723863124847,\n",
       "  -0.04433184862136841,\n",
       "  -0.009415661916136742,\n",
       "  0.058835744857788086,\n",
       "  -0.004688945598900318,\n",
       "  -0.018475200980901718,\n",
       "  -0.0021623647771775723,\n",
       "  -0.003536943346261978,\n",
       "  0.021831385791301727,\n",
       "  0.0008349991985596716,\n",
       "  -0.014730519615113735,\n",
       "  0.03332442790269852,\n",
       "  0.01537801418453455,\n",
       "  0.006512723863124847,\n",
       "  0.009577535092830658,\n",
       "  -0.029892701655626297,\n",
       "  0.011093753390014172,\n",
       "  -0.015842052176594734,\n",
       "  0.007343676406890154,\n",
       "  -0.042238280177116394,\n",
       "  -0.02624514512717724,\n",
       "  0.035158999264240265,\n",
       "  -0.01637084037065506,\n",
       "  -0.013726901262998581,\n",
       "  -0.008811332285404205,\n",
       "  -0.01039230078458786,\n",
       "  -0.024518489837646484,\n",
       "  0.019694650545716286,\n",
       "  0.01230241172015667,\n",
       "  -0.01744999922811985,\n",
       "  0.04446134716272354,\n",
       "  0.0028759585693478584,\n",
       "  -0.02441057562828064,\n",
       "  -0.0004947269335389137,\n",
       "  0.005322951357811689,\n",
       "  0.036605071276426315,\n",
       "  0.024475324898958206,\n",
       "  0.016165800392627716,\n",
       "  0.009577535092830658,\n",
       "  0.020579559728503227,\n",
       "  0.02583506517112255,\n",
       "  0.03222368657588959,\n",
       "  -0.04102962091565132,\n",
       "  0.03891447186470032,\n",
       "  -0.017655039206147194,\n",
       "  -0.005322951357811689,\n",
       "  0.041698701679706573,\n",
       "  0.03375609219074249,\n",
       "  0.016856461763381958,\n",
       "  0.027259554713964462,\n",
       "  -0.0051260050386190414,\n",
       "  0.011180086061358452,\n",
       "  0.025532899424433708,\n",
       "  -0.04200086370110512,\n",
       "  0.03000061772763729,\n",
       "  0.08210241049528122,\n",
       "  -0.009124288335442543,\n",
       "  -0.03177043795585632,\n",
       "  -0.017018336802721024,\n",
       "  -0.019586734473705292,\n",
       "  0.00023235641128849238,\n",
       "  -0.03343234211206436,\n",
       "  -0.020104730501770973,\n",
       "  0.006555890664458275,\n",
       "  0.012658534571528435,\n",
       "  0.011331168934702873,\n",
       "  0.027086889371275902,\n",
       "  -0.0470513291656971,\n",
       "  -0.037684228271245956,\n",
       "  0.02220909111201763,\n",
       "  0.017234167084097862,\n",
       "  -0.023180333897471428,\n",
       "  -0.02009393833577633,\n",
       "  0.001119627384468913,\n",
       "  -0.02016947977244854,\n",
       "  0.007948005571961403,\n",
       "  -0.009086518548429012,\n",
       "  0.03133877366781235,\n",
       "  0.06397254019975662,\n",
       "  0.016673006117343903,\n",
       "  0.027928633615374565,\n",
       "  -0.0272811371833086,\n",
       "  0.009129684418439865,\n",
       "  0.004626893904060125,\n",
       "  0.04036054387688637,\n",
       "  -0.010656693950295448,\n",
       "  -0.0021138025913387537,\n",
       "  0.04977080971002579,\n",
       "  -0.001906064455397427,\n",
       "  -0.014331230893731117,\n",
       "  0.00618897657841444,\n",
       "  0.009086518548429012,\n",
       "  0.05063413828611374,\n",
       "  0.008455210365355015,\n",
       "  -0.0070684910751879215,\n",
       "  -0.02173426002264023,\n",
       "  0.060130733996629715,\n",
       "  0.05594359710812569,\n",
       "  0.008487585000693798,\n",
       "  0.014838434755802155,\n",
       "  -0.017417624592781067,\n",
       "  0.04756932705640793,\n",
       "  -0.006814888678491116,\n",
       "  0.0063184755854308605,\n",
       "  -0.01673775538802147,\n",
       "  -0.02510123699903488,\n",
       "  -0.0006589614204131067,\n",
       "  -0.01024661399424076,\n",
       "  -0.004605310503393412,\n",
       "  0.013748484663665295,\n",
       "  0.008611688390374184,\n",
       "  -0.002013980410993099,\n",
       "  -0.008525355719029903,\n",
       "  -0.024712739512324333,\n",
       "  -0.021291805431246758,\n",
       "  0.01610105112195015,\n",
       "  -0.027345886453986168,\n",
       "  -0.000924029853194952,\n",
       "  0.00574112543836236,\n",
       "  -0.008255565539002419,\n",
       "  0.016921211034059525,\n",
       "  0.009453431703150272,\n",
       "  0.037511564791202545,\n",
       "  -0.005800479091703892,\n",
       "  0.025899814441800117,\n",
       "  -0.01683487929403782,\n",
       "  0.03328126296401024,\n",
       "  -0.004478509537875652,\n",
       "  0.010262801311910152,\n",
       "  0.014957142993807793,\n",
       "  0.03362659364938736,\n",
       "  0.006723159924149513,\n",
       "  0.025576066225767136,\n",
       "  0.0022783742751926184,\n",
       "  -0.022468088194727898,\n",
       "  0.00867643766105175,\n",
       "  0.012690909206867218,\n",
       "  -0.06095089763402939,\n",
       "  0.012604576535522938,\n",
       "  -0.02874879352748394,\n",
       "  0.014406771399080753,\n",
       "  -0.01625213399529457,\n",
       "  -0.033346012234687805,\n",
       "  -0.006620639935135841,\n",
       "  -0.024108409881591797,\n",
       "  0.003221289487555623,\n",
       "  -0.04450451210141182,\n",
       "  0.0491664819419384,\n",
       "  -0.00714942766353488,\n",
       "  -0.018194619566202164,\n",
       "  0.021216263994574547,\n",
       "  -0.049813974648714066,\n",
       "  -0.03328126296401024,\n",
       "  0.04541100561618805,\n",
       "  0.00019964440434705466,\n",
       "  -0.05335361883044243,\n",
       "  -0.05154063180088997,\n",
       "  0.027065305039286613,\n",
       "  0.00808829627931118,\n",
       "  0.03794322907924652,\n",
       "  0.003930836450308561,\n",
       "  -0.053051453083753586,\n",
       "  0.009820345789194107,\n",
       "  0.027540136128664017,\n",
       "  0.007991171441972256,\n",
       "  -0.012259244918823242,\n",
       "  0.03999362885951996,\n",
       "  -0.02041768655180931,\n",
       "  -0.005317555740475655,\n",
       "  0.021626343950629234,\n",
       "  -0.018151452764868736,\n",
       "  0.025058070197701454,\n",
       "  0.013845608569681644,\n",
       "  -0.03088552877306938,\n",
       "  -0.0020031887106597424,\n",
       "  0.0008032988989725709,\n",
       "  -0.03360500931739807,\n",
       "  -0.017342083156108856,\n",
       "  0.025424983352422714,\n",
       "  0.0429936908185482,\n",
       "  -0.01247507706284523,\n",
       "  -0.022878170013427734,\n",
       "  0.03595757484436035,\n",
       "  0.017482373863458633,\n",
       "  -0.0020814277231693268,\n",
       "  0.049425479024648666,\n",
       "  -0.012011039070785046,\n",
       "  0.05296511948108673,\n",
       "  -0.017655039206147194,\n",
       "  0.002986572217196226,\n",
       "  -0.011180086061358452,\n",
       "  -0.012680117040872574,\n",
       "  0.015561471693217754,\n",
       "  0.013996691443026066,\n",
       "  -0.0008289289544336498,\n",
       "  -0.006728556007146835,\n",
       "  -0.01588521897792816,\n",
       "  0.010861734859645367,\n",
       "  0.0029299163725227118,\n",
       "  0.017137043178081512,\n",
       "  -0.001587712555192411,\n",
       "  -0.013791651464998722,\n",
       "  0.005897603463381529,\n",
       "  0.04135337099432945,\n",
       "  0.04139653593301773,\n",
       "  -0.02352566458284855,\n",
       "  0.007090074010193348,\n",
       "  0.0012909438228234649,\n",
       "  0.021561594679951668,\n",
       "  0.0171586275100708,\n",
       "  -0.004570237826555967,\n",
       "  0.02169109508395195,\n",
       "  -0.011816790327429771,\n",
       "  0.02602931298315525,\n",
       "  -0.007753756828606129,\n",
       "  0.01978098228573799,\n",
       "  0.02732430398464203,\n",
       "  0.02732430398464203,\n",
       "  0.010608131997287273,\n",
       "  -0.0023215406108647585,\n",
       "  -0.01454706210643053,\n",
       "  0.029525788500905037,\n",
       "  -0.0047105285339057446,\n",
       "  -0.004135876428335905,\n",
       "  -0.007807714864611626,\n",
       "  0.01121246162801981,\n",
       "  0.04411601647734642,\n",
       "  0.013359987176954746,\n",
       "  -0.033367592841386795,\n",
       "  -0.010505612008273602,\n",
       "  -0.012982281856238842,\n",
       "  0.0076188622042536736,\n",
       "  0.019327735528349876,\n",
       "  0.022273840382695198,\n",
       "  0.014622603543102741,\n",
       "  ...]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_embeddings('Help me ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0f7cd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(create_embeddings('Hello, how are you?')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d8efaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "# python\n",
    "# adapt your create_embeddings to accept str or list\n",
    "def create_embeddings(texts):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=texts\n",
    "    )\n",
    "    response_dict = response.model_dump()\n",
    "    return [data[\"embedding\"] for data in response_dict[\"data\"]]\n",
    "\n",
    "# small adapter that matches LangChain's Embeddings interface\n",
    "class CustomEmbeddings:\n",
    "    def embed_documents(self, texts):\n",
    "        # returns list[list[float]]\n",
    "        return create_embeddings(texts)\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        # returns single vector\n",
    "        return create_embeddings([text])[0]\n",
    "\n",
    "# usage with LangChain FAISS wrapper (you already have `documents` from your loader/splitter)\n",
    "emb = CustomEmbeddings()\n",
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(documents, emb)  # same API as OpenAIEmbeddings\n",
    "\n",
    "# If you need raw faiss index manually:\n",
    "import numpy as np\n",
    "vecs = np.array(create_embeddings([d.page_content for d in documents]), dtype=\"float32\")\n",
    "import faiss\n",
    "index = faiss.IndexFlatL2(vecs.shape[1])\n",
    "index.add(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0fc9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424d32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1190750a0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
